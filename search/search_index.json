{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to Ben's Code Journal May it aid you in your coding adventures if a google search lands you here. aws_code-journal","title":"Home"},{"location":"#welcome-to-bens-code-journal","text":"May it aid you in your coding adventures if a google search lands you here. aws_code-journal","title":"Welcome to Ben's Code Journal"},{"location":"notes/MKDocs/Quick Notes/","text":"Quick Notes Deploy the server\\site Be sure you are in ./code-journal/ or ./<project root> code-journal |-docs |-site |-mkdocs.yml Benjamins-MBP-2:code-journal bbearce$ pwd /Users/bbearce/Documents/Code/code-journal Use this code to serve the developer site $ mkdocs serve Use this code to build the site $ mkdocs build To push to github do this: cd ../bbearce.github.io/ mkdocs gh-deploy --config-file ../code-journal/mkdocs.yml --remote-branch master Detailed Github Notes github deploy Note for the venv pip freeze lists these packages: Click==7.0 Jinja2==2.10.1 livereload==2.6.1 Markdown==3.1.1 MarkupSafe==1.1.1 mkdocs==1.0.4 mkdocs-rtd-dropdown==1.0.2 mkdocs-windmill-dark==0.2.0 PyYAML==5.1.2 six==1.12.0 tornado==6.0.3 I am pretty sure I only installed mkdocs and mkdocs-windmill-dark","title":"MKDocs"},{"location":"notes/MKDocs/Quick Notes/#quick-notes","text":"","title":"Quick Notes"},{"location":"notes/MKDocs/Quick Notes/#deploy-the-serversite","text":"Be sure you are in ./code-journal/ or ./<project root> code-journal |-docs |-site |-mkdocs.yml Benjamins-MBP-2:code-journal bbearce$ pwd /Users/bbearce/Documents/Code/code-journal Use this code to serve the developer site $ mkdocs serve Use this code to build the site $ mkdocs build To push to github do this: cd ../bbearce.github.io/ mkdocs gh-deploy --config-file ../code-journal/mkdocs.yml --remote-branch master","title":"Deploy the server\\site"},{"location":"notes/MKDocs/Quick Notes/#detailed-github-notes","text":"github deploy","title":"Detailed Github Notes"},{"location":"notes/MKDocs/Quick Notes/#note-for-the-venv","text":"pip freeze lists these packages: Click==7.0 Jinja2==2.10.1 livereload==2.6.1 Markdown==3.1.1 MarkupSafe==1.1.1 mkdocs==1.0.4 mkdocs-rtd-dropdown==1.0.2 mkdocs-windmill-dark==0.2.0 PyYAML==5.1.2 six==1.12.0 tornado==6.0.3 I am pretty sure I only installed mkdocs and mkdocs-windmill-dark","title":"Note for the venv"},{"location":"notes/algorithms/python/alphabet_rangoli/","text":"Alphabet Rangoli An alphabet diamond design in a square You are given an integer, N. Your task is to print an alphabet rangoli of size N. (Rangoli is a form of Indian folk art based on creation of patterns.) Different sizes of alphabet rangoli are shown below: #size 3 -> 9 ----c---- --c-b-c-- c-b-a-b-c --c-b-c-- ----c---- #size 5 -> 17 --------e-------- ------e-d-e------ ----e-d-c-d-e---- --e-d-c-b-c-d-e-- e-d-c-b-a-b-c-d-e --e-d-c-b-c-d-e-- ----e-d-c-d-e---- ------e-d-e------ --------e-------- #size 10 -> 37 ------------------j------------------ ----------------j-i-j---------------- --------------j-i-h-i-j-------------- ------------j-i-h-g-h-i-j------------ ----------j-i-h-g-f-g-h-i-j---------- --------j-i-h-g-f-e-f-g-h-i-j-------- ------j-i-h-g-f-e-d-e-f-g-h-i-j------ ----j-i-h-g-f-e-d-c-d-e-f-g-h-i-j---- --j-i-h-g-f-e-d-c-b-c-d-e-f-g-h-i-j-- j-i-h-g-f-e-d-c-b-a-b-c-d-e-f-g-h-i-j --j-i-h-g-f-e-d-c-b-c-d-e-f-g-h-i-j-- ----j-i-h-g-f-e-d-c-d-e-f-g-h-i-j---- ------j-i-h-g-f-e-d-e-f-g-h-i-j------ --------j-i-h-g-f-e-f-g-h-i-j-------- ----------j-i-h-g-f-g-h-i-j---------- ------------j-i-h-g-h-i-j------------ --------------j-i-h-i-j-------------- ----------------j-i-j---------------- ------------------j------------------ The center of the rangoli has the first alphabet letter a, and the boundary has the Nth alphabet letter (in alphabetical order). Input Format Only one line of input containing N, the size of the rangoli. Constraints 0< N< 27 Output Format Print the alphabet rangoli in the format explained above. Sample Input 5 Sample Output --------e-------- ------e-d-e------ ----e-d-c-d-e---- --e-d-c-b-c-d-e-- e-d-c-b-a-b-c-d-e --e-d-c-b-c-d-e-- ----e-d-c-d-e---- ------e-d-e------ --------e-------- The code: import string def print_rangoli(size): # your code goes here N = size width = 4*(N-1)+1 letters=string.ascii_letters[0:26] # triangle up for i in range(N-1): s = '{}'.format(letters[N-i-1]) for n in range(i): s = '{}-'.format(letters[N-i+n]) + s + '-{}'.format(letters[N-i+n]) s = s.center(width, '-') print(s); del(s) # center s = '{}'.format(letters[0]) for n in range(N-1): s = '{}-'.format(letters[n+1]) + s + '-{}'.format(letters[n+1]) print(s); del(s) # triangle down for i in range(N-2,-1,-1): s = '{}'.format(letters[N-i-1]) for n in range(i): s = '{}-'.format(letters[N-i+n]) + s + '-{}'.format(letters[N-i+n]) s = s.center(width, '-') print(s); del(s) if __name__ == '__main__': n = int(input()) print_rangoli(n)","title":"Alphabet Rangoli"},{"location":"notes/algorithms/python/alphabet_rangoli/#alphabet-rangoli","text":"An alphabet diamond design in a square You are given an integer, N. Your task is to print an alphabet rangoli of size N. (Rangoli is a form of Indian folk art based on creation of patterns.) Different sizes of alphabet rangoli are shown below: #size 3 -> 9 ----c---- --c-b-c-- c-b-a-b-c --c-b-c-- ----c---- #size 5 -> 17 --------e-------- ------e-d-e------ ----e-d-c-d-e---- --e-d-c-b-c-d-e-- e-d-c-b-a-b-c-d-e --e-d-c-b-c-d-e-- ----e-d-c-d-e---- ------e-d-e------ --------e-------- #size 10 -> 37 ------------------j------------------ ----------------j-i-j---------------- --------------j-i-h-i-j-------------- ------------j-i-h-g-h-i-j------------ ----------j-i-h-g-f-g-h-i-j---------- --------j-i-h-g-f-e-f-g-h-i-j-------- ------j-i-h-g-f-e-d-e-f-g-h-i-j------ ----j-i-h-g-f-e-d-c-d-e-f-g-h-i-j---- --j-i-h-g-f-e-d-c-b-c-d-e-f-g-h-i-j-- j-i-h-g-f-e-d-c-b-a-b-c-d-e-f-g-h-i-j --j-i-h-g-f-e-d-c-b-c-d-e-f-g-h-i-j-- ----j-i-h-g-f-e-d-c-d-e-f-g-h-i-j---- ------j-i-h-g-f-e-d-e-f-g-h-i-j------ --------j-i-h-g-f-e-f-g-h-i-j-------- ----------j-i-h-g-f-g-h-i-j---------- ------------j-i-h-g-h-i-j------------ --------------j-i-h-i-j-------------- ----------------j-i-j---------------- ------------------j------------------ The center of the rangoli has the first alphabet letter a, and the boundary has the Nth alphabet letter (in alphabetical order). Input Format Only one line of input containing N, the size of the rangoli. Constraints 0< N< 27 Output Format Print the alphabet rangoli in the format explained above. Sample Input 5 Sample Output --------e-------- ------e-d-e------ ----e-d-c-d-e---- --e-d-c-b-c-d-e-- e-d-c-b-a-b-c-d-e --e-d-c-b-c-d-e-- ----e-d-c-d-e---- ------e-d-e------ --------e-------- The code: import string def print_rangoli(size): # your code goes here N = size width = 4*(N-1)+1 letters=string.ascii_letters[0:26] # triangle up for i in range(N-1): s = '{}'.format(letters[N-i-1]) for n in range(i): s = '{}-'.format(letters[N-i+n]) + s + '-{}'.format(letters[N-i+n]) s = s.center(width, '-') print(s); del(s) # center s = '{}'.format(letters[0]) for n in range(N-1): s = '{}-'.format(letters[n+1]) + s + '-{}'.format(letters[n+1]) print(s); del(s) # triangle down for i in range(N-2,-1,-1): s = '{}'.format(letters[N-i-1]) for n in range(i): s = '{}-'.format(letters[N-i+n]) + s + '-{}'.format(letters[N-i+n]) s = s.center(width, '-') print(s); del(s) if __name__ == '__main__': n = int(input()) print_rangoli(n)","title":"Alphabet Rangoli"},{"location":"notes/algorithms/python/averages/","text":"Averages Find the average of a student given a list of students You have a record of N students. Each record contains the student's name, and their percent marks in Maths, Physics and Chemistry. The marks can be floating values. The user enters some integer N followed by the names and marks for N students. You are required to save the record in a dictionary data type. The user then enters a student's name. Output the average percentage marks obtained by that student, correct to two decimal places. Input Format: The first line contains the integer N, the number of students. The next N lines contains the name and marks obtained by that student separated by a space. The final line contains the name of a particular student previously listed. Constraints: 2<=N<=10 0<=Marks<=100 Output Format: Print one line: The average of the marks obtained by the particular student correct to 2 decimal places. Sample Input 3 Krishna 67 68 69 Arjun 70 98 63 Malika 52 56 60 Malika Sample Output 56.00 Implementation: if __name__ == '__main__': # By accepting input as an int we can loop to grab all other inputs n = int(input()) # Initialize marks dict student_marks = {} for _ in range(n): # Nice trick to grab first value as name and the rest in a list called line name, *line = input().split() scores = list(map(float, line)) # Fill the student marks dict student_marks[name] = scores # Whose score do we want? query_name = input() selected_avg = round(sum(student_marks[query_name])/3,2) print(\"{0:.2f}\".format(selected_avg))","title":"Averages"},{"location":"notes/algorithms/python/averages/#averages","text":"Find the average of a student given a list of students You have a record of N students. Each record contains the student's name, and their percent marks in Maths, Physics and Chemistry. The marks can be floating values. The user enters some integer N followed by the names and marks for N students. You are required to save the record in a dictionary data type. The user then enters a student's name. Output the average percentage marks obtained by that student, correct to two decimal places. Input Format: The first line contains the integer N, the number of students. The next N lines contains the name and marks obtained by that student separated by a space. The final line contains the name of a particular student previously listed. Constraints: 2<=N<=10 0<=Marks<=100 Output Format: Print one line: The average of the marks obtained by the particular student correct to 2 decimal places. Sample Input 3 Krishna 67 68 69 Arjun 70 98 63 Malika 52 56 60 Malika Sample Output 56.00 Implementation: if __name__ == '__main__': # By accepting input as an int we can loop to grab all other inputs n = int(input()) # Initialize marks dict student_marks = {} for _ in range(n): # Nice trick to grab first value as name and the rest in a list called line name, *line = input().split() scores = list(map(float, line)) # Fill the student marks dict student_marks[name] = scores # Whose score do we want? query_name = input() selected_avg = round(sum(student_marks[query_name])/3,2) print(\"{0:.2f}\".format(selected_avg))","title":"Averages"},{"location":"notes/algorithms/python/breadth_first_search/","text":"Breadth First Search Solve a maze! In the breadth first search we start by imagining a grid. grid = [\"..........\", \"...#...##.\", \"..##...#..\", \".....###..\", \"......*...\"] Also define a key. wall, clear, goal = \"#\", \".\", \"*\" The constraints are that you need to provide a function that takes a grid and a starting point and finds the shortest path to the goal. Provide the starting point as a tuple (0,0) . Here is a basic example: import collections, pdb def bfs(grid, start): queue = collections.deque([[start]]) seen = set([start]) while queue: # pdb.set_trace() path = queue.popleft() x, y = path[-1] if grid[y][x] == goal: return path for x2, y2 in ((x+1,y), (x-1,y), (x,y+1), (x,y-1)): if 0 <= x2 < width and 0 <= y2 < height and grid[y2][x2] != wall and (x2, y2) not in seen: queue.append(path + [(x2, y2)]) seen.add((x2, y2)) # pdb.set_trace(); # For when you get stuck I have another version without the collections package to see a base python implementation. lot = [[1,1,1,1,1,1,1], [1,1,0,1,1,1,1], [0,1,1,0,0,0,1], [0,0,1,1,1,1,9],] def bfs(grid, start): # queue=[start] width = len(lot[0]) height = len(lot) queue = [[start]] seen = set([start]) loop_limit = 3000 count=0 while queue and count < loop_limit: path = queue.pop(0) x, y = path[-1] if lot[y][x] == 9: return (path,len(path)) for x2, y2 in ((x+1,y),(x-1,y),(x,y+1),(x,y-1)): if 0 <= x2 < width and 0 <= y2 < height and lot[y][x] != 0 and (x2,y2) not in seen: queue.append(path + [(x2,y2)]) seen.add((x2,y2)) count=count+1 #print(count) #print(path) return [\"we didn't get to finish\",path] shortest_path = bfs(lot, (0,0)) print(shortest_path) This prints out the following: ([(0, 0), (1, 0), (2, 0), (3, 0), (4, 0), (5, 0), (6, 0), (6, 1), (6, 2), (6, 3)], 10) A list that contains the path traversed and the the number of points in the traversed path. Finally there is a graph based approach: # Python3 Program to print BFS traversal # from a given source vertex. BFS(int s) # traverses vertices reachable from s. from collections import defaultdict import pdb # This class represents a directed graph # using adjacency list representation class Graph: # Constructor def __init__(self): # default dictionary to store graph self.graph = defaultdict(list) # function to add an edge to graph def addEdge(self,u,v): self.graph[u].append(v) # Function to print a BFS of graph def BFS(self, s): # Mark all the vertices as not visited visited = [False] * (len(self.graph)) # Create a queue for BFS queue = [] # Mark the source node as # visited and enqueue it queue.append(s) visited[s] = True while queue: pdb.set_trace() # Dequeue a vertex from # queue and print it s = queue.pop(0) print (s, end = \" \") # Get all adjacent vertices of the # dequeued vertex s. If a adjacent # has not been visited, then mark it # visited and enqueue it for i in self.graph[s]: if visited[i] == False: queue.append(i) visited[i] = True # Driver code # Create a graph given in # the above diagram g = Graph() g.addEdge(0, 1) g.addEdge(0, 2) g.addEdge(1, 2) g.addEdge(2, 0) g.addEdge(2, 3) g.addEdge(3, 3) print (\"Following is Breadth First Traversal\" \" (starting from vertex 2)\") g.BFS(2) # This code is contributed by Neelam Yadav","title":"Breadth First Search"},{"location":"notes/algorithms/python/breadth_first_search/#breadth-first-search","text":"Solve a maze! In the breadth first search we start by imagining a grid. grid = [\"..........\", \"...#...##.\", \"..##...#..\", \".....###..\", \"......*...\"] Also define a key. wall, clear, goal = \"#\", \".\", \"*\" The constraints are that you need to provide a function that takes a grid and a starting point and finds the shortest path to the goal. Provide the starting point as a tuple (0,0) . Here is a basic example: import collections, pdb def bfs(grid, start): queue = collections.deque([[start]]) seen = set([start]) while queue: # pdb.set_trace() path = queue.popleft() x, y = path[-1] if grid[y][x] == goal: return path for x2, y2 in ((x+1,y), (x-1,y), (x,y+1), (x,y-1)): if 0 <= x2 < width and 0 <= y2 < height and grid[y2][x2] != wall and (x2, y2) not in seen: queue.append(path + [(x2, y2)]) seen.add((x2, y2)) # pdb.set_trace(); # For when you get stuck I have another version without the collections package to see a base python implementation. lot = [[1,1,1,1,1,1,1], [1,1,0,1,1,1,1], [0,1,1,0,0,0,1], [0,0,1,1,1,1,9],] def bfs(grid, start): # queue=[start] width = len(lot[0]) height = len(lot) queue = [[start]] seen = set([start]) loop_limit = 3000 count=0 while queue and count < loop_limit: path = queue.pop(0) x, y = path[-1] if lot[y][x] == 9: return (path,len(path)) for x2, y2 in ((x+1,y),(x-1,y),(x,y+1),(x,y-1)): if 0 <= x2 < width and 0 <= y2 < height and lot[y][x] != 0 and (x2,y2) not in seen: queue.append(path + [(x2,y2)]) seen.add((x2,y2)) count=count+1 #print(count) #print(path) return [\"we didn't get to finish\",path] shortest_path = bfs(lot, (0,0)) print(shortest_path) This prints out the following: ([(0, 0), (1, 0), (2, 0), (3, 0), (4, 0), (5, 0), (6, 0), (6, 1), (6, 2), (6, 3)], 10) A list that contains the path traversed and the the number of points in the traversed path. Finally there is a graph based approach: # Python3 Program to print BFS traversal # from a given source vertex. BFS(int s) # traverses vertices reachable from s. from collections import defaultdict import pdb # This class represents a directed graph # using adjacency list representation class Graph: # Constructor def __init__(self): # default dictionary to store graph self.graph = defaultdict(list) # function to add an edge to graph def addEdge(self,u,v): self.graph[u].append(v) # Function to print a BFS of graph def BFS(self, s): # Mark all the vertices as not visited visited = [False] * (len(self.graph)) # Create a queue for BFS queue = [] # Mark the source node as # visited and enqueue it queue.append(s) visited[s] = True while queue: pdb.set_trace() # Dequeue a vertex from # queue and print it s = queue.pop(0) print (s, end = \" \") # Get all adjacent vertices of the # dequeued vertex s. If a adjacent # has not been visited, then mark it # visited and enqueue it for i in self.graph[s]: if visited[i] == False: queue.append(i) visited[i] = True # Driver code # Create a graph given in # the above diagram g = Graph() g.addEdge(0, 1) g.addEdge(0, 2) g.addEdge(1, 2) g.addEdge(2, 0) g.addEdge(2, 3) g.addEdge(3, 3) print (\"Following is Breadth First Traversal\" \" (starting from vertex 2)\") g.BFS(2) # This code is contributed by Neelam Yadav","title":"Breadth First Search"},{"location":"notes/algorithms/python/class_quiz/","text":"Class Quiz! Consider the following code, what will it output? class A(object): def go(self): print(\"go A go!\") def stop(self): print(\"stop A stop!\") def pause(self): raise Exception(\"Not Implemented\") class B(A): def go(self): super(B, self).go() print(\"go B go!\") class C(A): def go(self): super(C, self).go() print(\"go C go!\") def stop(self): super(C, self).stop() print(\"stop C stop!\") class D(B,C): def go(self): super(D, self).go() print(\"go D go!\") def stop(self): super(D, self).stop() print(\"stop D stop!\") def pause(self): print(\"wait D wait!\") class E(B,C): pass a = A() b = B() c = C() d = D() e = E() # specify output from here onwards a.go() # go A go! b.go() # go A go! # go B go! c.go() # go A go! # go C go! d.go() # go A go! # go C go! # go B go! # go D go! e.go() # go A go! # go C go! # go B go! a.stop() # stop A stop! b.stop() # stop A stop! c.stop() # stop A stop! # stop C stop! d.stop() # stop A stop! # stop C stop! # stop D stop! e.stop() # stop A stop! a.pause() # ... Exception: Not Implemented b.pause() # ... Exception: Not Implemented c.pause() # ... Exception: Not Implemented d.pause() # wait D wait! e.pause() # ...Exception: Not Implemented","title":"Class Quiz"},{"location":"notes/algorithms/python/class_quiz/#class-quiz","text":"Consider the following code, what will it output? class A(object): def go(self): print(\"go A go!\") def stop(self): print(\"stop A stop!\") def pause(self): raise Exception(\"Not Implemented\") class B(A): def go(self): super(B, self).go() print(\"go B go!\") class C(A): def go(self): super(C, self).go() print(\"go C go!\") def stop(self): super(C, self).stop() print(\"stop C stop!\") class D(B,C): def go(self): super(D, self).go() print(\"go D go!\") def stop(self): super(D, self).stop() print(\"stop D stop!\") def pause(self): print(\"wait D wait!\") class E(B,C): pass a = A() b = B() c = C() d = D() e = E() # specify output from here onwards a.go() # go A go! b.go() # go A go! # go B go! c.go() # go A go! # go C go! d.go() # go A go! # go C go! # go B go! # go D go! e.go() # go A go! # go C go! # go B go! a.stop() # stop A stop! b.stop() # stop A stop! c.stop() # stop A stop! # stop C stop! d.stop() # stop A stop! # stop C stop! # stop D stop! e.stop() # stop A stop! a.pause() # ... Exception: Not Implemented b.pause() # ... Exception: Not Implemented c.pause() # ... Exception: Not Implemented d.pause() # wait D wait! e.pause() # ...Exception: Not Implemented","title":"Class Quiz!"},{"location":"notes/algorithms/python/collections_counter/","text":"Collections Counter Your task is to compute how much money Raghu earned. Raghu is a shoe shop owner. His shop has X number of shoes.He has a list containing the size of each shoe he has in his shop. There are N number of customers who are willing to pay x_i amount of money only if they get the shoe of their desired size. Your task is to compute how much money Raghu earned. Input Format The first line contains X, the number of shoes. The second line contains the space separated list of all the shoe sizes in the shop. The third line contains N, the number of customers. The next N lines contain the space separated values of the shoe_size desired by the customer and x_i, the price of the shoe. Enter your code here. Read input from STDIN. Print output to STDOUT Sample Input: 10 --> Number of Shoes 2 3 4 5 6 8 7 6 5 18 --> all shoe sizes 6 -- > Number of Customers 6 55 6 45 6 55 4 40 18 60 10 50 S ample Output: 200 Explanation Customer 1: Purchased size 6 shoe for $55. Customer 2: Purchased size 6 shoe for $45. Customer 3: Size 6 no longer available, so no purchase. Customer 4: Purchased size 4 shoe for $40. Customer 5: Purchased size 18 shoe for $60. Customer 6: Size 10 not available, so no purchase. Total money earned = $200 from collections import Counter if __name__ == \"__main__\": num_of_shoes = int(input()) all_shoe_sizes = Counter(map(int, input().split())) num_customers = int(input()) total_earned = 0 for n in range(num_customers): size, price = map(int, input().split()) if all_shoe_sizes[size] != 0: total_earned = total_earned + price all_shoe_sizes[size] -= 1 print(total_earned)","title":"Collections Counter"},{"location":"notes/algorithms/python/collections_counter/#collections-counter","text":"Your task is to compute how much money Raghu earned. Raghu is a shoe shop owner. His shop has X number of shoes.He has a list containing the size of each shoe he has in his shop. There are N number of customers who are willing to pay x_i amount of money only if they get the shoe of their desired size. Your task is to compute how much money Raghu earned. Input Format The first line contains X, the number of shoes. The second line contains the space separated list of all the shoe sizes in the shop. The third line contains N, the number of customers. The next N lines contain the space separated values of the shoe_size desired by the customer and x_i, the price of the shoe. Enter your code here. Read input from STDIN. Print output to STDOUT Sample Input: 10 --> Number of Shoes 2 3 4 5 6 8 7 6 5 18 --> all shoe sizes 6 -- > Number of Customers 6 55 6 45 6 55 4 40 18 60 10 50 S ample Output: 200 Explanation Customer 1: Purchased size 6 shoe for $55. Customer 2: Purchased size 6 shoe for $45. Customer 3: Size 6 no longer available, so no purchase. Customer 4: Purchased size 4 shoe for $40. Customer 5: Purchased size 18 shoe for $60. Customer 6: Size 10 not available, so no purchase. Total money earned = $200 from collections import Counter if __name__ == \"__main__\": num_of_shoes = int(input()) all_shoe_sizes = Counter(map(int, input().split())) num_customers = int(input()) total_earned = 0 for n in range(num_customers): size, price = map(int, input().split()) if all_shoe_sizes[size] != 0: total_earned = total_earned + price all_shoe_sizes[size] -= 1 print(total_earned)","title":"Collections Counter"},{"location":"notes/algorithms/python/crossing_rects/","text":"Crossing Rects Find the total overlapping area without double counting. Problem: Imagine a grid with rectangles on it. Find the total overlapping area that does not repeat. In other words if a grid square is overlapped by multiple rectangles, it will only contribute 1 unit of area to the total overlapping area. Example 1: __________________________________> (x) |_| | | A (0,0), (1,1) |___| | B (0,0), (2,2) |_____| C (0,0), (3,3) | | \\/ (y) The answer is: 4 Example 2: Key: *(x,y), +(w, l) * - Top Left Corner + - Width and Length A (0,0), (9,3) _________________________________> (x) | __|____ B (6,1), (8,4) | | | _| |_____|__|__|_| C (13,2), (1,3) | | | | | |_____|_| \\/ (y) The answer is: 9 Here's the anser: def overlapping_area(rects=[ [(0,0),(1,1)],[(0,0),(2,2)] ]): \"\"\" This function takes a list of lists where each inner list is a rectangle. Each list will contain two tuples representing the top left corner of each rectangle and it's x-width and y-length. # Example: rect = [(x,y),(w,l)] \"\"\" def get_coordinates(rect=[(0,0), (0,0)]): \"\"\" Takes a list of tuples defining the top left corner coordinates of each square and the x-width, y-length and return all coordinates of rectangle. Below is the easy to see to setup the for loop, that way seeingwhat the comprehension is doing is much easier. This generates all x,y coordinates of a rect. coor = [] for i in range(rect[1][0]): for j in range(rect[1][1]): coor.append((rect[0][0]+i,rect[0][1]+j)) \"\"\" # List comprehension (list comprehensions are ordered backwards): coor = [(rect[0][0]+i,rect[0][1]+j) for j in range(rect[1][1]) for i in range(rect[1][0])] return coor # Get all rects coordinates rects_coors = [get_coordinates(r) for r in rects] area = 0 # Number of rectangles n = len(rects) seen = set() while n > 1: # Find overlap coors_in_common = set(rects_coors[n-1]) & set(rects_coors[n-2]) # Subtract out any previous overlap squares new_coors = coors_in_common - seen # Add fresh squares to area area += len(new_coors) # Mark seen area seen = set(rects_coors[n-1]) & set(rects_coors[n-2]) n -= 1 print(\"area of overlap is: {}\".format(area)) # Default overlapping_area() >>> area of overlap is: 1 # Trial 1 rects = [[(0,0), (1,1)], [(0,0), (2,2)], [(0,0), (3,3)]] overlapping_area(rects) >>> area of overlap is: 1 # Trial 2 rects = [[(0,0), (9,3)], [(6,1), (8,4)], [(13,2),(1,3)]] overlapping_area(rects) >>> area of overlap is: 9","title":"Crossing Rects"},{"location":"notes/algorithms/python/crossing_rects/#crossing-rects","text":"Find the total overlapping area without double counting. Problem: Imagine a grid with rectangles on it. Find the total overlapping area that does not repeat. In other words if a grid square is overlapped by multiple rectangles, it will only contribute 1 unit of area to the total overlapping area. Example 1: __________________________________> (x) |_| | | A (0,0), (1,1) |___| | B (0,0), (2,2) |_____| C (0,0), (3,3) | | \\/ (y) The answer is: 4 Example 2: Key: *(x,y), +(w, l) * - Top Left Corner + - Width and Length A (0,0), (9,3) _________________________________> (x) | __|____ B (6,1), (8,4) | | | _| |_____|__|__|_| C (13,2), (1,3) | | | | | |_____|_| \\/ (y) The answer is: 9 Here's the anser: def overlapping_area(rects=[ [(0,0),(1,1)],[(0,0),(2,2)] ]): \"\"\" This function takes a list of lists where each inner list is a rectangle. Each list will contain two tuples representing the top left corner of each rectangle and it's x-width and y-length. # Example: rect = [(x,y),(w,l)] \"\"\" def get_coordinates(rect=[(0,0), (0,0)]): \"\"\" Takes a list of tuples defining the top left corner coordinates of each square and the x-width, y-length and return all coordinates of rectangle. Below is the easy to see to setup the for loop, that way seeingwhat the comprehension is doing is much easier. This generates all x,y coordinates of a rect. coor = [] for i in range(rect[1][0]): for j in range(rect[1][1]): coor.append((rect[0][0]+i,rect[0][1]+j)) \"\"\" # List comprehension (list comprehensions are ordered backwards): coor = [(rect[0][0]+i,rect[0][1]+j) for j in range(rect[1][1]) for i in range(rect[1][0])] return coor # Get all rects coordinates rects_coors = [get_coordinates(r) for r in rects] area = 0 # Number of rectangles n = len(rects) seen = set() while n > 1: # Find overlap coors_in_common = set(rects_coors[n-1]) & set(rects_coors[n-2]) # Subtract out any previous overlap squares new_coors = coors_in_common - seen # Add fresh squares to area area += len(new_coors) # Mark seen area seen = set(rects_coors[n-1]) & set(rects_coors[n-2]) n -= 1 print(\"area of overlap is: {}\".format(area)) # Default overlapping_area() >>> area of overlap is: 1 # Trial 1 rects = [[(0,0), (1,1)], [(0,0), (2,2)], [(0,0), (3,3)]] overlapping_area(rects) >>> area of overlap is: 1 # Trial 2 rects = [[(0,0), (9,3)], [(6,1), (8,4)], [(13,2),(1,3)]] overlapping_area(rects) >>> area of overlap is: 9","title":"Crossing Rects"},{"location":"notes/algorithms/python/default_dict/","text":"Default Dict Print the indices of each occurrence of m in group A. In this challenge, you will be given integers, n and m. There are m words, which might repeat, in word group A. There are m words belonging to word group B. For each m words, check whether the word has appeared in group A or not. Print the indices of each occurrence of m in group A.If it does not appear, print -1. Sample Input: 5 2 a a b a b a b Sample Output: 1 2 4 3 5 Code: from collections import defaultdict if __name__ == '__main__': n, m = map(int,input().split()) A = []; A = [input() for i in range(n)] B = []; B = [input() for i in range(m)] B_dict = defaultdict(list) for wordB in B: for A_indice in range(len(A)): if wordB == A[A_indice]: B_dict[wordB].append(A_indice+1) if B_dict[wordB] == []: B_dict[wordB].append(-1) for word in B_dict: print(\" \".join([str(i) for i in B_dict[word]]))","title":"Default Dict"},{"location":"notes/algorithms/python/default_dict/#default-dict","text":"Print the indices of each occurrence of m in group A. In this challenge, you will be given integers, n and m. There are m words, which might repeat, in word group A. There are m words belonging to word group B. For each m words, check whether the word has appeared in group A or not. Print the indices of each occurrence of m in group A.If it does not appear, print -1. Sample Input: 5 2 a a b a b a b Sample Output: 1 2 4 3 5 Code: from collections import defaultdict if __name__ == '__main__': n, m = map(int,input().split()) A = []; A = [input() for i in range(n)] B = []; B = [input() for i in range(m)] B_dict = defaultdict(list) for wordB in B: for A_indice in range(len(A)): if wordB == A[A_indice]: B_dict[wordB].append(A_indice+1) if B_dict[wordB] == []: B_dict[wordB].append(-1) for word in B_dict: print(\" \".join([str(i) for i in B_dict[word]]))","title":"Default Dict"},{"location":"notes/algorithms/python/door_mat/","text":"Door Mat Make a doormat sized NxM, and with 'Welcome' in the middle. Mr. Vincent works in a door mat manufacturing company. One day, he designed a new door mat with the following specifications: Mat size must be NxM. (N is an odd natural number, and M is 3 times N.) The design should have 'WELCOME' written in the center. The design pattern should only use these characters: | . - Sample Designs Size: 7 x 21 ---------.|.--------- ------.|..|..|.------ ---.|..|..|..|..|.--- -------WELCOME------- ---.|..|..|..|..|.--- ------.|..|..|.------ ---------.|.--------- Size: 11 x 33 ---------------.|.--------------- ------------.|..|..|.------------ ---------.|..|..|..|..|.--------- ------.|..|..|..|..|..|..|.------ ---.|..|..|..|..|..|..|..|..|.--- -------------WELCOME------------- ---.|..|..|..|..|..|..|..|..|.--- ------.|..|..|..|..|..|..|.------ ---------.|..|..|..|..|.--------- ------------.|..|..|.------------ ---------------.|.--------------- Input Format A single line containing the space separated values of N and M. Constraints: 5<N<101 15<M<303 Example Sample Input: 9 27 Sample Output: ------------.|.------------ ---------.|..|..|.--------- ------.|..|..|..|..|.------ ---.|..|..|..|..|..|..|.--- ----------WELCOME---------- ---.|..|..|..|..|..|..|.--- ------.|..|..|..|..|.------ ---------.|..|..|.--------- ------------.|.------------ if __name__ == '__main__': N, M = map(int,input().split()) for i in range(int((N-1)/2)): print(((2*i+1)*\".|.\").center(M,'-')) print('WELCOME'.center(M,'-')) for i in range(int((N-1)/2)): print((((N-2)-2*i)*\".|.\").center(M,'-'))","title":"Door Mat"},{"location":"notes/algorithms/python/door_mat/#door-mat","text":"Make a doormat sized NxM, and with 'Welcome' in the middle. Mr. Vincent works in a door mat manufacturing company. One day, he designed a new door mat with the following specifications: Mat size must be NxM. (N is an odd natural number, and M is 3 times N.) The design should have 'WELCOME' written in the center. The design pattern should only use these characters: | . - Sample Designs Size: 7 x 21 ---------.|.--------- ------.|..|..|.------ ---.|..|..|..|..|.--- -------WELCOME------- ---.|..|..|..|..|.--- ------.|..|..|.------ ---------.|.--------- Size: 11 x 33 ---------------.|.--------------- ------------.|..|..|.------------ ---------.|..|..|..|..|.--------- ------.|..|..|..|..|..|..|.------ ---.|..|..|..|..|..|..|..|..|.--- -------------WELCOME------------- ---.|..|..|..|..|..|..|..|..|.--- ------.|..|..|..|..|..|..|.------ ---------.|..|..|..|..|.--------- ------------.|..|..|.------------ ---------------.|.--------------- Input Format A single line containing the space separated values of N and M. Constraints: 5<N<101 15<M<303 Example Sample Input: 9 27 Sample Output: ------------.|.------------ ---------.|..|..|.--------- ------.|..|..|..|..|.------ ---.|..|..|..|..|..|..|.--- ----------WELCOME---------- ---.|..|..|..|..|..|..|.--- ------.|..|..|..|..|.------ ---------.|..|..|.--------- ------------.|.------------ if __name__ == '__main__': N, M = map(int,input().split()) for i in range(int((N-1)/2)): print(((2*i+1)*\".|.\").center(M,'-')) print('WELCOME'.center(M,'-')) for i in range(int((N-1)/2)): print((((N-2)-2*i)*\".|.\").center(M,'-'))","title":"Door Mat"},{"location":"notes/algorithms/python/find_a_string/","text":"Find a string Find all occurrences of a substring in a string In this challenge, the user enters a string and a substring. You have to print the number of times that the substring occurs in the given string. String traversal will take place from left to right, not from right to left. NOTE: String letters are case-sensitive. Input Format: The first line of input contains the original string. The next line contains the substring. Constraints: 1 <= len(string) <= 200 Each character in the string is an ascii character. Output Format: Output the integer number indicating the total number of occurrences of the substring in the original string. Sample Input: ABCDCDC CDC Sample Output: 2 Concept def count_substring(string, sub_string): index = 0 counts = 0 while index < len(string): index = string.find(sub_string, index) if index == -1: break counts += 1 index += 1 return counts if __name__ == '__main__': string = input().strip() sub_string = input().strip() count = count_substring(string, sub_string) print(count)","title":"Find a String"},{"location":"notes/algorithms/python/find_a_string/#find-a-string","text":"Find all occurrences of a substring in a string In this challenge, the user enters a string and a substring. You have to print the number of times that the substring occurs in the given string. String traversal will take place from left to right, not from right to left. NOTE: String letters are case-sensitive. Input Format: The first line of input contains the original string. The next line contains the substring. Constraints: 1 <= len(string) <= 200 Each character in the string is an ascii character. Output Format: Output the integer number indicating the total number of occurrences of the substring in the original string. Sample Input: ABCDCDC CDC Sample Output: 2 Concept def count_substring(string, sub_string): index = 0 counts = 0 while index < len(string): index = string.find(sub_string, index) if index == -1: break counts += 1 index += 1 return counts if __name__ == '__main__': string = input().strip() sub_string = input().strip() count = count_substring(string, sub_string) print(count)","title":"Find a string"},{"location":"notes/algorithms/python/names_and_dates/","text":"Names and Dates Who has the same birthday? This algorithm is a simple, find all people with the same birthday. # Initial data that we are searching through data = {'Kate Thompson':'11/23/2000','Ben Patterson':'05/12/1989','Joseph Bernanke':'11/23/1970','Lindsey Harrison':'05/12/2003','Jenny Bennington':'07/09/1998','Jeremy English':'02/27/1967'} def names_and_dates(data): unique_dates = set((i[0:5] for i in data.values())) dates_dict = {date:[] for date in unique_dates} for date in dates_dict: for name in data.keys(): if data[name][0:5] == date: dates_dict[date].append(name) same_birthdays = [dates_dict[date] for date in dates_dict.keys() if len(dates_dict[date]) > 1] return same_birthdays same_birthdays = names_and_dates(data) [print(names, \"Have the same birthday\") for names in same_birthdays]","title":"Names and Dates"},{"location":"notes/algorithms/python/names_and_dates/#names-and-dates","text":"Who has the same birthday? This algorithm is a simple, find all people with the same birthday. # Initial data that we are searching through data = {'Kate Thompson':'11/23/2000','Ben Patterson':'05/12/1989','Joseph Bernanke':'11/23/1970','Lindsey Harrison':'05/12/2003','Jenny Bennington':'07/09/1998','Jeremy English':'02/27/1967'} def names_and_dates(data): unique_dates = set((i[0:5] for i in data.values())) dates_dict = {date:[] for date in unique_dates} for date in dates_dict: for name in data.keys(): if data[name][0:5] == date: dates_dict[date].append(name) same_birthdays = [dates_dict[date] for date in dates_dict.keys() if len(dates_dict[date]) > 1] return same_birthdays same_birthdays = names_and_dates(data) [print(names, \"Have the same birthday\") for names in same_birthdays]","title":"Names and Dates"},{"location":"notes/algorithms/python/nodes_w_classes/","text":"Nodes with Classes Build a parent/child relationship with classes Consider the following code, what will it output? class Node(object): def __init__(self,sName): self._lChildren = [] self.sName = sName def __repr__(self): return \"<Node '{}'>\".format(self.sName) def append(self,*args,**kwargs): self._lChildren.append(*args,**kwargs) def print_all_1(self): print(self) for oChild in self._lChildren: oChild.print_all_1() def print_all_2(self): def gen(o): lAll = [o,] while lAll: oNext = lAll.pop(0) lAll.extend(oNext._lChildren) yield oNext for oNode in gen(self): print(oNode) oRoot = Node(\"root\") oChild1 = Node(\"child1\") oChild2 = Node(\"child2\") oChild3 = Node(\"child3\") oChild4 = Node(\"child4\") oChild5 = Node(\"child5\") oChild6 = Node(\"child6\") oChild7 = Node(\"child7\") oChild8 = Node(\"child8\") oChild9 = Node(\"child9\") oChild10 = Node(\"child10\") oRoot.append(oChild1) oRoot.append(oChild2) oRoot.append(oChild3) oChild1.append(oChild5) oChild2.append(oChild6) oChild4.append(oChild7) oChild3.append(oChild8) oChild3.append(oChild9) oChild6.append(oChild10) # specify output from here onwards oRoot.print_all_1() oRoot.print_all_2() Let's discuss what happens. Below is the map of the parents and children: oRoot() _ _| _ | | | oRoot1() oRoot2() oRoot3() | | _|____ oRoot5() oRoot6() | | | oRoot8() oRoot9() oRoot10() oRoot4() | oRoot7() The append method is taking the calling object and appending the passed object to an instance variable '_lChildren'. Once the above tree is setup, it's time to investigate the two print methods. oRoot().print_all_1() def print_all_1(self): print(self) for oChild in self._lChildren: oChild.print_all_1() The first action is to print the starting root. print(self). Then we loop through the children and call the print_all_1() method for each child. It's important to note that oChild5() is called before oChild2(). This is because before oChild2() is called oChild1() called print_all1() on it's children. This has the affect of traveling down branches as opposed to across them. oRoot.print_all_1() oRoot().print_all_2() def print_all_2(self): def gen(o): lAll = [o,] while lAll: oNext = lAll.pop(0) lAll.extend(oNext._lChildren) yield oNext for oNode in gen(self): print(oNode) First loop in the for loop: Do you see the generator? print_all_2() actually creates a generator function. First it creates a function called gen(o) and then creates lAll, a list for storing objects. This is an interesting use of a generator; since lAll is remembered between successive yields, it can theoretically traverse an infinite tree. So the first value to gen is self. In that for loop the first yield is hit and pauses the function after yeilding oRoot(). The for loop is looping through an iterator so the iterator is telling the for loop to keep going. So finish the first for loop and print the oRoot(). The second: So the for loop picks up and rechecks the while condition, which is true as we added oRoot()'s direct children to lAll. Now we pop oChild1() off of lAll and add it's children to lAll. Here is what lAll looks like at this point: [oChild2(), oChild3(), oChild5()]. We yield and print oChild1() and check the while again. Its true so we grab the next element off lAll which is oChild2(). Append its children and yield it and continue horizontaly and left to right across the tree. Check out the final route taken: oRoot.print_all_2()","title":"Node w Classes"},{"location":"notes/algorithms/python/nodes_w_classes/#nodes-with-classes","text":"Build a parent/child relationship with classes Consider the following code, what will it output? class Node(object): def __init__(self,sName): self._lChildren = [] self.sName = sName def __repr__(self): return \"<Node '{}'>\".format(self.sName) def append(self,*args,**kwargs): self._lChildren.append(*args,**kwargs) def print_all_1(self): print(self) for oChild in self._lChildren: oChild.print_all_1() def print_all_2(self): def gen(o): lAll = [o,] while lAll: oNext = lAll.pop(0) lAll.extend(oNext._lChildren) yield oNext for oNode in gen(self): print(oNode) oRoot = Node(\"root\") oChild1 = Node(\"child1\") oChild2 = Node(\"child2\") oChild3 = Node(\"child3\") oChild4 = Node(\"child4\") oChild5 = Node(\"child5\") oChild6 = Node(\"child6\") oChild7 = Node(\"child7\") oChild8 = Node(\"child8\") oChild9 = Node(\"child9\") oChild10 = Node(\"child10\") oRoot.append(oChild1) oRoot.append(oChild2) oRoot.append(oChild3) oChild1.append(oChild5) oChild2.append(oChild6) oChild4.append(oChild7) oChild3.append(oChild8) oChild3.append(oChild9) oChild6.append(oChild10) # specify output from here onwards oRoot.print_all_1() oRoot.print_all_2() Let's discuss what happens. Below is the map of the parents and children: oRoot() _ _| _ | | | oRoot1() oRoot2() oRoot3() | | _|____ oRoot5() oRoot6() | | | oRoot8() oRoot9() oRoot10() oRoot4() | oRoot7() The append method is taking the calling object and appending the passed object to an instance variable '_lChildren'. Once the above tree is setup, it's time to investigate the two print methods. oRoot().print_all_1() def print_all_1(self): print(self) for oChild in self._lChildren: oChild.print_all_1() The first action is to print the starting root. print(self). Then we loop through the children and call the print_all_1() method for each child. It's important to note that oChild5() is called before oChild2(). This is because before oChild2() is called oChild1() called print_all1() on it's children. This has the affect of traveling down branches as opposed to across them. oRoot.print_all_1() oRoot().print_all_2() def print_all_2(self): def gen(o): lAll = [o,] while lAll: oNext = lAll.pop(0) lAll.extend(oNext._lChildren) yield oNext for oNode in gen(self): print(oNode) First loop in the for loop: Do you see the generator? print_all_2() actually creates a generator function. First it creates a function called gen(o) and then creates lAll, a list for storing objects. This is an interesting use of a generator; since lAll is remembered between successive yields, it can theoretically traverse an infinite tree. So the first value to gen is self. In that for loop the first yield is hit and pauses the function after yeilding oRoot(). The for loop is looping through an iterator so the iterator is telling the for loop to keep going. So finish the first for loop and print the oRoot(). The second: So the for loop picks up and rechecks the while condition, which is true as we added oRoot()'s direct children to lAll. Now we pop oChild1() off of lAll and add it's children to lAll. Here is what lAll looks like at this point: [oChild2(), oChild3(), oChild5()]. We yield and print oChild1() and check the while again. Its true so we grab the next element off lAll which is oChild2(). Append its children and yield it and continue horizontaly and left to right across the tree. Check out the final route taken: oRoot.print_all_2()","title":"Nodes with Classes"},{"location":"notes/algorithms/python/print_directory/","text":"Print Directory This function takes the name of a directory and prints out the paths files within that directory as well as any files contained in contained directories. This function is similar to os.walk. Please don't use os.walk in your answer. We are interested in your ability to work with nested structures. def print_directory_contents(sPath): import os for sChild in os.listdir(sPath): # Everything gets turned into a new path # Then we see which can go deeper... sChildPath = os.path.join(sPath,sChild) if os.path.isdir(sChildPath): # If we have a folder, recall this function print_directory_contents(sChildPath) else: # If we hit a base case then print as we have found a file print(sChildPath)","title":"Print Directory"},{"location":"notes/algorithms/python/print_directory/#print-directory","text":"This function takes the name of a directory and prints out the paths files within that directory as well as any files contained in contained directories. This function is similar to os.walk. Please don't use os.walk in your answer. We are interested in your ability to work with nested structures. def print_directory_contents(sPath): import os for sChild in os.listdir(sPath): # Everything gets turned into a new path # Then we see which can go deeper... sChildPath = os.path.join(sPath,sChild) if os.path.isdir(sChildPath): # If we have a folder, recall this function print_directory_contents(sChildPath) else: # If we hit a base case then print as we have found a file print(sChildPath)","title":"Print Directory"},{"location":"notes/algorithms/python/retry/","text":"retry() Retry a GET request a maximum of 5 times. Let's assume you want to get some response from a get command. For all intensive purposes we will assume this is all happening inside a function called get_response(choice) Next youy want to make a function try_again(response='pass') that will keep trying to execute get_response(choice) if we get a '401' response, which means that the client could not be authenticated. The catch is that we want the maximum retries to be 5 before accepting the failed authentication. Furthermore each time the retry function is called the function should sleep for n^2 seconds. It shouldn't wait anytime to execute the first get_response(choice) , which is the one initially passed to try_again() . Finally if we get '404' then return a '404 Not Found Error'. We start by defining get_response() def get_response(choice=3): choices = {1:'404',2:'pass',3:'401'} return choices[choice] Now we need try_again(). I have to give credit to Zagaran which you can find a link to on the Sources tab for this algorithm. During an interview I attempted a recursive solution, but they said a for loop would of done. So for extra practice I implemented both. def try_again_recursive(response, try_count=1): \"\"\" This function will take a response object and do the following: - If we get 'pass', return 'we connected!' - If we get '404', return '404 Not Found Error' - If we get '401', try again, however each time you try again wait the square of the try seconds before trying again. Try a maximum of 5 times before returning 'client could not be authenticated.' Example: try1: wait 1 seconds to retry try2: wait 4 seconds to retry try3: wait 9 seconds to retry try4: wait 16 seconds to retry try5: wait 0 seconds to retry! Since the max tries is 5, there is no need to wait the additional 25 seconds before exiting. \"\"\" if response == '404': return '404 Not Found Error' elif response == '401': if try_count == 5: print('for n = {0}, waiting {1} seconds.'.format(try_count, 0)) print('client could not be authenticated.') else: print('for n = {0}, waiting {1} seconds.'.format(try_count, try_count**2)) time.sleep(try_count**2) try_again_recursive(get_response(), try_count=try_count+1) else: return 'we connected!' return response Check out the output below # Tests # >>>try_again_recursive(get_response()) # for n = 1, waiting 1 seconds. # for n = 2, waiting 4 seconds. # for n = 3, waiting 9 seconds. # for n = 4, waiting 16 seconds. # for n = 5, waiting 0 seconds. # client could not be authenticated. # '401' One thing to note, I cheated a little. For the sake of practicing the multiple calls, I made sure the get_response() function always returned a '401'. We will address this a little later. For now let's implement the for loop version. # For Loop Solution: def try_again_for_loop(response): \"\"\" This function will take a response object and do the following: - If we get 'pass', return 'we connected!' - If we get '404', return '404 Not Found Error' - If we get '404', try again, however each time you try again wait the square of the try seconds before trying again. Try a maximum of 5 times before returning 'client could not be authenticated.' Example: try1: wait 1 seconds to retry try2: wait 4 seconds to retry try3: wait 9 seconds to retry try4: wait 16 seconds to retry try5: wait 0 seconds to retry! Since the max tries is 5, there is no need to wait the additional 25 seconds before exiting. \"\"\" for i in range(1,6): # [1,2,3,4,5] if response == '404': return '404 Not Found Error' elif response == '401': if i == 5: print('for n = {0}, waiting {1} seconds.'.format(i, 0)) print('client could not be authenticated.') else: # pdb.set_trace() print('for n = {0}, waiting {1} seconds.'.format(i, i**2)) time.sleep(i**2) response = get_response() else: return 'we connected!' return response Output: # >>> try_again_for_loop(get_response()) # for n = 1, waiting 1 seconds. # for n = 2, waiting 4 seconds. # for n = 3, waiting 9 seconds. # for n = 4, waiting 16 seconds. # for n = 5, waiting 0 seconds. # client could not be authenticated. # '401' Now we need to simulate reality a little better to give the other logic a chance to be executed. Let's make it so get_response() could return any of the other values ('pass','404'). Go into the recursive version of try_again() and find this line try_again_recursive(get_response(), try_count=try_count+1) , and change it to try_again_recursive(get_response(random.randint(1,3)), try_count=try_count+1) . You will need to import random at the top of your script. Then also add to your call of try_again_recursive() Results: # Simulation # >>> try_again_recursive(get_response(random.randint(1,3))) # for n = 1, waiting 1 seconds. # '401' # >>> try_again_recursive(get_response(random.randint(1,3))) # for n = 1, waiting 1 seconds. # '401' # >>> try_again_recursive(get_response(random.randint(1,3))) # 'we connected!' # >>> try_again_recursive(get_response(random.randint(1,3))) # for n = 1, waiting 1 seconds. # '401' # >>> try_again_recursive(get_response(random.randint(1,3))) # '404 Not Found Error' # >>> try_again_recursive(get_response(random.randint(1,3))) # for n = 1, waiting 1 seconds. # for n = 2, waiting 4 seconds. # for n = 3, waiting 9 seconds. # for n = 4, waiting 16 seconds. # for n = 5, waiting 0 seconds. # client could not be authenticated. # '401' Again, the for loop version changes the same thing, ie. response = get_response( to this response = get_response(random.rendint(1,3)) . # >>> try_again_for_loop(get_response(random.randint(1,3))) # for n = 1, waiting 1 seconds. # for n = 2, waiting 4 seconds. # '404 Not Found Error' # >>> try_again_for_loop(get_response(random.randint(1,3))) # for n = 1, waiting 1 seconds. # for n = 2, waiting 4 seconds. # for n = 3, waiting 9 seconds. # 'we connected!' # >>> try_again_for_loop(get_response(random.randint(1,3))) # for n = 1, waiting 1 seconds. # for n = 2, waiting 4 seconds. # for n = 3, waiting 9 seconds. # 'we connected!' # >>> try_again_for_loop(get_response(random.randint(1,3))) # '404 Not Found Error'","title":"Retry"},{"location":"notes/algorithms/python/retry/#retry","text":"Retry a GET request a maximum of 5 times. Let's assume you want to get some response from a get command. For all intensive purposes we will assume this is all happening inside a function called get_response(choice) Next youy want to make a function try_again(response='pass') that will keep trying to execute get_response(choice) if we get a '401' response, which means that the client could not be authenticated. The catch is that we want the maximum retries to be 5 before accepting the failed authentication. Furthermore each time the retry function is called the function should sleep for n^2 seconds. It shouldn't wait anytime to execute the first get_response(choice) , which is the one initially passed to try_again() . Finally if we get '404' then return a '404 Not Found Error'. We start by defining get_response() def get_response(choice=3): choices = {1:'404',2:'pass',3:'401'} return choices[choice] Now we need try_again(). I have to give credit to Zagaran which you can find a link to on the Sources tab for this algorithm. During an interview I attempted a recursive solution, but they said a for loop would of done. So for extra practice I implemented both. def try_again_recursive(response, try_count=1): \"\"\" This function will take a response object and do the following: - If we get 'pass', return 'we connected!' - If we get '404', return '404 Not Found Error' - If we get '401', try again, however each time you try again wait the square of the try seconds before trying again. Try a maximum of 5 times before returning 'client could not be authenticated.' Example: try1: wait 1 seconds to retry try2: wait 4 seconds to retry try3: wait 9 seconds to retry try4: wait 16 seconds to retry try5: wait 0 seconds to retry! Since the max tries is 5, there is no need to wait the additional 25 seconds before exiting. \"\"\" if response == '404': return '404 Not Found Error' elif response == '401': if try_count == 5: print('for n = {0}, waiting {1} seconds.'.format(try_count, 0)) print('client could not be authenticated.') else: print('for n = {0}, waiting {1} seconds.'.format(try_count, try_count**2)) time.sleep(try_count**2) try_again_recursive(get_response(), try_count=try_count+1) else: return 'we connected!' return response Check out the output below # Tests # >>>try_again_recursive(get_response()) # for n = 1, waiting 1 seconds. # for n = 2, waiting 4 seconds. # for n = 3, waiting 9 seconds. # for n = 4, waiting 16 seconds. # for n = 5, waiting 0 seconds. # client could not be authenticated. # '401' One thing to note, I cheated a little. For the sake of practicing the multiple calls, I made sure the get_response() function always returned a '401'. We will address this a little later. For now let's implement the for loop version. # For Loop Solution: def try_again_for_loop(response): \"\"\" This function will take a response object and do the following: - If we get 'pass', return 'we connected!' - If we get '404', return '404 Not Found Error' - If we get '404', try again, however each time you try again wait the square of the try seconds before trying again. Try a maximum of 5 times before returning 'client could not be authenticated.' Example: try1: wait 1 seconds to retry try2: wait 4 seconds to retry try3: wait 9 seconds to retry try4: wait 16 seconds to retry try5: wait 0 seconds to retry! Since the max tries is 5, there is no need to wait the additional 25 seconds before exiting. \"\"\" for i in range(1,6): # [1,2,3,4,5] if response == '404': return '404 Not Found Error' elif response == '401': if i == 5: print('for n = {0}, waiting {1} seconds.'.format(i, 0)) print('client could not be authenticated.') else: # pdb.set_trace() print('for n = {0}, waiting {1} seconds.'.format(i, i**2)) time.sleep(i**2) response = get_response() else: return 'we connected!' return response Output: # >>> try_again_for_loop(get_response()) # for n = 1, waiting 1 seconds. # for n = 2, waiting 4 seconds. # for n = 3, waiting 9 seconds. # for n = 4, waiting 16 seconds. # for n = 5, waiting 0 seconds. # client could not be authenticated. # '401' Now we need to simulate reality a little better to give the other logic a chance to be executed. Let's make it so get_response() could return any of the other values ('pass','404'). Go into the recursive version of try_again() and find this line try_again_recursive(get_response(), try_count=try_count+1) , and change it to try_again_recursive(get_response(random.randint(1,3)), try_count=try_count+1) . You will need to import random at the top of your script. Then also add to your call of try_again_recursive() Results: # Simulation # >>> try_again_recursive(get_response(random.randint(1,3))) # for n = 1, waiting 1 seconds. # '401' # >>> try_again_recursive(get_response(random.randint(1,3))) # for n = 1, waiting 1 seconds. # '401' # >>> try_again_recursive(get_response(random.randint(1,3))) # 'we connected!' # >>> try_again_recursive(get_response(random.randint(1,3))) # for n = 1, waiting 1 seconds. # '401' # >>> try_again_recursive(get_response(random.randint(1,3))) # '404 Not Found Error' # >>> try_again_recursive(get_response(random.randint(1,3))) # for n = 1, waiting 1 seconds. # for n = 2, waiting 4 seconds. # for n = 3, waiting 9 seconds. # for n = 4, waiting 16 seconds. # for n = 5, waiting 0 seconds. # client could not be authenticated. # '401' Again, the for loop version changes the same thing, ie. response = get_response( to this response = get_response(random.rendint(1,3)) . # >>> try_again_for_loop(get_response(random.randint(1,3))) # for n = 1, waiting 1 seconds. # for n = 2, waiting 4 seconds. # '404 Not Found Error' # >>> try_again_for_loop(get_response(random.randint(1,3))) # for n = 1, waiting 1 seconds. # for n = 2, waiting 4 seconds. # for n = 3, waiting 9 seconds. # 'we connected!' # >>> try_again_for_loop(get_response(random.randint(1,3))) # for n = 1, waiting 1 seconds. # for n = 2, waiting 4 seconds. # for n = 3, waiting 9 seconds. # 'we connected!' # >>> try_again_for_loop(get_response(random.randint(1,3))) # '404 Not Found Error'","title":"retry()"},{"location":"notes/algorithms/python/stairs/","text":"Stairs How many ways can you traverse n stairs if you can only take 1 or 2 steps. This is a cool little chunck of code illustrating and intersting way recurtsion solves a tough problem. _ |_ |_ |... how many ways can you traverse n stairs if you can only take 1 or 2 steps. Example: n = 1 (1) answer = 1 Example: n = 2 (1,1), (2) answer = 2 Example: n = 3 (1,1,1), (1,2), (2,1) answer = 3 Example: n = 4 (1,1,1,1), (1,1,2), (1,2,1), (2,1,1), (2,2) answer = 5 Example: n = 5 (1,1,1,1,1), (1,1,1,2), (1,1,2,1), (1,2,1,1), (2,1,1,1), (1,2,2), (2,1,2), (2,2,1) answer = 8 Pattern: n stairs_combo(n) 1 1 2 2 3 3 4 5 5 8 What do we notice? Answer Pattern: n stairs_combo(n) 1 1 = pattern doesn't hold 2 2 = pattern doesn't hold 3 3 = stairs_combo(2) + stairs_combo(1) = 2 + 1 = 3 4 5 = stairs_combo(3) + stairs_combo(2) = 3 + 2 = 5 5 8 = stairs_combo(4) + stairs_combo(3) = 5 + 3 = 8 We can use recursion on this since the answer depends on answers before it. For the first two values n can have (1,2) we will setup base cases to kill the recursive stack. Here is the answer: def stairs_combo(n=0): if n == 0: return 0 elif n == 1: return 1 elif n == 2: return 2 else: return stairs_combo(n-1) + stairs_combo(n-2) print(stairs_combo()) # 0 print(stairs_combo(1)) # 1 print(stairs_combo(2)) # 2 print(stairs_combo(3)) # 3 print(stairs_combo(4)) # 5 print(stairs_combo(5)) # 8 The other solution is to figure out the combinations for real! ;)","title":"Stairs"},{"location":"notes/algorithms/python/stairs/#stairs","text":"How many ways can you traverse n stairs if you can only take 1 or 2 steps. This is a cool little chunck of code illustrating and intersting way recurtsion solves a tough problem. _ |_ |_ |... how many ways can you traverse n stairs if you can only take 1 or 2 steps. Example: n = 1 (1) answer = 1 Example: n = 2 (1,1), (2) answer = 2 Example: n = 3 (1,1,1), (1,2), (2,1) answer = 3 Example: n = 4 (1,1,1,1), (1,1,2), (1,2,1), (2,1,1), (2,2) answer = 5 Example: n = 5 (1,1,1,1,1), (1,1,1,2), (1,1,2,1), (1,2,1,1), (2,1,1,1), (1,2,2), (2,1,2), (2,2,1) answer = 8 Pattern: n stairs_combo(n) 1 1 2 2 3 3 4 5 5 8 What do we notice? Answer Pattern: n stairs_combo(n) 1 1 = pattern doesn't hold 2 2 = pattern doesn't hold 3 3 = stairs_combo(2) + stairs_combo(1) = 2 + 1 = 3 4 5 = stairs_combo(3) + stairs_combo(2) = 3 + 2 = 5 5 8 = stairs_combo(4) + stairs_combo(3) = 5 + 3 = 8 We can use recursion on this since the answer depends on answers before it. For the first two values n can have (1,2) we will setup base cases to kill the recursive stack. Here is the answer: def stairs_combo(n=0): if n == 0: return 0 elif n == 1: return 1 elif n == 2: return 2 else: return stairs_combo(n-1) + stairs_combo(n-2) print(stairs_combo()) # 0 print(stairs_combo(1)) # 1 print(stairs_combo(2)) # 2 print(stairs_combo(3)) # 3 print(stairs_combo(4)) # 5 print(stairs_combo(5)) # 8 The other solution is to figure out the combinations for real! ;)","title":"Stairs"},{"location":"notes/algorithms/python/swap_case/","text":"sWAP cASE Switch case of all letters in a string. You are given a string and your task is to swap cases. In other words, convert all lowercase letters to uppercase letters and vice versa. For Example: Www.HackerRank.com \u2192 wWW.hACKERrANK.COM Pythonist 2 \u2192 pYTHONIST 2 Input Format: A single line containing a string S. Constraints: * 0<len(S)<=1000 Output Format: Print the modified string S. Sample Input: HackerRank.com presents \"Pythonist 2\". Sample Output: hACKERrANK.COM PRESENTS \"pYTHONIST 2\". Code: A = 'HackerRank.com presents \"Pythonist 2\".' def swap_case(s): S = list(s) for _ in range(len(S)): if S[_] == S[_].lower(): S[_] = S[_].upper() elif S[_] == S[_].upper(): S[_] = S[_].lower() return ''.join(S) print(swap_case(A))","title":"sWAP cASE"},{"location":"notes/algorithms/python/swap_case/#swap-case","text":"Switch case of all letters in a string. You are given a string and your task is to swap cases. In other words, convert all lowercase letters to uppercase letters and vice versa. For Example: Www.HackerRank.com \u2192 wWW.hACKERrANK.COM Pythonist 2 \u2192 pYTHONIST 2 Input Format: A single line containing a string S. Constraints: * 0<len(S)<=1000 Output Format: Print the modified string S. Sample Input: HackerRank.com presents \"Pythonist 2\". Sample Output: hACKERrANK.COM PRESENTS \"pYTHONIST 2\". Code: A = 'HackerRank.com presents \"Pythonist 2\".' def swap_case(s): S = list(s) for _ in range(len(S)): if S[_] == S[_].lower(): S[_] = S[_].upper() elif S[_] == S[_].upper(): S[_] = S[_].lower() return ''.join(S) print(swap_case(A))","title":"sWAP cASE"},{"location":"notes/algorithms/python/wheel/wheel/","text":"Make a Spinning Wheel To start we need picture like states. We can make these with strings. Import what you need import os import sys import time import math state_1 = \"\"\" -|- | / | \\\\ | | | | | | | | | | | | \\\\ | / | | -|- \"\"\" state_2 = \"\"\" / / / / / / / / / / / / / / \"\"\" state_3 = \"\"\" --------------- --------------- --------------- \"\"\" state_4 = \"\"\" - / \\\\ ---------------------------------------- \\\\ / - \"\"\" state_5 = \"\"\" --------------- --------------- --------------- \"\"\" state_6 = \"\"\" \\\\ \\\\ \\\\ \\\\ \\\\ \\\\ \\\\ \\\\ \\\\ \\\\ \\\\ \\\\ \\\\ \\\\ \"\"\" Now define a generator to access the wheel states infintely: def spinning_cursor(): while True: for cursor in [state_1,state_2,state_3,state_4,state_5,state_6]: yield cursor Next wheel size and set placeholders to keep track of the elapsed time and velocity : radius = 1 # ft spinner = spinning_cursor() elapsed_time = 0 velocity = 0 Choose the speed in terms of rotations per second: rotations_per_second = 3 rotations_desired = 2 \"DJ spin that shit!\" - KS - for _ in range(6*rotations_desired): # there are 6 states and we need all of them per rotation state = next(spinner) # call the next state if state == state_1 and elapsed_time != 0: # Once we've done a full rotation we should have enough info to calculate the velocity velocity = 2*math.pi*radius / elapsed_time # ft/s # In 1 second we do 6 states * rotations_per_second. # We can divide 1 second into these partitions to find out # how much time has passed between states. elapsed_time += 1.0 / (6*rotations_per_second) # seconds sys.stdout.write(state) # see the state sys.stdout.flush() # clear screen time.sleep(1.0/(6*rotations_per_second)) # control the rate of execution os.system('clear') # clear the screen of any states os.system('clear') # clear the screen of any states print(\"velocity: {} in miles/hour\".format(velocity/5280*60*60)) # velocity is currently in ft/s. # 5280 ft in a mile # 60 seconds in a min # 60 min in an hour Your browser does not support HTML5 video.","title":"Wheel"},{"location":"notes/algorithms/python/wheel/wheel/#make-a-spinning-wheel","text":"To start we need picture like states. We can make these with strings. Import what you need import os import sys import time import math state_1 = \"\"\" -|- | / | \\\\ | | | | | | | | | | | | \\\\ | / | | -|- \"\"\" state_2 = \"\"\" / / / / / / / / / / / / / / \"\"\" state_3 = \"\"\" --------------- --------------- --------------- \"\"\" state_4 = \"\"\" - / \\\\ ---------------------------------------- \\\\ / - \"\"\" state_5 = \"\"\" --------------- --------------- --------------- \"\"\" state_6 = \"\"\" \\\\ \\\\ \\\\ \\\\ \\\\ \\\\ \\\\ \\\\ \\\\ \\\\ \\\\ \\\\ \\\\ \\\\ \"\"\" Now define a generator to access the wheel states infintely: def spinning_cursor(): while True: for cursor in [state_1,state_2,state_3,state_4,state_5,state_6]: yield cursor Next wheel size and set placeholders to keep track of the elapsed time and velocity : radius = 1 # ft spinner = spinning_cursor() elapsed_time = 0 velocity = 0 Choose the speed in terms of rotations per second: rotations_per_second = 3 rotations_desired = 2 \"DJ spin that shit!\" - KS - for _ in range(6*rotations_desired): # there are 6 states and we need all of them per rotation state = next(spinner) # call the next state if state == state_1 and elapsed_time != 0: # Once we've done a full rotation we should have enough info to calculate the velocity velocity = 2*math.pi*radius / elapsed_time # ft/s # In 1 second we do 6 states * rotations_per_second. # We can divide 1 second into these partitions to find out # how much time has passed between states. elapsed_time += 1.0 / (6*rotations_per_second) # seconds sys.stdout.write(state) # see the state sys.stdout.flush() # clear screen time.sleep(1.0/(6*rotations_per_second)) # control the rate of execution os.system('clear') # clear the screen of any states os.system('clear') # clear the screen of any states print(\"velocity: {} in miles/hour\".format(velocity/5280*60*60)) # velocity is currently in ft/s. # 5280 ft in a mile # 60 seconds in a min # 60 min in an hour Your browser does not support HTML5 video.","title":"Make a Spinning Wheel"},{"location":"notes/bash/basics/","text":"Basic bash commands Help from the man ;) This small section is to show you that help is on the way with man . Type this prefacing any other command in bash and you can get help on it: $ man ls NAME ls - list directory contents . . . Where are you? Find your location with pwd : bbearce@bbearce-XPS-15-9560:~$ pwd /home/bbearce Look around with ls : bbearce@bbearce-XPS-15-9560:~$ ls check-config.sh gems Slicer-4.10.2-linux-amd64 Desktop Music snap docker_practice pgAdmin4 src Documents Pictures Templates Downloads Public Videos Dropbox (Partners HealthCare) R wget-log examples.desktop seaborn-data -l With -l you can see things listed out vertically bbearce@bbearce-XPS-15-9560:~$ ls -l total 2268 -rw-rw-r-- 1 bbearce bbearce 10314 May 20 09:40 check-config.sh drwxr-xr-x 2 bbearce bbearce 4096 Sep 18 11:15 Desktop drwxrwxr-x 2 bbearce bbearce 4096 Sep 5 18:11 docker_practice drwxr-xr-x 14 bbearce bbearce 4096 Sep 18 13:37 Documents drwxr-xr-x 4 bbearce bbearce 4096 Sep 19 14:44 Downloads drwx------ 7 bbearce bbearce 4096 Sep 18 11:22 Dropbox (Partners HealthCare) -rw-r--r-- 1 bbearce bbearce 8980 May 16 16:13 examples.desktop drwxrwxr-x 9 bbearce bbearce 4096 Jul 15 13:53 gems drwxr-xr-x 2 bbearce bbearce 4096 May 16 16:49 Music drwxrwxr-x 3 bbearce bbearce 4096 Aug 8 09:10 pgAdmin4 drwxr-xr-x 2 bbearce bbearce 4096 Jun 17 15:07 Pictures drwxr-xr-x 2 bbearce bbearce 4096 May 16 16:49 Public drwxrwxr-x 3 bbearce bbearce 4096 May 17 09:02 R drwxrwxr-x 2 bbearce bbearce 4096 Jul 19 17:36 seaborn-data drwxrwxr-x 8 bbearce bbearce 4096 Jun 4 13:06 Slicer-4.10.2-linux-amd64 drwxr-xr-x 8 bbearce bbearce 4096 Jul 25 16:43 snap drwxrwxr-x 3 bbearce bbearce 4096 May 23 16:12 src drwxr-xr-x 2 bbearce bbearce 4096 May 16 16:49 Templates drwxr-xr-x 2 bbearce bbearce 4096 Aug 30 13:55 Videos -rw-rw-r-- 1 bbearce bbearce 2220414 Aug 16 17:05 wget-log The columns are using ls -lai : +--------------+------------------+-----------------+-------+-------+------+-------+-----+-------+-----------+ | index number | file permissions | number of links | owner | group | size | month | day | time | filename | +--------------+------------------+-----------------+-------+-------+------+-------+-----+-------+-----------+ | 933442 | -rwxrw-r-- | 10 | root | root | 2048 | Jan | 13 | 07:11 | afile.exe | +--------------+------------------+-----------------+-------+-------+------+-------+-----+-------+-----------+ -a With -a you show hidden files: Hidden files are denoted with a .<file_name> bbearce@bbearce-XPS-15-9560:~$ ls -a . gems .pyenv .. .gitconfig .pylint.d .azure .gksu.lock .python_history .azure-shell .gnome R .bash_history .gnupg .Rhistory .bash_logout .hplip .rstudio-desktop .bashrc .ICEauthority seaborn-data .bundle .ipython Slicer-4.10.2-linux-amd64 .cache .java snap check-config.sh .jupyter .sqlite_history .compiz .kde src .config .lesshst .ssh .DataGrip2019.1 .local .sudo_as_admin_successful Desktop .mozilla .systemtap .dmrc Music Templates .docker .nano Videos docker_practice .node_repl_history .viminfo Documents .pgadmin .vscode Downloads pgAdmin4 .wget-hsts .dropbox Pictures wget-log -la Using both -la : bbearce@bbearce-XPS-15-9560:~$ ls -la total 2564 drwxrwxrwx 50 bbearce bbearce 4096 Sep 19 22:01 . drwxr-xr-x 3 root root 4096 May 29 15:05 .. drwxrwxr-x 6 bbearce bbearce 4096 May 23 16:51 .azure drwxrwxr-x 3 bbearce bbearce 4096 May 23 16:51 .azure-shell -rw------- 1 bbearce bbearce 56352 Sep 19 18:05 .bash_history -rw-r--r-- 1 bbearce bbearce 220 May 16 16:13 .bash_logout -rw-r--r-- 1 bbearce bbearce 3865 Jun 20 16:55 .bashrc drwxrwxr-x 4 bbearce bbearce 4096 Jul 10 14:28 .bundle drwx------ 48 bbearce bbearce 4096 Sep 9 13:31 .cache -rw-rw-r-- 1 bbearce bbearce 10314 May 20 09:40 check-config.sh drwx------ 3 bbearce bbearce 4096 May 16 16:50 .compiz drwx------ 43 bbearce bbearce 4096 Sep 12 11:10 .config drwxrwxr-x 4 bbearce bbearce 4096 Jul 25 16:43 .DataGrip2019.1 drwxr-xr-x 2 bbearce bbearce 4096 Sep 18 11:15 Desktop -rw-r--r-- 1 bbearce bbearce 25 May 16 16:49 .dmrc drwxrwx--- 3 bbearce bbearce 4096 Sep 5 17:35 .docker drwxrwxr-x 2 bbearce bbearce 4096 Sep 5 18:11 docker_practice drwxr-xr-x 14 bbearce bbearce 4096 Sep 18 13:37 Documents drwxr-xr-x 4 bbearce bbearce 4096 Sep 19 14:44 Downloads drwx------ 7 bbearce bbearce 4096 Sep 19 22:01 .dropbox drwxrwxr-x 3 bbearce bbearce 4096 Sep 18 03:24 .dropbox-dist drwx------ 7 bbearce bbearce 4096 Sep 18 11:22 Dropbox (Partners HealthCare) -rw-r--r-- 1 bbearce bbearce 8980 May 16 16:13 examples.desktop drwx------ 2 bbearce bbearce 4096 Sep 17 06:50 .gconf drwxrwxr-x 4 bbearce bbearce 4096 Jun 20 16:33 .gem drwxrwxr-x 9 bbearce bbearce 4096 Jul 15 13:53 gems -rw-rw-r-- 1 bbearce bbearce 57 May 21 17:11 .gitconfig -rw-r----- 1 bbearce bbearce 0 May 31 12:23 .gksu.lock drwx------ 3 bbearce bbearce 4096 May 17 08:25 .gnome drwx------ 3 bbearce bbearce 4096 Sep 19 22:01 .gnupg drwxr-xr-x 2 bbearce bbearce 4096 Jun 28 10:21 .hplip -rw------- 1 bbearce bbearce 27762 Sep 19 22:01 .ICEauthority drwxr-xr-x 5 bbearce bbearce 4096 Jun 16 18:30 .ipython drwxrwxr-x 4 bbearce bbearce 4096 Jul 25 16:43 .java drwxrwxr-x 3 bbearce bbearce 4096 Jun 16 22:35 .jupyter drwx------ 3 bbearce bbearce 4096 Jun 9 21:43 .kde -rw------- 1 bbearce bbearce 99 Sep 5 19:01 .lesshst drwx------ 6 bbearce bbearce 4096 Jun 16 18:30 .local drwx------ 5 bbearce bbearce 4096 May 17 08:13 .mozilla drwxr-xr-x 2 bbearce bbearce 4096 May 16 16:49 Music drwxrwxr-x 2 bbearce bbearce 4096 May 22 15:23 .nano -rw-rw-r-- 1 bbearce bbearce 55 Aug 6 09:48 .node_repl_history --block_size=SIZE SIZE units are K,M,G,T,P,E,Z,Y (powers of 1024) or KB,MB,... (powers of 1000). bbearce@bbearce-XPS-15-9560:~$ ls -la --block-size=M total 3M drwxrwxrwx 50 bbearce bbearce 1M Sep 20 09:32 . drwxr-xr-x 3 root root 1M May 29 15:05 .. drwxrwxr-x 6 bbearce bbearce 1M May 23 16:51 .azure drwxrwxr-x 3 bbearce bbearce 1M May 23 16:51 .azure-shell -rw------- 1 bbearce bbearce 1M Sep 19 18:05 .bash_history -rw-r--r-- 1 bbearce bbearce 1M May 16 16:13 .bash_logout ... sudo, su Notes courtesy of maketecheasier.com Using sudo you can execute code as superuser. It stands for super user do . $ man sudo NAME sudo, sudoedit \u2014 execute a command as another user . . . $ man su NAME su - change user ID or become superuser . . . $ su The su command substitutes the current user in use by the system in the shell. This will tell the system to switch (and essentially log out of) the current user to the one specified.. su is best used when a user wants direct access to the root account on the system. It doesn\u2019t go through sudo or anything like that. It is disabled by default on Ubuntu. It is recommended to use sudo -i in this case. As the note above mentions, this drops you at /root . $ sudo su This command is essentially the same as just running su in the shell. Instead of telling the system to \u201cswitch users\u201d directly, you\u2019re telling it to run the \u201csu\u201d command as root. When sudo su is run, \u201c.profile,\u201d \u201c.bashrc\u201d and \u201c/etc/profile\u201d will be started, much like running su (or su root ). This is because if any command is run with sudo in front of it, it\u2019s a command that is given root privileges. Though there isn\u2019t very much difference from \u201csu,\u201d sudo su is still a very useful command for one important reason: When a user is running \u201csu\u201d to gain root access on a system, they must know the root password. The way root is given with sudo su is by requesting the current user\u2019s password. This makes it possible to gain root without the root password which increases security. $ sudo -i Using sudo -i is virtually the same as the sudo su command. Users can gain root by \u201csudo\u201d and not by switching to the root user. Much like sudo su , the -i flag allows a user to get a root environment without having to know the root account password. sudo -i is also very similar to using sudo su in that it\u2019ll read all of the environmental files (.profile, etc.) and set the environment inside the shell with it. Where it differs from \u201csudo su\u201d is that sudo -i is a much cleaner way of gaining root and a root environment without directly interacting with the root user. How? With sudo su you\u2019re using more than one root setuid commands. This fact makes it much more challenging to figure out what environmental variables will be kept and which ones will be changed (when swamping to the root environment). This is not true with sudo -i , and it is because of this most people view it as the preferred method to gain root without logging in directly. $ sudo -s The -s switch for \u201csudo\u201d command reads the $SHELL variable of the current user executing commands. This command works as if the user is running sudo /bin/bash . sudo -s is a \u201cnon-login\u201d style shell. This means that unlike a command like sudo -i or sudo su , the system will not read any environmental files. This means that when a user tells the shell to run sudo -s , it gains root but will not change the user or the user environment. Your home will not be the root home, etc. This command is best used when the user doesn\u2019t want to touch root at all and just wants a root shell for easy command execution. Other commands talked about above gain root access, but touch root environmental files, and allow users more fuller access to root (which can be a security issue). Summary and demo of pwd when running these commands: bbearce@bbearce-XPS-15-9560:~$ sudo su root@bbearce-XPS-15-9560:/home/bbearce# pwd /home/bbearce root@bbearce-XPS-15-9560:/home/bbearce# exit exit bbearce@bbearce-XPS-15-9560:~$ sudo -i root@bbearce-XPS-15-9560:~# pwd /root root@bbearce-XPS-15-9560:~# exit logout bbearce@bbearce-XPS-15-9560:~$ sudo -s root@bbearce-XPS-15-9560:~# pwd /home/bbearce root@bbearce-XPS-15-9560:~# exit exit btw: exit is for leaving a current logged in session. bash or sh or dash? Notes courtesy of diffzi.com Bash ( bash ) is one of many available (yet the most commonly used) Unix shells. Bash stands for \" B ourne A gain SH ell\", and is a replacement/improvement of the original Bourne shell ( sh ). What is Bash? Bash is the Bourne-Again shell. Bash is an excellent full-featured shell appropriate for interactive use; indeed, it is still the default login shell. Bash is designed for human beings and provides a superset of POSIX functionality. What is Dash? Dash is the Debian Almquist Shell. Dash implements the Single Unix Spec, then it does not have to do more to meet that formal spec. Dash is for non-interactive script execution. Dash Only supports POSIX compliant features. Key Differences Bash is an excellent full-featured shell appropriate for interactive use; indeed, it is still the default login shell. However, it is rather large and slow to start up and operate by comparison with dash. Dash implements the Single Unix Spec, then it does not have to do more to meet that formal spec. But some of the \u201cbashisms\u201d are convenient, would add little to the size of dash, and would make it far easier to use dash as an alternative. A lot of shell scripts which contain the command set \u2013k are not supported by dash but supported by bash. Bash Supports the same scripting commands as Dash as well as its own additional commands, Dash Only supports POSIX compliant features. Bash is designed for human beings and provides a superset of POSIX functionality, Dash is for non-interactive script execution. Bash supports tab completion and Supports a command history. Dash is only 100K compared to Bash\u2019s 900K. Dash is for Faster start-up and script execution as compared to Bash. Moving and Copying Use the mv command to move things or rename them. Use the cp command to copy things. Use the rsync command to move things. Use the -a flag to archive and retain permissions and time stamps. Check OS Version $ cat /etc/os-release make files Courtesty of stackoverflow make is part of the build system commonly used in unix type systems - binutils . It looks at make files which hold configuration information and build targets. Specifically: ./configure - this is a script that sets up the environment for the build make - calls make with the default build target. Normally builds the app. make install - calls make with the install build target. Normally installs the app. sshfs Courtesy of github About SSHFS allows you to mount a remote filesystem using SFTP. Most SSH servers support and enable this SFTP access by default, so SSHFS is very simple to use - there's nothing to do on the server-side. Development Status SSHFS is shipped by all major Linux distributions and has been in production use across a wide range of systems for many years. However, at present SSHFS does not have any active, regular contributors, and there are a number of known issues (see the bugtracker). The current maintainer continues to apply pull requests and makes regular releases, but unfortunately has no capacity to do any development beyond addressing high-impact issues. When reporting bugs, please understand that unless you are including a pull request or are reporting a critical issue, you will probably not get a response. How to use Once sshfs is installed (see next section) running it is very simple: $ sshfs [user@]hostname:[directory] mountpoint It is recommended to run SSHFS as regular user (not as root). For this to work the mountpoint must be owned by the user. If username is omitted SSHFS will use the local username. If the directory is omitted, SSHFS will mount the (remote) home directory. If you need to enter a password sshfs will ask for it (actually it just runs ssh which ask for the password if needed). Also many ssh options can be specified (see the manual pages for sftp(1) and ssh_config(5)), including the remote port number (-oport=PORT) To unmount the filesystem: fusermount -u mountpoint On BSD and macOS, to unmount the filesystem: umount mountpoint If you get an error: fuse: mountpoint is not empty fuse: if you are sure this is safe, use the 'nonempty' mount option You might need to kill all sshfs processes and restart: ~$ killall sshfs Then restart your sshfs mounting procedure","title":"Basics"},{"location":"notes/bash/basics/#basic-bash-commands","text":"","title":"Basic bash commands"},{"location":"notes/bash/basics/#help-from-the-man","text":"This small section is to show you that help is on the way with man . Type this prefacing any other command in bash and you can get help on it: $ man ls NAME ls - list directory contents . . .","title":"Help from the man ;)"},{"location":"notes/bash/basics/#where-are-you","text":"Find your location with pwd : bbearce@bbearce-XPS-15-9560:~$ pwd /home/bbearce Look around with ls : bbearce@bbearce-XPS-15-9560:~$ ls check-config.sh gems Slicer-4.10.2-linux-amd64 Desktop Music snap docker_practice pgAdmin4 src Documents Pictures Templates Downloads Public Videos Dropbox (Partners HealthCare) R wget-log examples.desktop seaborn-data","title":"Where are you?"},{"location":"notes/bash/basics/#-l","text":"With -l you can see things listed out vertically bbearce@bbearce-XPS-15-9560:~$ ls -l total 2268 -rw-rw-r-- 1 bbearce bbearce 10314 May 20 09:40 check-config.sh drwxr-xr-x 2 bbearce bbearce 4096 Sep 18 11:15 Desktop drwxrwxr-x 2 bbearce bbearce 4096 Sep 5 18:11 docker_practice drwxr-xr-x 14 bbearce bbearce 4096 Sep 18 13:37 Documents drwxr-xr-x 4 bbearce bbearce 4096 Sep 19 14:44 Downloads drwx------ 7 bbearce bbearce 4096 Sep 18 11:22 Dropbox (Partners HealthCare) -rw-r--r-- 1 bbearce bbearce 8980 May 16 16:13 examples.desktop drwxrwxr-x 9 bbearce bbearce 4096 Jul 15 13:53 gems drwxr-xr-x 2 bbearce bbearce 4096 May 16 16:49 Music drwxrwxr-x 3 bbearce bbearce 4096 Aug 8 09:10 pgAdmin4 drwxr-xr-x 2 bbearce bbearce 4096 Jun 17 15:07 Pictures drwxr-xr-x 2 bbearce bbearce 4096 May 16 16:49 Public drwxrwxr-x 3 bbearce bbearce 4096 May 17 09:02 R drwxrwxr-x 2 bbearce bbearce 4096 Jul 19 17:36 seaborn-data drwxrwxr-x 8 bbearce bbearce 4096 Jun 4 13:06 Slicer-4.10.2-linux-amd64 drwxr-xr-x 8 bbearce bbearce 4096 Jul 25 16:43 snap drwxrwxr-x 3 bbearce bbearce 4096 May 23 16:12 src drwxr-xr-x 2 bbearce bbearce 4096 May 16 16:49 Templates drwxr-xr-x 2 bbearce bbearce 4096 Aug 30 13:55 Videos -rw-rw-r-- 1 bbearce bbearce 2220414 Aug 16 17:05 wget-log The columns are using ls -lai : +--------------+------------------+-----------------+-------+-------+------+-------+-----+-------+-----------+ | index number | file permissions | number of links | owner | group | size | month | day | time | filename | +--------------+------------------+-----------------+-------+-------+------+-------+-----+-------+-----------+ | 933442 | -rwxrw-r-- | 10 | root | root | 2048 | Jan | 13 | 07:11 | afile.exe | +--------------+------------------+-----------------+-------+-------+------+-------+-----+-------+-----------+","title":"-l"},{"location":"notes/bash/basics/#-a","text":"With -a you show hidden files: Hidden files are denoted with a .<file_name> bbearce@bbearce-XPS-15-9560:~$ ls -a . gems .pyenv .. .gitconfig .pylint.d .azure .gksu.lock .python_history .azure-shell .gnome R .bash_history .gnupg .Rhistory .bash_logout .hplip .rstudio-desktop .bashrc .ICEauthority seaborn-data .bundle .ipython Slicer-4.10.2-linux-amd64 .cache .java snap check-config.sh .jupyter .sqlite_history .compiz .kde src .config .lesshst .ssh .DataGrip2019.1 .local .sudo_as_admin_successful Desktop .mozilla .systemtap .dmrc Music Templates .docker .nano Videos docker_practice .node_repl_history .viminfo Documents .pgadmin .vscode Downloads pgAdmin4 .wget-hsts .dropbox Pictures wget-log","title":"-a"},{"location":"notes/bash/basics/#-la","text":"Using both -la : bbearce@bbearce-XPS-15-9560:~$ ls -la total 2564 drwxrwxrwx 50 bbearce bbearce 4096 Sep 19 22:01 . drwxr-xr-x 3 root root 4096 May 29 15:05 .. drwxrwxr-x 6 bbearce bbearce 4096 May 23 16:51 .azure drwxrwxr-x 3 bbearce bbearce 4096 May 23 16:51 .azure-shell -rw------- 1 bbearce bbearce 56352 Sep 19 18:05 .bash_history -rw-r--r-- 1 bbearce bbearce 220 May 16 16:13 .bash_logout -rw-r--r-- 1 bbearce bbearce 3865 Jun 20 16:55 .bashrc drwxrwxr-x 4 bbearce bbearce 4096 Jul 10 14:28 .bundle drwx------ 48 bbearce bbearce 4096 Sep 9 13:31 .cache -rw-rw-r-- 1 bbearce bbearce 10314 May 20 09:40 check-config.sh drwx------ 3 bbearce bbearce 4096 May 16 16:50 .compiz drwx------ 43 bbearce bbearce 4096 Sep 12 11:10 .config drwxrwxr-x 4 bbearce bbearce 4096 Jul 25 16:43 .DataGrip2019.1 drwxr-xr-x 2 bbearce bbearce 4096 Sep 18 11:15 Desktop -rw-r--r-- 1 bbearce bbearce 25 May 16 16:49 .dmrc drwxrwx--- 3 bbearce bbearce 4096 Sep 5 17:35 .docker drwxrwxr-x 2 bbearce bbearce 4096 Sep 5 18:11 docker_practice drwxr-xr-x 14 bbearce bbearce 4096 Sep 18 13:37 Documents drwxr-xr-x 4 bbearce bbearce 4096 Sep 19 14:44 Downloads drwx------ 7 bbearce bbearce 4096 Sep 19 22:01 .dropbox drwxrwxr-x 3 bbearce bbearce 4096 Sep 18 03:24 .dropbox-dist drwx------ 7 bbearce bbearce 4096 Sep 18 11:22 Dropbox (Partners HealthCare) -rw-r--r-- 1 bbearce bbearce 8980 May 16 16:13 examples.desktop drwx------ 2 bbearce bbearce 4096 Sep 17 06:50 .gconf drwxrwxr-x 4 bbearce bbearce 4096 Jun 20 16:33 .gem drwxrwxr-x 9 bbearce bbearce 4096 Jul 15 13:53 gems -rw-rw-r-- 1 bbearce bbearce 57 May 21 17:11 .gitconfig -rw-r----- 1 bbearce bbearce 0 May 31 12:23 .gksu.lock drwx------ 3 bbearce bbearce 4096 May 17 08:25 .gnome drwx------ 3 bbearce bbearce 4096 Sep 19 22:01 .gnupg drwxr-xr-x 2 bbearce bbearce 4096 Jun 28 10:21 .hplip -rw------- 1 bbearce bbearce 27762 Sep 19 22:01 .ICEauthority drwxr-xr-x 5 bbearce bbearce 4096 Jun 16 18:30 .ipython drwxrwxr-x 4 bbearce bbearce 4096 Jul 25 16:43 .java drwxrwxr-x 3 bbearce bbearce 4096 Jun 16 22:35 .jupyter drwx------ 3 bbearce bbearce 4096 Jun 9 21:43 .kde -rw------- 1 bbearce bbearce 99 Sep 5 19:01 .lesshst drwx------ 6 bbearce bbearce 4096 Jun 16 18:30 .local drwx------ 5 bbearce bbearce 4096 May 17 08:13 .mozilla drwxr-xr-x 2 bbearce bbearce 4096 May 16 16:49 Music drwxrwxr-x 2 bbearce bbearce 4096 May 22 15:23 .nano -rw-rw-r-- 1 bbearce bbearce 55 Aug 6 09:48 .node_repl_history","title":"-la"},{"location":"notes/bash/basics/#-block_sizesize","text":"SIZE units are K,M,G,T,P,E,Z,Y (powers of 1024) or KB,MB,... (powers of 1000). bbearce@bbearce-XPS-15-9560:~$ ls -la --block-size=M total 3M drwxrwxrwx 50 bbearce bbearce 1M Sep 20 09:32 . drwxr-xr-x 3 root root 1M May 29 15:05 .. drwxrwxr-x 6 bbearce bbearce 1M May 23 16:51 .azure drwxrwxr-x 3 bbearce bbearce 1M May 23 16:51 .azure-shell -rw------- 1 bbearce bbearce 1M Sep 19 18:05 .bash_history -rw-r--r-- 1 bbearce bbearce 1M May 16 16:13 .bash_logout ...","title":"--block_size=SIZE"},{"location":"notes/bash/basics/#sudo-su","text":"Notes courtesy of maketecheasier.com Using sudo you can execute code as superuser. It stands for super user do . $ man sudo NAME sudo, sudoedit \u2014 execute a command as another user . . . $ man su NAME su - change user ID or become superuser . . .","title":"sudo, su"},{"location":"notes/bash/basics/#su","text":"The su command substitutes the current user in use by the system in the shell. This will tell the system to switch (and essentially log out of) the current user to the one specified.. su is best used when a user wants direct access to the root account on the system. It doesn\u2019t go through sudo or anything like that. It is disabled by default on Ubuntu. It is recommended to use sudo -i in this case. As the note above mentions, this drops you at /root .","title":"$ su"},{"location":"notes/bash/basics/#sudo-su_1","text":"This command is essentially the same as just running su in the shell. Instead of telling the system to \u201cswitch users\u201d directly, you\u2019re telling it to run the \u201csu\u201d command as root. When sudo su is run, \u201c.profile,\u201d \u201c.bashrc\u201d and \u201c/etc/profile\u201d will be started, much like running su (or su root ). This is because if any command is run with sudo in front of it, it\u2019s a command that is given root privileges. Though there isn\u2019t very much difference from \u201csu,\u201d sudo su is still a very useful command for one important reason: When a user is running \u201csu\u201d to gain root access on a system, they must know the root password. The way root is given with sudo su is by requesting the current user\u2019s password. This makes it possible to gain root without the root password which increases security.","title":"$ sudo su"},{"location":"notes/bash/basics/#sudo-i","text":"Using sudo -i is virtually the same as the sudo su command. Users can gain root by \u201csudo\u201d and not by switching to the root user. Much like sudo su , the -i flag allows a user to get a root environment without having to know the root account password. sudo -i is also very similar to using sudo su in that it\u2019ll read all of the environmental files (.profile, etc.) and set the environment inside the shell with it. Where it differs from \u201csudo su\u201d is that sudo -i is a much cleaner way of gaining root and a root environment without directly interacting with the root user. How? With sudo su you\u2019re using more than one root setuid commands. This fact makes it much more challenging to figure out what environmental variables will be kept and which ones will be changed (when swamping to the root environment). This is not true with sudo -i , and it is because of this most people view it as the preferred method to gain root without logging in directly.","title":"$ sudo -i"},{"location":"notes/bash/basics/#sudo-s","text":"The -s switch for \u201csudo\u201d command reads the $SHELL variable of the current user executing commands. This command works as if the user is running sudo /bin/bash . sudo -s is a \u201cnon-login\u201d style shell. This means that unlike a command like sudo -i or sudo su , the system will not read any environmental files. This means that when a user tells the shell to run sudo -s , it gains root but will not change the user or the user environment. Your home will not be the root home, etc. This command is best used when the user doesn\u2019t want to touch root at all and just wants a root shell for easy command execution. Other commands talked about above gain root access, but touch root environmental files, and allow users more fuller access to root (which can be a security issue).","title":"$ sudo -s"},{"location":"notes/bash/basics/#summary-and-demo-of-pwd-when-running-these-commands","text":"bbearce@bbearce-XPS-15-9560:~$ sudo su root@bbearce-XPS-15-9560:/home/bbearce# pwd /home/bbearce root@bbearce-XPS-15-9560:/home/bbearce# exit exit bbearce@bbearce-XPS-15-9560:~$ sudo -i root@bbearce-XPS-15-9560:~# pwd /root root@bbearce-XPS-15-9560:~# exit logout bbearce@bbearce-XPS-15-9560:~$ sudo -s root@bbearce-XPS-15-9560:~# pwd /home/bbearce root@bbearce-XPS-15-9560:~# exit exit btw: exit is for leaving a current logged in session.","title":"Summary and demo of pwd when running these commands:"},{"location":"notes/bash/basics/#bash-or-sh-or-dash","text":"Notes courtesy of diffzi.com Bash ( bash ) is one of many available (yet the most commonly used) Unix shells. Bash stands for \" B ourne A gain SH ell\", and is a replacement/improvement of the original Bourne shell ( sh ).","title":"bash or sh or dash?"},{"location":"notes/bash/basics/#what-is-bash","text":"Bash is the Bourne-Again shell. Bash is an excellent full-featured shell appropriate for interactive use; indeed, it is still the default login shell. Bash is designed for human beings and provides a superset of POSIX functionality.","title":"What is Bash?"},{"location":"notes/bash/basics/#what-is-dash","text":"Dash is the Debian Almquist Shell. Dash implements the Single Unix Spec, then it does not have to do more to meet that formal spec. Dash is for non-interactive script execution. Dash Only supports POSIX compliant features.","title":"What is Dash?"},{"location":"notes/bash/basics/#key-differences","text":"Bash is an excellent full-featured shell appropriate for interactive use; indeed, it is still the default login shell. However, it is rather large and slow to start up and operate by comparison with dash. Dash implements the Single Unix Spec, then it does not have to do more to meet that formal spec. But some of the \u201cbashisms\u201d are convenient, would add little to the size of dash, and would make it far easier to use dash as an alternative. A lot of shell scripts which contain the command set \u2013k are not supported by dash but supported by bash. Bash Supports the same scripting commands as Dash as well as its own additional commands, Dash Only supports POSIX compliant features. Bash is designed for human beings and provides a superset of POSIX functionality, Dash is for non-interactive script execution. Bash supports tab completion and Supports a command history. Dash is only 100K compared to Bash\u2019s 900K. Dash is for Faster start-up and script execution as compared to Bash.","title":"Key Differences"},{"location":"notes/bash/basics/#moving-and-copying","text":"Use the mv command to move things or rename them. Use the cp command to copy things. Use the rsync command to move things. Use the -a flag to archive and retain permissions and time stamps.","title":"Moving and Copying"},{"location":"notes/bash/basics/#check-os-version","text":"$ cat /etc/os-release","title":"Check OS Version"},{"location":"notes/bash/basics/#make-files","text":"Courtesty of stackoverflow make is part of the build system commonly used in unix type systems - binutils . It looks at make files which hold configuration information and build targets. Specifically: ./configure - this is a script that sets up the environment for the build make - calls make with the default build target. Normally builds the app. make install - calls make with the install build target. Normally installs the app.","title":"make files"},{"location":"notes/bash/basics/#sshfs","text":"Courtesy of github","title":"sshfs"},{"location":"notes/bash/basics/#about","text":"SSHFS allows you to mount a remote filesystem using SFTP. Most SSH servers support and enable this SFTP access by default, so SSHFS is very simple to use - there's nothing to do on the server-side.","title":"About"},{"location":"notes/bash/basics/#development-status","text":"SSHFS is shipped by all major Linux distributions and has been in production use across a wide range of systems for many years. However, at present SSHFS does not have any active, regular contributors, and there are a number of known issues (see the bugtracker). The current maintainer continues to apply pull requests and makes regular releases, but unfortunately has no capacity to do any development beyond addressing high-impact issues. When reporting bugs, please understand that unless you are including a pull request or are reporting a critical issue, you will probably not get a response.","title":"Development Status"},{"location":"notes/bash/basics/#how-to-use","text":"Once sshfs is installed (see next section) running it is very simple: $ sshfs [user@]hostname:[directory] mountpoint It is recommended to run SSHFS as regular user (not as root). For this to work the mountpoint must be owned by the user. If username is omitted SSHFS will use the local username. If the directory is omitted, SSHFS will mount the (remote) home directory. If you need to enter a password sshfs will ask for it (actually it just runs ssh which ask for the password if needed). Also many ssh options can be specified (see the manual pages for sftp(1) and ssh_config(5)), including the remote port number (-oport=PORT) To unmount the filesystem: fusermount -u mountpoint On BSD and macOS, to unmount the filesystem: umount mountpoint If you get an error: fuse: mountpoint is not empty fuse: if you are sure this is safe, use the 'nonempty' mount option You might need to kill all sshfs processes and restart: ~$ killall sshfs Then restart your sshfs mounting procedure","title":"How to use"},{"location":"notes/bash/environment_variables/","text":"Environment Variables $PATH Courtesy of smallbusiness.chron.com Ubuntu Linux, as well as all other Linux distributions, uses the PATH variable to tell the operating system where to look for executable commands. Typically these commands are located in the /usr/sbin, usr/bin and /sbin, and /bin directories. Other command directories can be added to this list of directories by adding them to the PATH variable. You can choose to make a user-specified directory available for a single user or the entire system, depending on your company's requirements. Add to Path Add a path to the PATH variable: export PATH=$PATH:/my/custom/path This appends your new path to the old path and overwrites PATH. Remove from Path Execute echo $PATH to see full path variable and copy it to clipboard. Then remove a specific path between colons ...:<some path>:<path to be removed>:... and paste that into this command: export PATH=<new full path minus the path you do not want> Note thatwe aren't appending to $PATH this time, but overwriting it.","title":"Environment Variables"},{"location":"notes/bash/environment_variables/#environment-variables","text":"","title":"Environment Variables"},{"location":"notes/bash/environment_variables/#path","text":"Courtesy of smallbusiness.chron.com Ubuntu Linux, as well as all other Linux distributions, uses the PATH variable to tell the operating system where to look for executable commands. Typically these commands are located in the /usr/sbin, usr/bin and /sbin, and /bin directories. Other command directories can be added to this list of directories by adding them to the PATH variable. You can choose to make a user-specified directory available for a single user or the entire system, depending on your company's requirements.","title":"$PATH"},{"location":"notes/bash/environment_variables/#add-to-path","text":"Add a path to the PATH variable: export PATH=$PATH:/my/custom/path This appends your new path to the old path and overwrites PATH.","title":"Add to Path"},{"location":"notes/bash/environment_variables/#remove-from-path","text":"Execute echo $PATH to see full path variable and copy it to clipboard. Then remove a specific path between colons ...:<some path>:<path to be removed>:... and paste that into this command: export PATH=<new full path minus the path you do not want> Note thatwe aren't appending to $PATH this time, but overwriting it.","title":"Remove from Path"},{"location":"notes/bash/processes/","text":"Processes Kill a process (TL;DR) $ kill <pid> Ex: $ kill 1234 Courtesy of booleanworld.com ...more...below: Use top to see running processes. azureuser@miccai:~$ top top - 19:14:36 up 28 min, 1 user, load average: 0.00, 0.02, 0.05 Tasks: 115 total, 1 running, 114 sleeping, 0 stopped, 0 zombie %Cpu(s): 0.0 us, 0.0 sy, 0.0 ni,100.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st KiB Mem: 3514568 total, 715812 used, 2798756 free, 32776 buffers KiB Swap: 0 total, 0 used, 0 free. 336792 cached Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 2 root 20 0 0 0 0 S 0.0 0.0 0:00.00 kthreadd 3 root 20 0 0 0 0 S 0.0 0.0 0:00.10 ksoftirqd/0 5 root 0 -20 0 0 0 S 0.0 0.0 0:00.00 kworker/0:0H 6 root 20 0 0 0 0 S 0.0 0.0 0:00.19 kworker/u256:0 7 root 20 0 0 0 0 S 0.0 0.0 0:00.90 rcu_sched 8 root 20 0 0 0 0 S 0.0 0.0 0:00.00 rcu_bh 9 root 20 0 0 0 0 S 0.0 0.0 0:00.99 rcuos/0 10 root 20 0 0 0 0 S 0.0 0.0 0:00.00 rcuob/0 11 root rt 0 0 0 0 S 0.0 0.0 0:00.07 migration/0 12 root rt 0 0 0 0 S 0.0 0.0 0:00.02 watchdog/0 13 root rt 0 0 0 0 S 0.0 0.0 0:00.02 watchdog/1 14 root rt 0 0 0 0 S 0.0 0.0 0:00.03 migration/1 15 root 20 0 0 0 0 S 0.0 0.0 0:00.11 ksoftirqd/1 17 root 0 -20 0 0 0 S 0.0 0.0 0:00.00 kworker/1:0H 18 root 20 0 0 0 0 S 0.0 0.0 0:00.42 rcuos/1 19 root 20 0 0 0 0 S 0.0 0.0 0:00.00 rcuob/1 20 root 0 -20 0 0 0 S 0.0 0.0 0:00.00 khelper 21 root 20 0 0 0 0 S 0.0 0.0 0:00.00 kdevtmpfs 22 root 0 -20 0 0 0 S 0.0 0.0 0:00.00 netns 23 root 0 -20 0 0 0 S 0.0 0.0 0:00.00 perf 24 root 20 0 0 0 0 S 0.0 0.0 0:00.00 khungtaskd 25 root 0 -20 0 0 0 S 0.0 0.0 0:00.00 writeback 26 root 25 5 0 0 0 S 0.0 0.0 0:00.00 ksmd 27 root 39 19 0 0 0 S 0.0 0.0 0:00.03 khugepaged 28 root 0 -20 0 0 0 S 0.0 0.0 0:00.00 crypto 29 root 0 -20 0 0 0 S 0.0 0.0 0:00.00 kintegrityd 30 root 0 -20 0 0 0 S 0.0 0.0 0:00.00 bioset 31 root 0 -20 0 0 0 S 0.0 0.0 0:00.00 kblockd ... ... ... The other option is $ ps aux . This will give the command used to run the process (this can sometimes be more helpful). azureuser@miccai:~$ ps aux USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND root 1 0.2 0.1 35080 5100 ? Ss 18:46 0:04 /sbin/init root 2 0.0 0.0 0 0 ? S 18:46 0:00 [kthreadd] root 3 0.0 0.0 0 0 ? S 18:46 0:00 [ksoftirqd/0] root 5 0.0 0.0 0 0 ? S< 18:46 0:00 [kworker/0:0H] root 6 0.0 0.0 0 0 ? S 18:46 0:00 [kworker/u256:0] root 7 0.0 0.0 0 0 ? S 18:46 0:00 [rcu_sched] root 8 0.0 0.0 0 0 ? S 18:46 0:00 [rcu_bh] root 9 0.0 0.0 0 0 ? S 18:46 0:01 [rcuos/0] root 10 0.0 0.0 0 0 ? S 18:46 0:00 [rcuob/0] root 11 0.0 0.0 0 0 ? S 18:46 0:00 [migration/0] root 12 0.0 0.0 0 0 ? S 18:46 0:00 [watchdog/0] root 13 0.0 0.0 0 0 ? S 18:46 0:00 [watchdog/1] root 14 0.0 0.0 0 0 ? S 18:46 0:00 [migration/1] ... ... ... The advantage of using ps is that you can easily filter this list with the grep command. For example, to find a process associated with the term \"SCREEN\", you can use: azureuser@miccai:~$ ps aux | grep -i SCREEN azureus+ 1813 0.0 0.0 26104 2756 ? Ss 19:02 0:00 SCREEN -S mysql azureus+ 2058 0.0 0.0 8212 2148 pts/0 S+ 19:17 0:00 grep --color=auto -i SCREEN Thus, even when there are no \u201cvnstat\u201d related processes running, we would get one entry showing the grep process: azureuser@miccai:~$ ps aux | grep -i \"vnstat\" azureus+ 2070 0.0 0.0 8212 2212 pts/0 S+ 19:18 0:00 grep --color=auto -i vnstat Killing a process: There are various commands you can use to kill a process \u2014 kill , killall , pkill and top . We will begin from the simplest one: the killall command. killall Killing processes with the killall command: The killall command is one of the easiest ways to kill a process. If you know the exact name of a process, and you know that it\u2019s not running as another user and it is not in the Z or D states, then you can use this command directly; there\u2019s no need to manually locate the process as we described above. By default, For example, to kill a process named \u201cfirefox\u201d, run: $ killall firefox To forcibly kill the process with SIGKILL , run: $ killall -9 firefox You can also use -SIGKILL instead of -9 . If you want to kill processes interactively, you can use -i like so: $ killall -i firefox If you want to kill a process running as a different user, you can use sudo : $ sudo killall firefox You can also kill a process that has been running for a certain period of time with the -o and -y flags. So, if you want to kill a process that has been running for more than 30 minutes, use: $ killall -o 30m <process-name> If you want to kill a process that has been running for less than 30 minutes, use: $ killall -y 30m <process-name> Similarly, use the following abbreviations for the respective units of time: s seconds m minutes h hours d days w weeks M months y years pkill Killing processes with the pkill command Sometimes, you only know part of a program\u2019s name. Just like pgrep , pkill allows you to kill processes based on partial matches. For example, if you want to kill all processes containing the name apache in the name, run: pkill apache If you want to use a SIGKILL instead of a SIGTERM , use: pkill -9 apache Again, you can also use -SIGKILL instead of -9 . kill Killing processes with the kill command: Using the kill command is straightforward. Once you have found out the PID of the process that you want to kill , you can terminate it using the kill command. For example, if you want to kill a process having a PID of 1234, then use the following command: kill 1234 As we mentioned previously, the default is to use a SIGTERM . To use a SIGKILL , use -9 or -SIGKILL as we have seen before: kill -9 1234 Using top Killing processes with the top command: It is very easy to kill processes using the top command. First, search for the process that you want to kill and note the PID. Then, press k while top is running (this is case sensitive). It will prompt you to enter the PID of the process that you want to kill.","title":"Processes"},{"location":"notes/bash/processes/#processes","text":"","title":"Processes"},{"location":"notes/bash/processes/#kill-a-process-tldr","text":"$ kill <pid> Ex: $ kill 1234 Courtesy of booleanworld.com ...more...below: Use top to see running processes. azureuser@miccai:~$ top top - 19:14:36 up 28 min, 1 user, load average: 0.00, 0.02, 0.05 Tasks: 115 total, 1 running, 114 sleeping, 0 stopped, 0 zombie %Cpu(s): 0.0 us, 0.0 sy, 0.0 ni,100.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st KiB Mem: 3514568 total, 715812 used, 2798756 free, 32776 buffers KiB Swap: 0 total, 0 used, 0 free. 336792 cached Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 2 root 20 0 0 0 0 S 0.0 0.0 0:00.00 kthreadd 3 root 20 0 0 0 0 S 0.0 0.0 0:00.10 ksoftirqd/0 5 root 0 -20 0 0 0 S 0.0 0.0 0:00.00 kworker/0:0H 6 root 20 0 0 0 0 S 0.0 0.0 0:00.19 kworker/u256:0 7 root 20 0 0 0 0 S 0.0 0.0 0:00.90 rcu_sched 8 root 20 0 0 0 0 S 0.0 0.0 0:00.00 rcu_bh 9 root 20 0 0 0 0 S 0.0 0.0 0:00.99 rcuos/0 10 root 20 0 0 0 0 S 0.0 0.0 0:00.00 rcuob/0 11 root rt 0 0 0 0 S 0.0 0.0 0:00.07 migration/0 12 root rt 0 0 0 0 S 0.0 0.0 0:00.02 watchdog/0 13 root rt 0 0 0 0 S 0.0 0.0 0:00.02 watchdog/1 14 root rt 0 0 0 0 S 0.0 0.0 0:00.03 migration/1 15 root 20 0 0 0 0 S 0.0 0.0 0:00.11 ksoftirqd/1 17 root 0 -20 0 0 0 S 0.0 0.0 0:00.00 kworker/1:0H 18 root 20 0 0 0 0 S 0.0 0.0 0:00.42 rcuos/1 19 root 20 0 0 0 0 S 0.0 0.0 0:00.00 rcuob/1 20 root 0 -20 0 0 0 S 0.0 0.0 0:00.00 khelper 21 root 20 0 0 0 0 S 0.0 0.0 0:00.00 kdevtmpfs 22 root 0 -20 0 0 0 S 0.0 0.0 0:00.00 netns 23 root 0 -20 0 0 0 S 0.0 0.0 0:00.00 perf 24 root 20 0 0 0 0 S 0.0 0.0 0:00.00 khungtaskd 25 root 0 -20 0 0 0 S 0.0 0.0 0:00.00 writeback 26 root 25 5 0 0 0 S 0.0 0.0 0:00.00 ksmd 27 root 39 19 0 0 0 S 0.0 0.0 0:00.03 khugepaged 28 root 0 -20 0 0 0 S 0.0 0.0 0:00.00 crypto 29 root 0 -20 0 0 0 S 0.0 0.0 0:00.00 kintegrityd 30 root 0 -20 0 0 0 S 0.0 0.0 0:00.00 bioset 31 root 0 -20 0 0 0 S 0.0 0.0 0:00.00 kblockd ... ... ... The other option is $ ps aux . This will give the command used to run the process (this can sometimes be more helpful). azureuser@miccai:~$ ps aux USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND root 1 0.2 0.1 35080 5100 ? Ss 18:46 0:04 /sbin/init root 2 0.0 0.0 0 0 ? S 18:46 0:00 [kthreadd] root 3 0.0 0.0 0 0 ? S 18:46 0:00 [ksoftirqd/0] root 5 0.0 0.0 0 0 ? S< 18:46 0:00 [kworker/0:0H] root 6 0.0 0.0 0 0 ? S 18:46 0:00 [kworker/u256:0] root 7 0.0 0.0 0 0 ? S 18:46 0:00 [rcu_sched] root 8 0.0 0.0 0 0 ? S 18:46 0:00 [rcu_bh] root 9 0.0 0.0 0 0 ? S 18:46 0:01 [rcuos/0] root 10 0.0 0.0 0 0 ? S 18:46 0:00 [rcuob/0] root 11 0.0 0.0 0 0 ? S 18:46 0:00 [migration/0] root 12 0.0 0.0 0 0 ? S 18:46 0:00 [watchdog/0] root 13 0.0 0.0 0 0 ? S 18:46 0:00 [watchdog/1] root 14 0.0 0.0 0 0 ? S 18:46 0:00 [migration/1] ... ... ... The advantage of using ps is that you can easily filter this list with the grep command. For example, to find a process associated with the term \"SCREEN\", you can use: azureuser@miccai:~$ ps aux | grep -i SCREEN azureus+ 1813 0.0 0.0 26104 2756 ? Ss 19:02 0:00 SCREEN -S mysql azureus+ 2058 0.0 0.0 8212 2148 pts/0 S+ 19:17 0:00 grep --color=auto -i SCREEN Thus, even when there are no \u201cvnstat\u201d related processes running, we would get one entry showing the grep process: azureuser@miccai:~$ ps aux | grep -i \"vnstat\" azureus+ 2070 0.0 0.0 8212 2212 pts/0 S+ 19:18 0:00 grep --color=auto -i vnstat Killing a process: There are various commands you can use to kill a process \u2014 kill , killall , pkill and top . We will begin from the simplest one: the killall command.","title":"Kill a process (TL;DR)"},{"location":"notes/bash/processes/#killall","text":"Killing processes with the killall command: The killall command is one of the easiest ways to kill a process. If you know the exact name of a process, and you know that it\u2019s not running as another user and it is not in the Z or D states, then you can use this command directly; there\u2019s no need to manually locate the process as we described above. By default, For example, to kill a process named \u201cfirefox\u201d, run: $ killall firefox To forcibly kill the process with SIGKILL , run: $ killall -9 firefox You can also use -SIGKILL instead of -9 . If you want to kill processes interactively, you can use -i like so: $ killall -i firefox If you want to kill a process running as a different user, you can use sudo : $ sudo killall firefox You can also kill a process that has been running for a certain period of time with the -o and -y flags. So, if you want to kill a process that has been running for more than 30 minutes, use: $ killall -o 30m <process-name> If you want to kill a process that has been running for less than 30 minutes, use: $ killall -y 30m <process-name> Similarly, use the following abbreviations for the respective units of time: s seconds m minutes h hours d days w weeks M months y years","title":"killall"},{"location":"notes/bash/processes/#pkill","text":"Killing processes with the pkill command Sometimes, you only know part of a program\u2019s name. Just like pgrep , pkill allows you to kill processes based on partial matches. For example, if you want to kill all processes containing the name apache in the name, run: pkill apache If you want to use a SIGKILL instead of a SIGTERM , use: pkill -9 apache Again, you can also use -SIGKILL instead of -9 .","title":"pkill"},{"location":"notes/bash/processes/#kill","text":"Killing processes with the kill command: Using the kill command is straightforward. Once you have found out the PID of the process that you want to kill , you can terminate it using the kill command. For example, if you want to kill a process having a PID of 1234, then use the following command: kill 1234 As we mentioned previously, the default is to use a SIGTERM . To use a SIGKILL , use -9 or -SIGKILL as we have seen before: kill -9 1234","title":"kill"},{"location":"notes/bash/processes/#using-top","text":"Killing processes with the top command: It is very easy to kill processes using the top command. First, search for the process that you want to kill and note the PID. Then, press k while top is running (this is case sensitive). It will prompt you to enter the PID of the process that you want to kill.","title":"Using top"},{"location":"notes/bash/screen/","text":"Screen Courtesy of linuxize.com and this video by Linux Leech . Basics: C-a means Control+a and seems to be the basis of most commands. C-a ? Means to press control+a and then the ? for help about other command for screen. Start a new screen with the word screen . Name a screen session with screen \u2013S secondscreen Rename Screen: To list running screen sessions, use screen -ls $screen -ls There is a screen on: 12129.testsession (Detached) 1 Socket in /var/run/screen/S-root. Yeah, here we go!! Renaming the screen session name testsession to something else. Here is the command to rename the existing session. Note: sessionname as used below is a command so it is always necessary $ screen -S 12129.testsession -X sessionname newname C-a d is to detach. Once you detach you can see all screens with screen \u2013ls Now connect to a screen... bbearce@bbearce-XPS-15-9560:~$ screen -ls There are screens on: 530.new_screen (05/28/2019 03:27:17 PM) (Detached) 370.pts-4.bbearce-XPS-15-9560 (05/28/2019 03:24:18 PM) (Detached) 2 Sockets in /var/run/screen/S-bbearce. Connect to either with the name of the screen or the PID (prefacing numbers {530, 370}) To get rid of a screen: bbearce@bbearce-XPS-15-9560:~$ screen -X -S 370 quit The \u2013X is for sending a command to a screen and \u2013S is to identify the name of the screen to send the command. The command is quit . Now use screen \u2013ls : bbearce@bbearce-XPS-15-9560:~$ screen -ls There is a screen on: 530.new_screen (05/28/2019 03:27:17 PM) (Detached) 1 Socket in /var/run/screen/S-bbearce. The other way to kill a screen is from within it. Keep in mind this is technically for windows and not screens, but will kill a screen if there is only 1 window C-a k This will prompt you for whether or not you are sure. (y/n) Now screen \u2013ls : bbearce@bbearce-XPS-15-9560:~$ screen -ls No Sockets found in /var/run/screen/S-bbearce. Windows: Once in a screen use C-a c to create a new window. C-a n is for next C-a p is for previous C-a w is for listing windows C-a \" is for showing a menu of windows Don't forget C-a k will kill a window and eventually the screen if there is only one window. If you make 4 screens and echo 0-3 in them, we can jump to each with these commands: C-a 0 will jump to the first window with echo 0 in in it C-a 1 will jump to the first window with echo 1 in in it C-a 2 will jump to the first window with echo 2 in in it C-a 3 will jump to the first window with echo 3 in in it C-a \" will show them all and notice they are all named bash. We can rename them to be more useful. Ex: Num Name 0 bash 1 bash 2 bash 3 bash If you press C-a A we can rename our windows. Notice what happens during C-a \" now after renaming: Ex: Num Name 0 bash 1 bash 2 window-2 3 bash Panes: C-a | will split the window vertically C-a S will split the window horizontally C-a tab to change panes C-a X to exit panes C-a x to lock the terminal\\screen - you will need a password to get back in. C-a t to to get the time and load on the system Tab over to a new pane that is empty and open a window with the general window commands. C-a X will close a pane as well as performing C-a : which will bring up a prompt starting with : . At the prompt type remove and press enter. This removes the pane as well. Run Commands with Screen: Use VI to make counter.py file as such: $ vi counter.py ...write the code below import time for i in range(5): print(time.ctime(time.time())) time.sleep(1) Now we can run this program in a screen but will kill the screen when complete $ screen -d -m counter.py You can see the screen momentarily before it quits by running screen \u2013r . Also we can run this in a screen and not have it automatically quit by connecting first. Problems There is no screen to be resumed matching <screen-name> azureuser@cbibop3:~$ screen -r codalab There is a screen on: 8967.codalab (10/18/2019 06:56:52 PM) (Attached) There is no screen to be resumed matching codalab. As screen -r says, there is one screen, but it is attached. To resume it on your current terminal, you have to detach it from the other one first: screen -d -r 8967 , see manpage -d . Edit: use -d instead of -x . Edit2: @alex78191: When using -x , screen attaches to the currently running session, resulting in a \"multi-display mode\": you see the session on both terminals simultaneously, i.e., when entering a command on one terminal, it also appears on the second. However, detaching from a multi-display mode just detaches the current terminal. You hence get the message that it is still attached (on the other terminal).","title":"Screen"},{"location":"notes/bash/screen/#screen","text":"Courtesy of linuxize.com and this video by Linux Leech .","title":"Screen"},{"location":"notes/bash/screen/#basics","text":"C-a means Control+a and seems to be the basis of most commands. C-a ? Means to press control+a and then the ? for help about other command for screen. Start a new screen with the word screen . Name a screen session with screen \u2013S secondscreen","title":"Basics:"},{"location":"notes/bash/screen/#rename-screen","text":"To list running screen sessions, use screen -ls $screen -ls There is a screen on: 12129.testsession (Detached) 1 Socket in /var/run/screen/S-root. Yeah, here we go!! Renaming the screen session name testsession to something else. Here is the command to rename the existing session. Note: sessionname as used below is a command so it is always necessary $ screen -S 12129.testsession -X sessionname newname C-a d is to detach. Once you detach you can see all screens with screen \u2013ls Now connect to a screen... bbearce@bbearce-XPS-15-9560:~$ screen -ls There are screens on: 530.new_screen (05/28/2019 03:27:17 PM) (Detached) 370.pts-4.bbearce-XPS-15-9560 (05/28/2019 03:24:18 PM) (Detached) 2 Sockets in /var/run/screen/S-bbearce. Connect to either with the name of the screen or the PID (prefacing numbers {530, 370})","title":"Rename Screen:"},{"location":"notes/bash/screen/#to-get-rid-of-a-screen","text":"bbearce@bbearce-XPS-15-9560:~$ screen -X -S 370 quit The \u2013X is for sending a command to a screen and \u2013S is to identify the name of the screen to send the command. The command is quit . Now use screen \u2013ls : bbearce@bbearce-XPS-15-9560:~$ screen -ls There is a screen on: 530.new_screen (05/28/2019 03:27:17 PM) (Detached) 1 Socket in /var/run/screen/S-bbearce. The other way to kill a screen is from within it. Keep in mind this is technically for windows and not screens, but will kill a screen if there is only 1 window C-a k This will prompt you for whether or not you are sure. (y/n) Now screen \u2013ls : bbearce@bbearce-XPS-15-9560:~$ screen -ls No Sockets found in /var/run/screen/S-bbearce.","title":"To get rid of a screen:"},{"location":"notes/bash/screen/#windows","text":"Once in a screen use C-a c to create a new window. C-a n is for next C-a p is for previous C-a w is for listing windows C-a \" is for showing a menu of windows Don't forget C-a k will kill a window and eventually the screen if there is only one window. If you make 4 screens and echo 0-3 in them, we can jump to each with these commands: C-a 0 will jump to the first window with echo 0 in in it C-a 1 will jump to the first window with echo 1 in in it C-a 2 will jump to the first window with echo 2 in in it C-a 3 will jump to the first window with echo 3 in in it C-a \" will show them all and notice they are all named bash. We can rename them to be more useful. Ex: Num Name 0 bash 1 bash 2 bash 3 bash If you press C-a A we can rename our windows. Notice what happens during C-a \" now after renaming: Ex: Num Name 0 bash 1 bash 2 window-2 3 bash","title":"Windows:"},{"location":"notes/bash/screen/#panes","text":"C-a | will split the window vertically C-a S will split the window horizontally C-a tab to change panes C-a X to exit panes C-a x to lock the terminal\\screen - you will need a password to get back in. C-a t to to get the time and load on the system Tab over to a new pane that is empty and open a window with the general window commands. C-a X will close a pane as well as performing C-a : which will bring up a prompt starting with : . At the prompt type remove and press enter. This removes the pane as well.","title":"Panes:"},{"location":"notes/bash/screen/#run-commands-with-screen","text":"Use VI to make counter.py file as such: $ vi counter.py ...write the code below import time for i in range(5): print(time.ctime(time.time())) time.sleep(1) Now we can run this program in a screen but will kill the screen when complete $ screen -d -m counter.py You can see the screen momentarily before it quits by running screen \u2013r . Also we can run this in a screen and not have it automatically quit by connecting first.","title":"Run Commands with Screen:"},{"location":"notes/bash/screen/#problems","text":"There is no screen to be resumed matching <screen-name> azureuser@cbibop3:~$ screen -r codalab There is a screen on: 8967.codalab (10/18/2019 06:56:52 PM) (Attached) There is no screen to be resumed matching codalab. As screen -r says, there is one screen, but it is attached. To resume it on your current terminal, you have to detach it from the other one first: screen -d -r 8967 , see manpage -d . Edit: use -d instead of -x . Edit2: @alex78191: When using -x , screen attaches to the currently running session, resulting in a \"multi-display mode\": you see the session on both terminals simultaneously, i.e., when entering a command on one terminal, it also appears on the second. However, detaching from a multi-display mode just detaches the current terminal. You hence get the message that it is still attached (on the other terminal).","title":"Problems"},{"location":"notes/bash/ssh/","text":"SSH Useage $ ssh <username>@<host-ip> Keys Courtesty of stackexchange Generating a Key Pair the Proper way On Local server ssh-keygen -t rsa On remote Server ssh root@remote_servers_ip \"mkdir -p .ssh\" Uploading Generated Public Keys to the Remote Server cat ~/.ssh/id_rsa.pub | ssh root@remote_servers_ip \"cat >> ~/.ssh/authorized_keys\" Set Permissions on Remote server ssh root@remote_servers_ip \"chmod 700 ~/.ssh; chmod 640 ~/.ssh/authorized_keys\" Login ssh root@remote_servers_ip Enabling SSH Protocol v2 uncomment \"Protocol 2\" in /etc/ssh/sshd_config Enabling public key authorization in sshd uncomment \"PubkeyAuthentication yes\" in /etc/ssh/sshd_config If StrictModes is set to yes in /etc/ssh/sshd_config then restorecon -Rv ~/.ssh","title":"SSH"},{"location":"notes/bash/ssh/#ssh","text":"","title":"SSH"},{"location":"notes/bash/ssh/#useage","text":"$ ssh <username>@<host-ip>","title":"Useage"},{"location":"notes/bash/ssh/#keys","text":"Courtesty of stackexchange Generating a Key Pair the Proper way On Local server ssh-keygen -t rsa On remote Server ssh root@remote_servers_ip \"mkdir -p .ssh\" Uploading Generated Public Keys to the Remote Server cat ~/.ssh/id_rsa.pub | ssh root@remote_servers_ip \"cat >> ~/.ssh/authorized_keys\" Set Permissions on Remote server ssh root@remote_servers_ip \"chmod 700 ~/.ssh; chmod 640 ~/.ssh/authorized_keys\" Login ssh root@remote_servers_ip Enabling SSH Protocol v2 uncomment \"Protocol 2\" in /etc/ssh/sshd_config Enabling public key authorization in sshd uncomment \"PubkeyAuthentication yes\" in /etc/ssh/sshd_config If StrictModes is set to yes in /etc/ssh/sshd_config then restorecon -Rv ~/.ssh","title":"Keys"},{"location":"notes/bash/startup/","text":"Run On Startup Proper instructions aren't working so I made a run.sh script that I can run from /home/bbearce #!/bin/bash ### BB - 01/11/2020 - Add startup commands here ### # Mounting via sshfs if [ \"$1\" == mount ]; then sshfs bbearce@medici-codalab-master.eastus.cloudapp.azure.com:/home/bbearce/src/MedICI/codalab-competitions /home/bbearce/mounts/medici; sshfs azureuser@cbibop3.cloudapp.net:/home/azureuser/codalab-competitions /home/bbearce/mounts/cbibop3; # Postgres and pgAdmin elif [ \"$1\" == postgres ]; then cd /home/bbearce/pgAdmin4/pgAdmin4; . bin/activate; python lib/python2.7/site-packages/pgadmin4/pgAdmin4.py; elif [ \"$1\" == code-journal ]; then cd /home/bbearce/Documents/code-journal; . venv/bin/activate; mkdocs serve; elif [ \"$1\" == github_key ] || [ \"$1\" == gk ]; then # add github ssh key to agent eval \"$(ssh-agent -s)\"; ssh-add ~/.ssh/github; elif [ \"$1\" == thegratefulbrauer ] || [ \"$1\" == tgb ]; then cd /home/bbearce/Documents/thegratefulbrauer; . venv3.6/bin/activate; python app.py; else echo \"not sure what you want...\" fi ### BB - Add startup commands here ### Courtesy of ghacks Find file /etc/rc.local . You can place scripts that you want to run at startup. /etc/rc.local #!/bin/sh -e # # rc.local # # This script is executed at the end of each multiuser runlevel. # Make sure that the script will \"exit 0\" on success or any other # value on error. # # In order to enable or disable this script just change the execution # bits. # # By default this script does nothing. ### BB - 01/11/2020 - Add startup commands here ### # Mounting via sshfs sshfs bbearce@medici-codalab-master.eastus.cloudapp.azure.com:/home/bbearce/src/MedICI/codalab-competitions /home/bbearce/mounts/medici; sshfs azureuser@cbibop3.cloudapp.net:/home/azureuser/codalab-competitions /home/bbearce/mounts/cbibop3; # add github ssh key to agent eval \"$(ssh-agent -s)\"; ssh-add ~/.ssh/github; ### BB - Add startup commands here ### exit 0","title":"On Startup"},{"location":"notes/bash/startup/#run-on-startup","text":"Proper instructions aren't working so I made a run.sh script that I can run from /home/bbearce #!/bin/bash ### BB - 01/11/2020 - Add startup commands here ### # Mounting via sshfs if [ \"$1\" == mount ]; then sshfs bbearce@medici-codalab-master.eastus.cloudapp.azure.com:/home/bbearce/src/MedICI/codalab-competitions /home/bbearce/mounts/medici; sshfs azureuser@cbibop3.cloudapp.net:/home/azureuser/codalab-competitions /home/bbearce/mounts/cbibop3; # Postgres and pgAdmin elif [ \"$1\" == postgres ]; then cd /home/bbearce/pgAdmin4/pgAdmin4; . bin/activate; python lib/python2.7/site-packages/pgadmin4/pgAdmin4.py; elif [ \"$1\" == code-journal ]; then cd /home/bbearce/Documents/code-journal; . venv/bin/activate; mkdocs serve; elif [ \"$1\" == github_key ] || [ \"$1\" == gk ]; then # add github ssh key to agent eval \"$(ssh-agent -s)\"; ssh-add ~/.ssh/github; elif [ \"$1\" == thegratefulbrauer ] || [ \"$1\" == tgb ]; then cd /home/bbearce/Documents/thegratefulbrauer; . venv3.6/bin/activate; python app.py; else echo \"not sure what you want...\" fi ### BB - Add startup commands here ### Courtesy of ghacks Find file /etc/rc.local . You can place scripts that you want to run at startup. /etc/rc.local #!/bin/sh -e # # rc.local # # This script is executed at the end of each multiuser runlevel. # Make sure that the script will \"exit 0\" on success or any other # value on error. # # In order to enable or disable this script just change the execution # bits. # # By default this script does nothing. ### BB - 01/11/2020 - Add startup commands here ### # Mounting via sshfs sshfs bbearce@medici-codalab-master.eastus.cloudapp.azure.com:/home/bbearce/src/MedICI/codalab-competitions /home/bbearce/mounts/medici; sshfs azureuser@cbibop3.cloudapp.net:/home/azureuser/codalab-competitions /home/bbearce/mounts/cbibop3; # add github ssh key to agent eval \"$(ssh-agent -s)\"; ssh-add ~/.ssh/github; ### BB - Add startup commands here ### exit 0","title":"Run On Startup"},{"location":"notes/bash/users/","text":"Users Courtesy of cyberciti.biz Introduction : By default, the cloud server comes with a user named ubuntu . You can use such primary user account for sysadmin tasks on Ubuntu. However, sometimes you need to add a user account on Ubuntu for additional sysadmin tasks. This page shows how to create a regular user account or sysadmin account on the Ubuntu server. $ adduser Steps to create a user account on Ubuntu Linux 1. Open the terminal application 2. Log in to remote box by running the ssh user@your-ubuntu-box-ip 3. To add a new user in Ubuntu run sudo adduser userNameHere 4. Enter password and other needed info to create a user account on Ubuntu server 5. New username would be added to /etc/passwd file, and encrypted password stored in the /etc/shadow file Example bbearce@bbearce-XPS-15-9560:~$ sudo adduser vivek [sudo] password for bbearce: Adding user `vivek' ... Adding new group `vivek' (1001) ... Adding new user `vivek' (1001) with group `vivek' ... Creating home directory `/home/vivek' ... Copying files from `/etc/skel' ... Enter new UNIX password: Retype new UNIX password: passwd: password updated successfully Changing the user information for vivek Enter the new value, or press ENTER for the default Full Name []: Room Number []: Work Phone []: Home Phone []: Other []: Is the information correct? [Y/n] y Verification Use the grep command or cat command as follows: $ cat /etc/passwd . . . vivek:x:1001:1001:,,,:/home/vivek:/bin/bash or $ grep '^vivek' /etc/passwd vivek:x:1001:1001:,,,:/home/vivek:/bin/bash $ userdel Remove the user Log in to your server via SSH. Switch to the root user: $ sudo su - Use the userdel command to remove the old user: $ userdel <user's username> Optional: You can also delete that user's home directory and mail spool by using the -r flag with the command: $ userdel -r user's username Warning: Only delete a user's home directory if you are certain you no longer need their files or mail.","title":"Users"},{"location":"notes/bash/users/#users","text":"Courtesy of cyberciti.biz Introduction : By default, the cloud server comes with a user named ubuntu . You can use such primary user account for sysadmin tasks on Ubuntu. However, sometimes you need to add a user account on Ubuntu for additional sysadmin tasks. This page shows how to create a regular user account or sysadmin account on the Ubuntu server.","title":"Users"},{"location":"notes/bash/users/#adduser","text":"Steps to create a user account on Ubuntu Linux 1. Open the terminal application 2. Log in to remote box by running the ssh user@your-ubuntu-box-ip 3. To add a new user in Ubuntu run sudo adduser userNameHere 4. Enter password and other needed info to create a user account on Ubuntu server 5. New username would be added to /etc/passwd file, and encrypted password stored in the /etc/shadow file","title":"$ adduser"},{"location":"notes/bash/users/#example","text":"bbearce@bbearce-XPS-15-9560:~$ sudo adduser vivek [sudo] password for bbearce: Adding user `vivek' ... Adding new group `vivek' (1001) ... Adding new user `vivek' (1001) with group `vivek' ... Creating home directory `/home/vivek' ... Copying files from `/etc/skel' ... Enter new UNIX password: Retype new UNIX password: passwd: password updated successfully Changing the user information for vivek Enter the new value, or press ENTER for the default Full Name []: Room Number []: Work Phone []: Home Phone []: Other []: Is the information correct? [Y/n] y","title":"Example"},{"location":"notes/bash/users/#verification","text":"Use the grep command or cat command as follows: $ cat /etc/passwd . . . vivek:x:1001:1001:,,,:/home/vivek:/bin/bash or $ grep '^vivek' /etc/passwd vivek:x:1001:1001:,,,:/home/vivek:/bin/bash","title":"Verification"},{"location":"notes/bash/users/#userdel","text":"","title":"$ userdel"},{"location":"notes/bash/users/#remove-the-user","text":"Log in to your server via SSH. Switch to the root user: $ sudo su - Use the userdel command to remove the old user: $ userdel <user's username> Optional: You can also delete that user's home directory and mail spool by using the -r flag with the command: $ userdel -r user's username Warning: Only delete a user's home directory if you are certain you no longer need their files or mail.","title":"Remove the user"},{"location":"notes/bash/vi/","text":"VI","title":"VI"},{"location":"notes/bash/vi/#vi","text":"","title":"VI"},{"location":"notes/bash/zip_and_unzip/","text":"Zipping and Unzipping zip, unzip Courtesty of geeksforgeeks.org zip $ man zip NAME zip - package and compress (archive) files . . . To zip files into a .zip file run this command: bbearce@bbearce-XPS-15-9560:~/Desktop$ ls something.txt wheel.py bbearce@bbearce-XPS-15-9560:~/Desktop$ zip example.zip wheel.py something.txt adding: wheel.py (deflated 79%) adding: something.txt (stored 0%) bbearce@bbearce-XPS-15-9560:~/Desktop$ ls example.zip something.txt wheel.py To zip eveything in a directory into zip file use ./* This is useful for pointing to <some directory>/* bbearce@bbearce-XPS-15-9560:~/Desktop$ ls something.txt wheel.py bbearce@bbearce-XPS-15-9560:~/Desktop$ zip example.zip ./* adding: something.txt (stored 0%) adding: wheel.py (deflated 79%) bbearce@bbearce-XPS-15-9560:~/Desktop$ ls example.zip something.txt wheel.py Folders will be picked up but not their contents without -r : bbearce@bbearce-XPS-15-9560:~/Desktop$ ls directory something.txt wheel.py bbearce@bbearce-XPS-15-9560:~/Desktop$ ls directory/ test.txt bbearce@bbearce-XPS-15-9560:~/Desktop$ zip example.zip ./* adding: directory/ (stored 0%) adding: something.txt (stored 0%) adding: wheel.py (deflated 79%) bbearce@bbearce-XPS-15-9560:~/Desktop$ zip -r example.zip ./* updating: directory/ (stored 0%) updating: something.txt (stored 0%) updating: wheel.py (deflated 79%) adding: directory/test.txt (stored 0%) Notice how zipping to example.zip again updates pre-existing files and adds new ones. unzip $ man unzip NAME unzip - list, test and extract compressed files in a ZIP archive . . . To unzip simply use the unzip command: bbearce@bbearce-XPS-15-9560:~/Desktop$ ls example.zip bbearce@bbearce-XPS-15-9560:~/Desktop$ unzip example.zip Archive: example.zip creating: directory/ extracting: something.txt inflating: wheel.py extracting: directory/test.txt bbearce@bbearce-XPS-15-9560:~/Desktop$ ls directory example.zip something.txt wheel.py We can unzip to a specific directory with the -d flag: bbearce@bbearce-XPS-15-9560:~/Desktop$ ls example.zip bbearce@bbearce-XPS-15-9560:~/Desktop$ unzip example.zip -d test Archive: example.zip creating: test/directory/ extracting: test/something.txt inflating: test/wheel.py extracting: test/directory/test.txt bbearce@bbearce-XPS-15-9560:~/Desktop$ ls example.zip test bbearce@bbearce-XPS-15-9560:~/Desktop$ ls test directory something.txt wheel.py If the directory already exists, we can dump the contents into it: bbearce@bbearce-XPS-15-9560:~/Desktop$ ls example.zip bbearce@bbearce-XPS-15-9560:~/Desktop$ mkdir test bbearce@bbearce-XPS-15-9560:~/Desktop$ ls example.zip test bbearce@bbearce-XPS-15-9560:~/Desktop$ unzip example.zip -d test Archive: example.zip creating: test/directory/ extracting: test/something.txt inflating: test/wheel.py extracting: test/directory/test.txt bbearce@bbearce-XPS-15-9560:~/Desktop$ ls example.zip test bbearce@bbearce-XPS-15-9560:~/Desktop$ ls test directory something.txt wheel.py Tar Files .tar The tar command is used to create tar archives by converting a group of files into an archive. It supports a vast range of compression programs such as gzip , bzip2 , lzip , lzma , lzop , xz and compress . Tar was originally designed for creating archives to store files on magnetic tape which is why it has its name \u201c T ape AR chive\u201d. Create a .tar bbearce@bbearce-XPS-15-9560:~/Desktop$ ls test.txt bbearce@bbearce-XPS-15-9560:~/Desktop$ tar -cvf test.tar test.txt test.txt bbearce@bbearce-XPS-15-9560:~/Desktop$ ls test.tar test.txt Here -cvf means c: create; v: verbose; f: use archive file or device (we can and did specify a filename to use) . Keep in mind we didn't use the -z flag which would make a gzip . .tar.gz .tar.gz files are just files that have been zipped with -z to make a gzip. Let's redo the above example with -z : bbearce@bbearce-XPS-15-9560:~/Desktop$ ls test.txt bbearce@bbearce-XPS-15-9560:~/Desktop$ tar -cvzf test.tar test.txt test.txt bbearce@bbearce-XPS-15-9560:~/Desktop$ ls test.tar test.txt Note that the archive name test.tar is a .tar.gz but you have to specify that explicitly. So a canonical way of diong this is: tar -cvzf test.tar.gz test.txt . Also the [-] is optional, so tar cvzf test.tar.gz test.txt would work too. We can see that the .tar.gz is smaller with du bbearce@bbearce-XPS-15-9560:~/Desktop$ du -BK ./* 20K ./test.tar 4K ./test.tar.gz 12K ./test.txt Unzip a .tar We need the -x option: bbearce@bbearce-XPS-15-9560:~/Desktop$ ls test.tar bbearce@bbearce-XPS-15-9560:~/Desktop$ tar -xvf test.tar test.txt bbearce@bbearce-XPS-15-9560:~/Desktop$ ls test.tar test.txt When downloading 3DSlicer you get a *.tar.gz file. This command installs it. tar zxvf Slicer-4.8.1-linux-amd64.tar.gz FYI: ( Link )","title":"Zip and Unzip"},{"location":"notes/bash/zip_and_unzip/#zipping-and-unzipping","text":"","title":"Zipping and Unzipping"},{"location":"notes/bash/zip_and_unzip/#zip-unzip","text":"Courtesty of geeksforgeeks.org","title":"zip, unzip"},{"location":"notes/bash/zip_and_unzip/#zip","text":"$ man zip NAME zip - package and compress (archive) files . . . To zip files into a .zip file run this command: bbearce@bbearce-XPS-15-9560:~/Desktop$ ls something.txt wheel.py bbearce@bbearce-XPS-15-9560:~/Desktop$ zip example.zip wheel.py something.txt adding: wheel.py (deflated 79%) adding: something.txt (stored 0%) bbearce@bbearce-XPS-15-9560:~/Desktop$ ls example.zip something.txt wheel.py To zip eveything in a directory into zip file use ./* This is useful for pointing to <some directory>/* bbearce@bbearce-XPS-15-9560:~/Desktop$ ls something.txt wheel.py bbearce@bbearce-XPS-15-9560:~/Desktop$ zip example.zip ./* adding: something.txt (stored 0%) adding: wheel.py (deflated 79%) bbearce@bbearce-XPS-15-9560:~/Desktop$ ls example.zip something.txt wheel.py Folders will be picked up but not their contents without -r : bbearce@bbearce-XPS-15-9560:~/Desktop$ ls directory something.txt wheel.py bbearce@bbearce-XPS-15-9560:~/Desktop$ ls directory/ test.txt bbearce@bbearce-XPS-15-9560:~/Desktop$ zip example.zip ./* adding: directory/ (stored 0%) adding: something.txt (stored 0%) adding: wheel.py (deflated 79%) bbearce@bbearce-XPS-15-9560:~/Desktop$ zip -r example.zip ./* updating: directory/ (stored 0%) updating: something.txt (stored 0%) updating: wheel.py (deflated 79%) adding: directory/test.txt (stored 0%) Notice how zipping to example.zip again updates pre-existing files and adds new ones.","title":"zip"},{"location":"notes/bash/zip_and_unzip/#unzip","text":"$ man unzip NAME unzip - list, test and extract compressed files in a ZIP archive . . . To unzip simply use the unzip command: bbearce@bbearce-XPS-15-9560:~/Desktop$ ls example.zip bbearce@bbearce-XPS-15-9560:~/Desktop$ unzip example.zip Archive: example.zip creating: directory/ extracting: something.txt inflating: wheel.py extracting: directory/test.txt bbearce@bbearce-XPS-15-9560:~/Desktop$ ls directory example.zip something.txt wheel.py We can unzip to a specific directory with the -d flag: bbearce@bbearce-XPS-15-9560:~/Desktop$ ls example.zip bbearce@bbearce-XPS-15-9560:~/Desktop$ unzip example.zip -d test Archive: example.zip creating: test/directory/ extracting: test/something.txt inflating: test/wheel.py extracting: test/directory/test.txt bbearce@bbearce-XPS-15-9560:~/Desktop$ ls example.zip test bbearce@bbearce-XPS-15-9560:~/Desktop$ ls test directory something.txt wheel.py If the directory already exists, we can dump the contents into it: bbearce@bbearce-XPS-15-9560:~/Desktop$ ls example.zip bbearce@bbearce-XPS-15-9560:~/Desktop$ mkdir test bbearce@bbearce-XPS-15-9560:~/Desktop$ ls example.zip test bbearce@bbearce-XPS-15-9560:~/Desktop$ unzip example.zip -d test Archive: example.zip creating: test/directory/ extracting: test/something.txt inflating: test/wheel.py extracting: test/directory/test.txt bbearce@bbearce-XPS-15-9560:~/Desktop$ ls example.zip test bbearce@bbearce-XPS-15-9560:~/Desktop$ ls test directory something.txt wheel.py","title":"unzip"},{"location":"notes/bash/zip_and_unzip/#tar-files","text":"","title":"Tar Files"},{"location":"notes/bash/zip_and_unzip/#tar","text":"The tar command is used to create tar archives by converting a group of files into an archive. It supports a vast range of compression programs such as gzip , bzip2 , lzip , lzma , lzop , xz and compress . Tar was originally designed for creating archives to store files on magnetic tape which is why it has its name \u201c T ape AR chive\u201d.","title":".tar"},{"location":"notes/bash/zip_and_unzip/#create-a-tar","text":"bbearce@bbearce-XPS-15-9560:~/Desktop$ ls test.txt bbearce@bbearce-XPS-15-9560:~/Desktop$ tar -cvf test.tar test.txt test.txt bbearce@bbearce-XPS-15-9560:~/Desktop$ ls test.tar test.txt Here -cvf means c: create; v: verbose; f: use archive file or device (we can and did specify a filename to use) . Keep in mind we didn't use the -z flag which would make a gzip .","title":"Create a .tar"},{"location":"notes/bash/zip_and_unzip/#targz","text":".tar.gz files are just files that have been zipped with -z to make a gzip. Let's redo the above example with -z : bbearce@bbearce-XPS-15-9560:~/Desktop$ ls test.txt bbearce@bbearce-XPS-15-9560:~/Desktop$ tar -cvzf test.tar test.txt test.txt bbearce@bbearce-XPS-15-9560:~/Desktop$ ls test.tar test.txt Note that the archive name test.tar is a .tar.gz but you have to specify that explicitly. So a canonical way of diong this is: tar -cvzf test.tar.gz test.txt . Also the [-] is optional, so tar cvzf test.tar.gz test.txt would work too. We can see that the .tar.gz is smaller with du bbearce@bbearce-XPS-15-9560:~/Desktop$ du -BK ./* 20K ./test.tar 4K ./test.tar.gz 12K ./test.txt","title":".tar.gz"},{"location":"notes/bash/zip_and_unzip/#unzip-a-tar","text":"We need the -x option: bbearce@bbearce-XPS-15-9560:~/Desktop$ ls test.tar bbearce@bbearce-XPS-15-9560:~/Desktop$ tar -xvf test.tar test.txt bbearce@bbearce-XPS-15-9560:~/Desktop$ ls test.tar test.txt When downloading 3DSlicer you get a *.tar.gz file. This command installs it. tar zxvf Slicer-4.8.1-linux-amd64.tar.gz FYI: ( Link )","title":"Unzip a .tar"},{"location":"notes/docker/basics/","text":"Docker Install Docker has good documentation here . Recap and cheat sheet: List Docker CLI commands docker docker container --help Display Docker version and info docker --version docker version docker info Execute Docker image docker run hello-world List Docker images docker image ls docker image ls --all docker image ls -aq List Docker containers (running, all, all in quiet mode) docker container ls docker container ls --all docker container ls \u2013aq List Docker services docker service ls docker stack services getstartedlab Tasks Note the addition of '_web' to the service name docker service ps getstartedlab_web Note: container ls will show you the tasks running as well docker container ls Run without sudo To create the docker group and add your user: Create the docker group: $ sudo groupadd docker Add your user to the docker group. $ sudo usermod -aG docker $USER Log out and log back in so that your group membership is re-evaluated. If testing on a virtual machine, it may be necessary to restart the virtual machine for changes to take effect. On a desktop Linux environment such as X Windows, log out of your session completely and then log back in. On Linux, you can also run the following command to activate the changes to groups: $ newgrp docker Verify that you can run docker commands without sudo. $ docker run hello-world Useful Commands Use docker container inspect 4ca8ce46f817 to inspect a container. You will get a json dump of characteristics that are super useful. Example: [ { \"Id\": \"4ca8ce46f8170fc5c5eeb93bc27e8f84c2e8b32ddafc8e748a124e24fc8ff455\", \"Created\": \"2019-09-26T19:10:42.524604801Z\", \"Path\": \"python\", \"Args\": [ \"predict.py\" ], \"State\": { \"Status\": \"exited\", \"Running\": false, \"Paused\": false, \"Restarting\": false, \"OOMKilled\": false, \"Dead\": false, \"Pid\": 0, \"ExitCode\": 0, \"Error\": \"\", \"StartedAt\": \"2019-09-26T19:10:43.536396229Z\", \"FinishedAt\": \"2019-09-27T01:41:30.393256193Z\" . . .there is a lot more. Useful Flags -v|--volume[=[[HOST-DIR:]CONTAINER-DIR[:OPTIONS]]] Create a bind mount. If you specify, -v /HOST-DIR:/CONTAINER-DIR, Docker bind mounts /HOST-DIR in the host to /CONTAINER-DIR in the Docker container. If 'HOST-DIR' is omitted, Docker automatically creates the new volume on the host. The OPTIONS are a comma delimited list and can be: \u00b7 [rw|ro] \u00b7 [z|Z] \u00b7 [[r]shared|[r]slave|[r]private] \u00b7 [delegated|cached|consistent] \u00b7 [nocopy] -d, --detach=true|false Detached mode: run the container in the background and print the new container ID. The default is false. -i, --interactive=true|false Keep STDIN open even if not attached. The default is false. When set to true, keep stdin open even if not attached. -t, --tty=true|false Allocate a pseudo-TTY. The default is false. When set to true Docker can allocate a pseudo-tty and attach to the standard input of any container. This can be used, for example, to run a throwaway interactive shell. The default is false. The -t option is incompatible with a redirection of the docker client standard input. --name=\" \" Assign a name to the container The operator can identify a container in three ways: \u2502Identifier type \u2502 Example value \u2502 \u2502UUID long identifier \u2502 \"f78375b1c487e03c9438c729345e54db9d20cfa2ac1fc3494b6eb60872e74778\" \u2502 \u2502UUID short identifier \u2502 \"f78375b1c487\"\u2502 \u2502Name \u2502 \"evil_ptolemy\"| --restart=\" \" To configure the restart policy for a container, use the --restart flag when using the docker run command. The value of the --restart flag can be any of the following: Flag Description no Do not automatically restart the container. (the default) on-failure Restart the container if it exits due to an error, which manifests as a non-zero exit code. always Always restart the container if it stops. If it is manually stopped, it is restarted only when Docker daemon restarts or the container itself is manually restarted. (See the second bullet listed in restart policy details ) unless-stopped Similar to always , except that when the container is stopped (manually or otherwise), it is not restarted even after Docker daemon restarts. Managing and Removing Good discussion Summary docker build -t friendlyhello . # Create image using this directory's Dockerfile docker run -d -p 4000:80 friendlyhello # Same thing, but in detached mode docker container ls # List all running containers docker container ls -a # List all containers, even those not running docker container stop <hash> # Gracefully stop the specified container docker container kill <hash> # Force shutdown of the specified container docker container rm <hash> # Remove specified container from this machine docker container rm $(docker container ls -a -q) # Remove all containers docker image ls -a # List all images on this machine docker image rm <image id> # Remove specified image from this machine docker image rm $(docker image ls -a -q) # Remove all images from this machine docker login # Log in this CLI session using your Docker credentials docker tag <image> username/repository:tag # Tag <image> for upload to registry docker push username/repository:tag # Upload tagged image to registry docker run username/repository:tag # Run image from a registry Investigating and playing around DockerHub: Image specifications: Account: bbearce Repo: Nomenclature: bbearce/ : To start with a clean slate: Stop all containers: docker container rm $(docker container ls -a -q) # Remove all containers docker image rm $(docker image ls -a -q) # Remove all images from this machine If you want to run an instance of an image issue this command(this will download it if you don't have the image): docker run -it -d ashok/pyashokproj bin/bash Keep in mind this is different than getting inside a running container. For this to work the container needs to be already running: docker exec -it <container-name/ID> bash Some dockers can be started and stopped indefinitely either because they are a web server or an OS image(Ubuntu). Others based on things like pythonX.X can't be started up once stopped. A lot of customization and investigation can only really be done inside the running docker. So in order to get in we need to one of two things depending on the docker: OS or web server type docker: Use docker container \u2013ls a to find the stopped container id. Next use docker start <container id> to start the container again. Now use docker ps to see that it is running Python or language image: If you attempt to start the stopped container it will run for a brief second like it already did upon instantiation and then stop. We have to explicitly use docker run -it -d <image> bin/bash . This needs all of those flags (itd) in order to start a container in an interactive session, pipe the terminal from the docker to your local terminal and to run in detached mode. Now that it is running indefinitely we can run docker exec -it <container-name/ID> bash and actually connect to it. Start a docker container: docker start <container-name/ID> Stop a docker container: docker stop <container-name/ID> Take a container and make a new image from it (Example): docker run -itd codalab/codalab-legacy bash Note: Don't forget the -d This downloads a new image and starts an instance. It doesn't have the python package 'seaborn' installed in the python so we are going to add it. We started a container and it is running in detached mode. Now let's connect to it. Use docker ps to get the container's id: docker exec -it d7ef724c4309 bash You should be looking at the prompt: root@f907b9e5d9a6:/# Follow these instructions root@f907b9e5d9a6:/# pip install seaborn ...python is importing stuff... root@f907b9e5d9a6:/# python >>> import seaborn >>> You can see we installed seaborn. Now exit the docker root@f907b9e5d9a6:/# exit . We need to build it to an image: docker commit d7ef724c4309 bbearce/codalab:legacy We just made an image and tagged it with this identifier bbearce/codalab:legacy and we can see it if we execute: $ docker images REPOSITORY TAG IMAGE ID CREATED SIZE bbearce/codalab legacy c2d04ddb825a 3 seconds ago 2.65GB codalab/codalab-legacy latest 432ce2829707 20 months ago 2.64GB Now let's push it online (Docker Hub) as an optional last step: docker login docker push bbearce/codalab:legacy Another way to share is with: docker save docker load save/load docs","title":"Basics"},{"location":"notes/docker/basics/#docker","text":"","title":"Docker"},{"location":"notes/docker/basics/#install","text":"Docker has good documentation here . Recap and cheat sheet: List Docker CLI commands docker docker container --help Display Docker version and info docker --version docker version docker info Execute Docker image docker run hello-world List Docker images docker image ls docker image ls --all docker image ls -aq List Docker containers (running, all, all in quiet mode) docker container ls docker container ls --all docker container ls \u2013aq List Docker services docker service ls docker stack services getstartedlab Tasks Note the addition of '_web' to the service name docker service ps getstartedlab_web Note: container ls will show you the tasks running as well docker container ls","title":"Install"},{"location":"notes/docker/basics/#run-without-sudo","text":"To create the docker group and add your user: Create the docker group: $ sudo groupadd docker Add your user to the docker group. $ sudo usermod -aG docker $USER Log out and log back in so that your group membership is re-evaluated. If testing on a virtual machine, it may be necessary to restart the virtual machine for changes to take effect. On a desktop Linux environment such as X Windows, log out of your session completely and then log back in. On Linux, you can also run the following command to activate the changes to groups: $ newgrp docker Verify that you can run docker commands without sudo. $ docker run hello-world","title":"Run without sudo"},{"location":"notes/docker/basics/#useful-commands","text":"Use docker container inspect 4ca8ce46f817 to inspect a container. You will get a json dump of characteristics that are super useful. Example: [ { \"Id\": \"4ca8ce46f8170fc5c5eeb93bc27e8f84c2e8b32ddafc8e748a124e24fc8ff455\", \"Created\": \"2019-09-26T19:10:42.524604801Z\", \"Path\": \"python\", \"Args\": [ \"predict.py\" ], \"State\": { \"Status\": \"exited\", \"Running\": false, \"Paused\": false, \"Restarting\": false, \"OOMKilled\": false, \"Dead\": false, \"Pid\": 0, \"ExitCode\": 0, \"Error\": \"\", \"StartedAt\": \"2019-09-26T19:10:43.536396229Z\", \"FinishedAt\": \"2019-09-27T01:41:30.393256193Z\" . . .there is a lot more.","title":"Useful Commands"},{"location":"notes/docker/basics/#useful-flags","text":"-v|--volume[=[[HOST-DIR:]CONTAINER-DIR[:OPTIONS]]] Create a bind mount. If you specify, -v /HOST-DIR:/CONTAINER-DIR, Docker bind mounts /HOST-DIR in the host to /CONTAINER-DIR in the Docker container. If 'HOST-DIR' is omitted, Docker automatically creates the new volume on the host. The OPTIONS are a comma delimited list and can be: \u00b7 [rw|ro] \u00b7 [z|Z] \u00b7 [[r]shared|[r]slave|[r]private] \u00b7 [delegated|cached|consistent] \u00b7 [nocopy] -d, --detach=true|false Detached mode: run the container in the background and print the new container ID. The default is false. -i, --interactive=true|false Keep STDIN open even if not attached. The default is false. When set to true, keep stdin open even if not attached. -t, --tty=true|false Allocate a pseudo-TTY. The default is false. When set to true Docker can allocate a pseudo-tty and attach to the standard input of any container. This can be used, for example, to run a throwaway interactive shell. The default is false. The -t option is incompatible with a redirection of the docker client standard input. --name=\" \" Assign a name to the container The operator can identify a container in three ways: \u2502Identifier type \u2502 Example value \u2502 \u2502UUID long identifier \u2502 \"f78375b1c487e03c9438c729345e54db9d20cfa2ac1fc3494b6eb60872e74778\" \u2502 \u2502UUID short identifier \u2502 \"f78375b1c487\"\u2502 \u2502Name \u2502 \"evil_ptolemy\"| --restart=\" \" To configure the restart policy for a container, use the --restart flag when using the docker run command. The value of the --restart flag can be any of the following: Flag Description no Do not automatically restart the container. (the default) on-failure Restart the container if it exits due to an error, which manifests as a non-zero exit code. always Always restart the container if it stops. If it is manually stopped, it is restarted only when Docker daemon restarts or the container itself is manually restarted. (See the second bullet listed in restart policy details ) unless-stopped Similar to always , except that when the container is stopped (manually or otherwise), it is not restarted even after Docker daemon restarts.","title":"Useful Flags"},{"location":"notes/docker/basics/#managing-and-removing","text":"Good discussion Summary docker build -t friendlyhello . # Create image using this directory's Dockerfile docker run -d -p 4000:80 friendlyhello # Same thing, but in detached mode docker container ls # List all running containers docker container ls -a # List all containers, even those not running docker container stop <hash> # Gracefully stop the specified container docker container kill <hash> # Force shutdown of the specified container docker container rm <hash> # Remove specified container from this machine docker container rm $(docker container ls -a -q) # Remove all containers docker image ls -a # List all images on this machine docker image rm <image id> # Remove specified image from this machine docker image rm $(docker image ls -a -q) # Remove all images from this machine docker login # Log in this CLI session using your Docker credentials docker tag <image> username/repository:tag # Tag <image> for upload to registry docker push username/repository:tag # Upload tagged image to registry docker run username/repository:tag # Run image from a registry","title":"Managing and Removing"},{"location":"notes/docker/basics/#investigating-and-playing-around","text":"DockerHub: Image specifications: Account: bbearce Repo: Nomenclature: bbearce/ : To start with a clean slate: Stop all containers: docker container rm $(docker container ls -a -q) # Remove all containers docker image rm $(docker image ls -a -q) # Remove all images from this machine If you want to run an instance of an image issue this command(this will download it if you don't have the image): docker run -it -d ashok/pyashokproj bin/bash Keep in mind this is different than getting inside a running container. For this to work the container needs to be already running: docker exec -it <container-name/ID> bash Some dockers can be started and stopped indefinitely either because they are a web server or an OS image(Ubuntu). Others based on things like pythonX.X can't be started up once stopped. A lot of customization and investigation can only really be done inside the running docker. So in order to get in we need to one of two things depending on the docker: OS or web server type docker: Use docker container \u2013ls a to find the stopped container id. Next use docker start <container id> to start the container again. Now use docker ps to see that it is running Python or language image: If you attempt to start the stopped container it will run for a brief second like it already did upon instantiation and then stop. We have to explicitly use docker run -it -d <image> bin/bash . This needs all of those flags (itd) in order to start a container in an interactive session, pipe the terminal from the docker to your local terminal and to run in detached mode. Now that it is running indefinitely we can run docker exec -it <container-name/ID> bash and actually connect to it. Start a docker container: docker start <container-name/ID> Stop a docker container: docker stop <container-name/ID> Take a container and make a new image from it (Example): docker run -itd codalab/codalab-legacy bash Note: Don't forget the -d This downloads a new image and starts an instance. It doesn't have the python package 'seaborn' installed in the python so we are going to add it. We started a container and it is running in detached mode. Now let's connect to it. Use docker ps to get the container's id: docker exec -it d7ef724c4309 bash You should be looking at the prompt: root@f907b9e5d9a6:/# Follow these instructions root@f907b9e5d9a6:/# pip install seaborn ...python is importing stuff... root@f907b9e5d9a6:/# python >>> import seaborn >>> You can see we installed seaborn. Now exit the docker root@f907b9e5d9a6:/# exit . We need to build it to an image: docker commit d7ef724c4309 bbearce/codalab:legacy We just made an image and tagged it with this identifier bbearce/codalab:legacy and we can see it if we execute: $ docker images REPOSITORY TAG IMAGE ID CREATED SIZE bbearce/codalab legacy c2d04ddb825a 3 seconds ago 2.65GB codalab/codalab-legacy latest 432ce2829707 20 months ago 2.64GB Now let's push it online (Docker Hub) as an optional last step: docker login docker push bbearce/codalab:legacy Another way to share is with: docker save docker load save/load docs","title":"Investigating and playing around"},{"location":"notes/docker/remote_registry/","text":"Remote Registry Courtesy of docs.docker.com Deploy a registry server Before you can deploy a registry, you need to install Docker on the host. A registry is an instance of the registry image, and runs within Docker. Run a local registry Use a command like the following to start the registry container: $ docker run -d -p 5000:5000 --restart=always --name registry registry:2 The registry is now ready to use. Warning: These first few examples show registry configurations that are only appropriate for testing. A production-ready registry must be protected by TLS and should ideally use an access-control mechanism. Keep reading and then continue to the configuration guide to deploy a production-ready registry. Copy an image from Docker Hub to your registry You can pull an image from Docker Hub and push it to your registry. The following example pulls the ubuntu:16.04 image from Docker Hub and re-tags it as my-ubuntu, then pushes it to the local registry. Finally, the ubuntu:16.04 and my-ubuntu images are deleted locally and the my-ubuntu image is pulled from the local registry. Pull the ubuntu:16.04 image from Docker Hub. $ docker pull ubuntu:16.04 Tag the image as localhost:5000/my-ubuntu. This creates an additional tag for the existing image. When the first part of the tag is a hostname and port, Docker interprets this as the location of a registry, when pushing. $ docker tag ubuntu:16.04 localhost:5000/my-ubuntu Push the image to the local registry running at localhost:5000: $ docker push localhost:5000/my-ubuntu Remove the locally-cached ubuntu:16.04 and localhost:5000/my-ubuntu images, so that you can test pulling the image from your registry. This does not remove the localhost:5000/my-ubuntu image from your registry. $ docker image remove ubuntu:16.04 $ docker image remove localhost:5000/my-ubuntu Pull the localhost:5000/my-ubuntu image from your local registry. $ docker pull localhost:5000/my-ubuntu Stop a local registry To stop the registry, use the same docker container stop command as with any other container. $ docker container stop registry To remove the container, use docker container rm. $ docker container stop registry && docker container rm -v registry SSL and HTTPS","title":"Remote Registry"},{"location":"notes/docker/remote_registry/#remote-registry","text":"Courtesy of docs.docker.com","title":"Remote Registry"},{"location":"notes/docker/remote_registry/#deploy-a-registry-server","text":"Before you can deploy a registry, you need to install Docker on the host. A registry is an instance of the registry image, and runs within Docker.","title":"Deploy a registry server"},{"location":"notes/docker/remote_registry/#run-a-local-registry","text":"Use a command like the following to start the registry container: $ docker run -d -p 5000:5000 --restart=always --name registry registry:2 The registry is now ready to use. Warning: These first few examples show registry configurations that are only appropriate for testing. A production-ready registry must be protected by TLS and should ideally use an access-control mechanism. Keep reading and then continue to the configuration guide to deploy a production-ready registry.","title":"Run a local registry"},{"location":"notes/docker/remote_registry/#copy-an-image-from-docker-hub-to-your-registry","text":"You can pull an image from Docker Hub and push it to your registry. The following example pulls the ubuntu:16.04 image from Docker Hub and re-tags it as my-ubuntu, then pushes it to the local registry. Finally, the ubuntu:16.04 and my-ubuntu images are deleted locally and the my-ubuntu image is pulled from the local registry. Pull the ubuntu:16.04 image from Docker Hub. $ docker pull ubuntu:16.04 Tag the image as localhost:5000/my-ubuntu. This creates an additional tag for the existing image. When the first part of the tag is a hostname and port, Docker interprets this as the location of a registry, when pushing. $ docker tag ubuntu:16.04 localhost:5000/my-ubuntu Push the image to the local registry running at localhost:5000: $ docker push localhost:5000/my-ubuntu Remove the locally-cached ubuntu:16.04 and localhost:5000/my-ubuntu images, so that you can test pulling the image from your registry. This does not remove the localhost:5000/my-ubuntu image from your registry. $ docker image remove ubuntu:16.04 $ docker image remove localhost:5000/my-ubuntu Pull the localhost:5000/my-ubuntu image from your local registry. $ docker pull localhost:5000/my-ubuntu","title":"Copy an image from Docker Hub to your registry"},{"location":"notes/docker/remote_registry/#stop-a-local-registry","text":"To stop the registry, use the same docker container stop command as with any other container. $ docker container stop registry To remove the container, use docker container rm. $ docker container stop registry && docker container rm -v registry","title":"Stop a local registry"},{"location":"notes/docker/remote_registry/#ssl-and-https","text":"","title":"SSL and HTTPS"},{"location":"notes/front_end/css/css/","text":"CSS Style something with: p { color:red; }","title":"CSS"},{"location":"notes/front_end/css/css/#css","text":"Style something with: p { color:red; }","title":"CSS"},{"location":"notes/front_end/html/html_template/","text":"HTML The basic html tree is as follows: <!DOCTYPE html> <html> <head> <title></title> </head> <body> </body> </html>","title":"HTML"},{"location":"notes/front_end/html/html_template/#html","text":"The basic html tree is as follows: <!DOCTYPE html> <html> <head> <title></title> </head> <body> </body> </html>","title":"HTML"},{"location":"notes/front_end/javascript/Javascript/","text":"Javascript console.log('strings!!!')","title":"Javascript"},{"location":"notes/front_end/javascript/Javascript/#javascript","text":"console.log('strings!!!')","title":"Javascript"},{"location":"notes/front_end/layouts/holy_grail/","text":"The Holy Grail This is apparently a hard style to make...or it was. Now that HTML5 and CSS3 have made lots of updates, styling is easier now. Below is my implementation of this layout. Preview Let's discuss what happened. First the HTML layout. HTML <!DOCTYPE html> <html> <head> <title>New Site</title> <link rel=\"stylesheet\" href=\"./style.css\"></link> <script src=\"https://kit.fontawesome.com/36fc456441.js\" crossorigin=\"anonymous\"></script> </head> <body> <header> <i class=\"fab fa-pied-piper-alt fa-5x\"></i> <ul class=contact-info> <ul>bbearce@somewhere.org</ul> <ul>(123)-456-7890</ul> <ul>Cool St., City, ST 01234</ul> </ul> <ul class=navbar> <li>Home</li> <li>About</li> <li>Details</li> <li>Jokes</li> </ul> </header> <div class=content> <div class=left> <ul> <li>stuff</li> <li>stuff</li> <li>stuff</li> <li>stuff</li> <li>stuff</li> <li>stuff</li> </ul> </div> <div class=middle> <p>Lorem Ipsum is simply dummy text of the printing and typesetting industry. Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book. It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged. It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages, and more recently with desktop publishing software like Aldus PageMaker including versions of Lorem Ipsum.</p> </div> <div class=right> <ul> <li>stuff</li> <li>stuff</li> <li>stuff</li> <li>stuff</li> <li>stuff</li> <li>stuff</li> </ul> </div> </div> <footer> <div class=icons> <i class=\"fas fa-cloud\"></i> <i class=\"fas fa-heart\"></i> <i class=\"fas fa-car\"></i> <i class=\"fas fa-file\"></i> <i class=\"fas fa-bars\"></i> </div> </footer> <script type=\"text/javascript\" src=\"./javascript.js\"></script> </body> </html> CSS JS","title":"Holy Grail"},{"location":"notes/front_end/layouts/holy_grail/#the-holy-grail","text":"This is apparently a hard style to make...or it was. Now that HTML5 and CSS3 have made lots of updates, styling is easier now. Below is my implementation of this layout. Preview Let's discuss what happened. First the HTML layout.","title":"The Holy Grail"},{"location":"notes/front_end/layouts/holy_grail/#html","text":"<!DOCTYPE html> <html> <head> <title>New Site</title> <link rel=\"stylesheet\" href=\"./style.css\"></link> <script src=\"https://kit.fontawesome.com/36fc456441.js\" crossorigin=\"anonymous\"></script> </head> <body> <header> <i class=\"fab fa-pied-piper-alt fa-5x\"></i> <ul class=contact-info> <ul>bbearce@somewhere.org</ul> <ul>(123)-456-7890</ul> <ul>Cool St., City, ST 01234</ul> </ul> <ul class=navbar> <li>Home</li> <li>About</li> <li>Details</li> <li>Jokes</li> </ul> </header> <div class=content> <div class=left> <ul> <li>stuff</li> <li>stuff</li> <li>stuff</li> <li>stuff</li> <li>stuff</li> <li>stuff</li> </ul> </div> <div class=middle> <p>Lorem Ipsum is simply dummy text of the printing and typesetting industry. Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book. It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged. It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages, and more recently with desktop publishing software like Aldus PageMaker including versions of Lorem Ipsum.</p> </div> <div class=right> <ul> <li>stuff</li> <li>stuff</li> <li>stuff</li> <li>stuff</li> <li>stuff</li> <li>stuff</li> </ul> </div> </div> <footer> <div class=icons> <i class=\"fas fa-cloud\"></i> <i class=\"fas fa-heart\"></i> <i class=\"fas fa-car\"></i> <i class=\"fas fa-file\"></i> <i class=\"fas fa-bars\"></i> </div> </footer> <script type=\"text/javascript\" src=\"./javascript.js\"></script> </body> </html>","title":"HTML"},{"location":"notes/front_end/layouts/holy_grail/#css","text":"","title":"CSS"},{"location":"notes/front_end/layouts/holy_grail/#js","text":"","title":"JS"},{"location":"notes/front_end/sass/sass/","text":"Sass Courtesy of sass-lang.com Install Instructions SCSS or SASS? There are two syntaxes available for Sass. The first, known as SCSS (Sassy CSS) and used throughout this reference, is an extension of the syntax of CSS. This means that every valid CSS stylesheet is a valid SCSS file with the same meaning. This syntax is enhanced with the Sass features described below. Files using this syntax have the .scss extension. The second and older syntax , known as the indented syntax (or sometimes just \u201c Sass \u201d), provides a more concise way of writing CSS. It uses indentation rather than brackets to indicate nesting of selectors, and newlines rather than semicolons to separate properties. Files using this syntax have the .sass extension. Preprocessing CSS on its own can be fun, but stylesheets are getting larger, more complex, and harder to maintain. This is where a preprocessor can help. Sass lets you use features that don't exist in CSS yet like variables, nesting, mixins, inheritance and other nifty goodies that make writing CSS fun again. Once you start tinkering with Sass, it will take your preprocessed Sass file and save it as a normal CSS file that you can use in your website. The most direct way to make this happen is in your terminal. Once Sass is installed, you can compile your Sass to CSS using the sass command. You'll need to tell Sass which file to build from, and where to output CSS to. For example, running sass input.scss output.css from your terminal would take a single Sass file, input.scss , and compile that file to output.css . You can also watch individual files or directories with the --watch flag. The watch flag tells Sass to watch your source files for changes, and re-compile CSS each time you save your Sass. If you wanted to watch (instead of manually build) your input.scss file, you'd just add the watch flag to your command, like so: sass --watch input.scss output.css You can watch and output to directories by using folder paths as your input and output, and separating them with a colon. In this example: sass --watch app/sass:public/stylesheets Sass would watch all files in the app/sass folder for changes, and compile CSS to the public/stylesheets folder. More... There is more, but it is so well documented on sass-lang, that it would be redundant to put it here.","title":"SASS"},{"location":"notes/front_end/sass/sass/#sass","text":"Courtesy of sass-lang.com Install Instructions","title":"Sass"},{"location":"notes/front_end/sass/sass/#scss-or-sass","text":"There are two syntaxes available for Sass. The first, known as SCSS (Sassy CSS) and used throughout this reference, is an extension of the syntax of CSS. This means that every valid CSS stylesheet is a valid SCSS file with the same meaning. This syntax is enhanced with the Sass features described below. Files using this syntax have the .scss extension. The second and older syntax , known as the indented syntax (or sometimes just \u201c Sass \u201d), provides a more concise way of writing CSS. It uses indentation rather than brackets to indicate nesting of selectors, and newlines rather than semicolons to separate properties. Files using this syntax have the .sass extension.","title":"SCSS or SASS?"},{"location":"notes/front_end/sass/sass/#preprocessing","text":"CSS on its own can be fun, but stylesheets are getting larger, more complex, and harder to maintain. This is where a preprocessor can help. Sass lets you use features that don't exist in CSS yet like variables, nesting, mixins, inheritance and other nifty goodies that make writing CSS fun again. Once you start tinkering with Sass, it will take your preprocessed Sass file and save it as a normal CSS file that you can use in your website. The most direct way to make this happen is in your terminal. Once Sass is installed, you can compile your Sass to CSS using the sass command. You'll need to tell Sass which file to build from, and where to output CSS to. For example, running sass input.scss output.css from your terminal would take a single Sass file, input.scss , and compile that file to output.css . You can also watch individual files or directories with the --watch flag. The watch flag tells Sass to watch your source files for changes, and re-compile CSS each time you save your Sass. If you wanted to watch (instead of manually build) your input.scss file, you'd just add the watch flag to your command, like so: sass --watch input.scss output.css You can watch and output to directories by using folder paths as your input and output, and separating them with a colon. In this example: sass --watch app/sass:public/stylesheets Sass would watch all files in the app/sass folder for changes, and compile CSS to the public/stylesheets folder.","title":"Preprocessing"},{"location":"notes/front_end/sass/sass/#more","text":"There is more, but it is so well documented on sass-lang, that it would be redundant to put it here.","title":"More..."},{"location":"notes/git/git_basics/","text":"Git Basics Courtesy of rogerdudler.github.io Create a Repo Create a new repo with git init : bbearce@bbearce-XPS-15-9560:~/Desktop/git_practice$ git init Initialized empty Git repository in /home/bbearce/Desktop/git_practice/.git/ Checkout a Repo Checkout a repo with git clone : $ git clone /path/to/repository When using a remote server, your command will be: git clone username@host:/path/to/repository Workflow Your local repository consists of three \"trees\" maintained by git. the first one is your Working Directory which holds the actual files. The second one is the Index which acts as a staging area and finally the HEAD which points to the last commit you've made. Add and Commit You can propose changes (add it to the Index) using: git add <filename> or git add * This is the first step in the basic git workflow. To actually commit these changes use: git commit -m \"Commit message\" Now the file is committed to the HEAD , but not in your remote repository yet. git remote -v will tell you which remote you are connected to. SYNOPSIS git remote [-v | --verbose] ... OPTIONS -v, --verbose Be a little more verbose and show remote url after name. NOTE: This must be placed between remote and subcommand. Adding a New Remote Courtesy of articles.assembla.com To add a new remote, use the git remote add command on the terminal, in the directory your repository is stored at. The git remote add command takes two arguments: A remote name, for example, \u201corigin\u201d A remote URL, which you can find on the Source sub-tab of your Git repo #set a new remote git remote add origin git@git.assembla.com:portfolio/space.space_name.git #Verify new remote git remote -v origin git@git.assembla.com:portfolio/space.space_name.git (fetch) origin git@git.assembla.com:portfolio/space.space_name.git (push) Pushing Changes Your changes are now in the HEAD of your local working copy. To send those changes to your remote repository, execute: git push origin master Change master to whatever branch you want to push your changes to. If you have not cloned an existing repository and want to connect your repository to a remote server, you need to add it with: git remote add origin <server> Now you are able to push your changes to the selected remote server. Push Without User:Pass Courtesy of medium.com A way to skip typing my username/password when using https://github, is by changing the HTTPs origin remote which pointing to an HTTP url into an SSH url. For example: https url: https://github.com/<Username>/<Project>.git ssh url: git@github.com:<Username>/<Project>.git You can do: git remote set-url origin git@github.com:<Username>/<Project>.git to change the url. You need to have an ssh key pair generated and added to github Steps: [1]. Generate Key Pair Open Terminal. Paste the text below, substituting in your GitHub email address. $ ssh-keygen -t rsa -b 4096 -C \"your_email@example.com\" Generating public/private rsa key pair. This creates a new ssh key, using the provided email as a label. When you're prompted to \"Enter a file in which to save the key,\" press Enter. This accepts the default file location. Enter a file in which to save the key (/home/you/.ssh/id_rsa): [Press enter] At the prompt, type a secure passphrase. For more information, see Working with SSH key passphrases . Enter passphrase (empty for no passphrase): [Type a passphrase]> Enter same passphrase again: [Type passphrase again] [2]. Add public key to git account or Add public key to git repo Possible Issues: If you get this error: ERROR: Permission to bbearce/code-journal.git denied to deploy key fatal: Could not read from remote repository. Please make sure you have the correct access rights and the repository exists. You need to add your ssh key to the ssh-agent. Before adding a new SSH key to the ssh-agent to manage your keys, you should have checked for existing SSH keys and generated a new SSH key . If you have checked for existing SSH keys and find one you want to use, follow the below instructions. Start the ssh-agent in the background. $ eval \"$(ssh-agent -s)\" > Agent pid 59566 Add your SSH private key to the ssh-agent. If you created your key with a different name, or if you are adding an existing key that has a different name, replace id_rsa in the command with the name of your private key file. $ ssh-add ~/.ssh/<your_ssh_key> not the .pub file but the file with no extension. Add the SSH key to your GitHub account. Branching Branches are used to develop features isolated from each other. The master branch is the \"default\" branch when you create a repository. Use other branches for development and merge them back to the master branch upon completion. Create a new branch named \"feature_x\" and switch to it using: git checkout -b feature_x Switch back to master: git checkout master Delete the branch again: git branch -d feature_x A branch is not available to others unless you push the branch to your remote repository: git push origin <branch> Update and Merge To update your local repository to the newest commit, execute: git pull In your working directory to fetch and merge remote changes. To merge another branch into your active branch (e.g. master), use: git merge <branch> In both cases git tries to auto-merge changes. Unfortunately, this is not always possible and results in conflicts. You are responsible to merge those conflicts manually by editing the files shown by git. After changing, you need to mark them as merged with: git add <filename> Before merging changes, you can also preview them by using: git diff <source_branch> <target_branch> Tagging It's recommended to create tags for software releases. This is a known concept, which also exists in SVN. You can create a new tag named 1.0.0 by executing: git tag 1.0.0 1b2e1d63ff The 1b2e1d63ff stands for the first 10 characters of the commit id you want to reference with your tag. You can get the commit id by looking at the...log. Log In its simplest form, you can study repository history using: git log You can add a lot of parameters to make the log look like what you want. To see only the commits of a certain author: git log --author=bob To see a very compressed log where each commit is one line: git log --pretty=oneline Or maybe you want to see an ASCII art tree of all the branches, decorated with the names of tags and branches: git log --graph --oneline --decorate --all See only which files have changed: git log --name-status These are just a few of the possible parameters you can use. For more, see git log --help Replace Local Changes In case you did something wrong, which for sure never happens ;), you can replace local changes using the command: git checkout -- <filename> This replaces the changes in your working tree with the last content in HEAD . Changes already added to the index, as well as new files, will be kept. If you instead want to drop all your local changes and commits, fetch the latest history from the server and point your local master branch at it like this: git fetch origin git reset --hard origin/master Useful Hints If you want a built-in git GUI, use: gitk Use colorful git output: git config color.ui true To show log on just one line per commit, use: git config format.pretty oneline Use interactive adding: git add -i Clone Single Branch Courtesy of stackoverflow git clone -b <mybranch> --single-branch <git-url>","title":"Basics"},{"location":"notes/git/git_basics/#git-basics","text":"Courtesy of rogerdudler.github.io","title":"Git Basics"},{"location":"notes/git/git_basics/#create-a-repo","text":"Create a new repo with git init : bbearce@bbearce-XPS-15-9560:~/Desktop/git_practice$ git init Initialized empty Git repository in /home/bbearce/Desktop/git_practice/.git/","title":"Create a Repo"},{"location":"notes/git/git_basics/#checkout-a-repo","text":"Checkout a repo with git clone : $ git clone /path/to/repository When using a remote server, your command will be: git clone username@host:/path/to/repository","title":"Checkout a Repo"},{"location":"notes/git/git_basics/#workflow","text":"Your local repository consists of three \"trees\" maintained by git. the first one is your Working Directory which holds the actual files. The second one is the Index which acts as a staging area and finally the HEAD which points to the last commit you've made.","title":"Workflow"},{"location":"notes/git/git_basics/#add-and-commit","text":"You can propose changes (add it to the Index) using: git add <filename> or git add * This is the first step in the basic git workflow. To actually commit these changes use: git commit -m \"Commit message\" Now the file is committed to the HEAD , but not in your remote repository yet. git remote -v will tell you which remote you are connected to. SYNOPSIS git remote [-v | --verbose] ... OPTIONS -v, --verbose Be a little more verbose and show remote url after name. NOTE: This must be placed between remote and subcommand.","title":"Add and Commit"},{"location":"notes/git/git_basics/#adding-a-new-remote","text":"Courtesy of articles.assembla.com To add a new remote, use the git remote add command on the terminal, in the directory your repository is stored at. The git remote add command takes two arguments: A remote name, for example, \u201corigin\u201d A remote URL, which you can find on the Source sub-tab of your Git repo #set a new remote git remote add origin git@git.assembla.com:portfolio/space.space_name.git #Verify new remote git remote -v origin git@git.assembla.com:portfolio/space.space_name.git (fetch) origin git@git.assembla.com:portfolio/space.space_name.git (push)","title":"Adding a New Remote"},{"location":"notes/git/git_basics/#pushing-changes","text":"Your changes are now in the HEAD of your local working copy. To send those changes to your remote repository, execute: git push origin master Change master to whatever branch you want to push your changes to. If you have not cloned an existing repository and want to connect your repository to a remote server, you need to add it with: git remote add origin <server> Now you are able to push your changes to the selected remote server.","title":"Pushing Changes"},{"location":"notes/git/git_basics/#push-without-userpass","text":"Courtesy of medium.com A way to skip typing my username/password when using https://github, is by changing the HTTPs origin remote which pointing to an HTTP url into an SSH url. For example: https url: https://github.com/<Username>/<Project>.git ssh url: git@github.com:<Username>/<Project>.git You can do: git remote set-url origin git@github.com:<Username>/<Project>.git to change the url. You need to have an ssh key pair generated and added to github Steps: [1]. Generate Key Pair Open Terminal. Paste the text below, substituting in your GitHub email address. $ ssh-keygen -t rsa -b 4096 -C \"your_email@example.com\" Generating public/private rsa key pair. This creates a new ssh key, using the provided email as a label. When you're prompted to \"Enter a file in which to save the key,\" press Enter. This accepts the default file location. Enter a file in which to save the key (/home/you/.ssh/id_rsa): [Press enter] At the prompt, type a secure passphrase. For more information, see Working with SSH key passphrases . Enter passphrase (empty for no passphrase): [Type a passphrase]> Enter same passphrase again: [Type passphrase again] [2]. Add public key to git account or Add public key to git repo","title":"Push Without User:Pass"},{"location":"notes/git/git_basics/#possible-issues","text":"If you get this error: ERROR: Permission to bbearce/code-journal.git denied to deploy key fatal: Could not read from remote repository. Please make sure you have the correct access rights and the repository exists. You need to add your ssh key to the ssh-agent. Before adding a new SSH key to the ssh-agent to manage your keys, you should have checked for existing SSH keys and generated a new SSH key . If you have checked for existing SSH keys and find one you want to use, follow the below instructions. Start the ssh-agent in the background. $ eval \"$(ssh-agent -s)\" > Agent pid 59566 Add your SSH private key to the ssh-agent. If you created your key with a different name, or if you are adding an existing key that has a different name, replace id_rsa in the command with the name of your private key file. $ ssh-add ~/.ssh/<your_ssh_key> not the .pub file but the file with no extension. Add the SSH key to your GitHub account.","title":"Possible Issues:"},{"location":"notes/git/git_basics/#branching","text":"Branches are used to develop features isolated from each other. The master branch is the \"default\" branch when you create a repository. Use other branches for development and merge them back to the master branch upon completion. Create a new branch named \"feature_x\" and switch to it using: git checkout -b feature_x Switch back to master: git checkout master Delete the branch again: git branch -d feature_x A branch is not available to others unless you push the branch to your remote repository: git push origin <branch>","title":"Branching"},{"location":"notes/git/git_basics/#update-and-merge","text":"To update your local repository to the newest commit, execute: git pull In your working directory to fetch and merge remote changes. To merge another branch into your active branch (e.g. master), use: git merge <branch> In both cases git tries to auto-merge changes. Unfortunately, this is not always possible and results in conflicts. You are responsible to merge those conflicts manually by editing the files shown by git. After changing, you need to mark them as merged with: git add <filename> Before merging changes, you can also preview them by using: git diff <source_branch> <target_branch>","title":"Update and Merge"},{"location":"notes/git/git_basics/#tagging","text":"It's recommended to create tags for software releases. This is a known concept, which also exists in SVN. You can create a new tag named 1.0.0 by executing: git tag 1.0.0 1b2e1d63ff The 1b2e1d63ff stands for the first 10 characters of the commit id you want to reference with your tag. You can get the commit id by looking at the...log.","title":"Tagging"},{"location":"notes/git/git_basics/#log","text":"In its simplest form, you can study repository history using: git log You can add a lot of parameters to make the log look like what you want. To see only the commits of a certain author: git log --author=bob To see a very compressed log where each commit is one line: git log --pretty=oneline Or maybe you want to see an ASCII art tree of all the branches, decorated with the names of tags and branches: git log --graph --oneline --decorate --all See only which files have changed: git log --name-status These are just a few of the possible parameters you can use. For more, see git log --help","title":"Log"},{"location":"notes/git/git_basics/#replace-local-changes","text":"In case you did something wrong, which for sure never happens ;), you can replace local changes using the command: git checkout -- <filename> This replaces the changes in your working tree with the last content in HEAD . Changes already added to the index, as well as new files, will be kept. If you instead want to drop all your local changes and commits, fetch the latest history from the server and point your local master branch at it like this: git fetch origin git reset --hard origin/master","title":"Replace Local Changes"},{"location":"notes/git/git_basics/#useful-hints","text":"If you want a built-in git GUI, use: gitk Use colorful git output: git config color.ui true To show log on just one line per commit, use: git config format.pretty oneline Use interactive adding: git add -i","title":"Useful Hints"},{"location":"notes/git/git_basics/#clone-single-branch","text":"Courtesy of stackoverflow git clone -b <mybranch> --single-branch <git-url>","title":"Clone Single Branch"},{"location":"notes/git/git_sub_trees/","text":"Subtrees Courtesty of github Typically, a subtree merge is used to contain a repository within a repository. The \"subrepository\" is stored in a folder of the main repository. The best way to explain subtree merges is to show by example. We will: Make an empty repository called test that represents our project Merge another repository into it as a subtree called Spoon-Knife . The test project will use that subproject as if it were part of the same repository. Fetch updates from Spoon-Knife into our test project. Setting up the empty repository for a subtree merge Open Terminal. Create a new directory and navigate to it. $ mkdir test $ cd test Initialize a new Git repository. $ git init > Initialized empty Git repository in /Users/octocat/tmp/test/.git/ Create and commit a new file. $ touch .gitignore $ git add .gitignore $ git commit -m \"initial commit\" > [master (root-commit) 3146c2a] initial commit > 0 files changed, 0 insertions(+), 0 deletions(-) > create mode 100644 .gitignore Adding a new repository as a subtree Add a new remote URL pointing to the separate project that we're interested in. $ git remote add -f spoon-knife git@github.com:octocat/Spoon-Knife.git > Updating spoon-knife > warning: no common commits > remote: Counting objects: 1732, done. > remote: Compressing objects: 100% (750/750), done. > remote: Total 1732 (delta 1086), reused 1558 (delta 967) > Receiving objects: 100% (1732/1732), 528.19 KiB | 621 KiB/s, done. > Resolving deltas: 100% (1086/1086), done. > From git://github.com/octocat/Spoon-Knife > * [new branch] master -> Spoon-Knife/master Merge the Spoon-Knife project into the local Git project. This doesn't change any of your files locally, but it does prepare Git for the next step. If you're using Git 2.9 or above: $ git merge -s ours --no-commit --allow-unrelated-histories spoon-knife/master > Automatic merge went well; stopped before committing as requested If you're using Git 2.8 or below: $ git merge -s ours --no-commit spoon-knife/master > Automatic merge went well; stopped before committing as requested Create a new directory called spoon-knife , and copy the Git history of the Spoon-Knife project into it. $ git read-tree --prefix=spoon-knife/ -u spoon-knife/master Commit the changes to keep them safe. $ git commit -m \"Subtree merged in spoon-knife\" > [master fe0ca25] Subtree merged in spoon-knife Although we've only added one subproject, any number of subprojects can be incorporated into a Git repository. Tip: If you create a fresh clone of the repository in the future, the remotes you've added will not be created for you. You will have to add them again using the git remote add command. Synchronizing with updates and changes When a subproject is added, it is not automatically kept in sync with the upstream changes. You will need to update the subproject with the following command: $ git pull -s subtree remotename branchname For the example above, this would be: $ git pull -s subtree spoon-knife master","title":"Subtrees"},{"location":"notes/git/git_sub_trees/#subtrees","text":"Courtesty of github Typically, a subtree merge is used to contain a repository within a repository. The \"subrepository\" is stored in a folder of the main repository. The best way to explain subtree merges is to show by example. We will: Make an empty repository called test that represents our project Merge another repository into it as a subtree called Spoon-Knife . The test project will use that subproject as if it were part of the same repository. Fetch updates from Spoon-Knife into our test project.","title":"Subtrees"},{"location":"notes/git/git_sub_trees/#setting-up-the-empty-repository-for-a-subtree-merge","text":"Open Terminal. Create a new directory and navigate to it. $ mkdir test $ cd test Initialize a new Git repository. $ git init > Initialized empty Git repository in /Users/octocat/tmp/test/.git/ Create and commit a new file. $ touch .gitignore $ git add .gitignore $ git commit -m \"initial commit\" > [master (root-commit) 3146c2a] initial commit > 0 files changed, 0 insertions(+), 0 deletions(-) > create mode 100644 .gitignore","title":"Setting up the empty repository for a subtree merge"},{"location":"notes/git/git_sub_trees/#adding-a-new-repository-as-a-subtree","text":"Add a new remote URL pointing to the separate project that we're interested in. $ git remote add -f spoon-knife git@github.com:octocat/Spoon-Knife.git > Updating spoon-knife > warning: no common commits > remote: Counting objects: 1732, done. > remote: Compressing objects: 100% (750/750), done. > remote: Total 1732 (delta 1086), reused 1558 (delta 967) > Receiving objects: 100% (1732/1732), 528.19 KiB | 621 KiB/s, done. > Resolving deltas: 100% (1086/1086), done. > From git://github.com/octocat/Spoon-Knife > * [new branch] master -> Spoon-Knife/master Merge the Spoon-Knife project into the local Git project. This doesn't change any of your files locally, but it does prepare Git for the next step. If you're using Git 2.9 or above: $ git merge -s ours --no-commit --allow-unrelated-histories spoon-knife/master > Automatic merge went well; stopped before committing as requested If you're using Git 2.8 or below: $ git merge -s ours --no-commit spoon-knife/master > Automatic merge went well; stopped before committing as requested Create a new directory called spoon-knife , and copy the Git history of the Spoon-Knife project into it. $ git read-tree --prefix=spoon-knife/ -u spoon-knife/master Commit the changes to keep them safe. $ git commit -m \"Subtree merged in spoon-knife\" > [master fe0ca25] Subtree merged in spoon-knife Although we've only added one subproject, any number of subprojects can be incorporated into a Git repository. Tip: If you create a fresh clone of the repository in the future, the remotes you've added will not be created for you. You will have to add them again using the git remote add command.","title":"Adding a new repository as a subtree"},{"location":"notes/git/git_sub_trees/#synchronizing-with-updates-and-changes","text":"When a subproject is added, it is not automatically kept in sync with the upstream changes. You will need to update the subproject with the following command: $ git pull -s subtree remotename branchname For the example above, this would be: $ git pull -s subtree spoon-knife master","title":"Synchronizing with updates and changes"},{"location":"notes/git/git_submodules/","text":"Submodules Courtesy of github Git Submodules basic explanation Why submodules? In Git you can add a submodule to a repository. This is basically a repository embedded in your main repository. This can be very useful. A couple of advantages of using submodules: You can separate the code into different repositories. Useful if you have a codebase with big components, you could make a component a submodule. This way you'll have a cleaner Git log (commits are specific to a certain component). You can add the submodule to multiple repositories. Useful if you have multiple repositories that share the same components. With this approach you can easily update those components in all the repositories that added them as a submodule. This is a lot more convienient than copy-pasting the code into the repositories. Basics When you add a submodule in Git, you don't add the code of the submodule to the main repository, you only add information about the submodule that is added to the main repository. This information describes which commit the submodule is pointing at. This way, the submodule's code won't automatically be updated if the submodule's repository is updated. This is good, because your code might not work with the latest commit of the submodule, it prevents unexpected behaviour. Adding a submodule You can add a submodule to a repository like this: git submodule add git@github.com:url_to/awesome_submodule.git path_to_awesome_submodule With default configuration, this will check out the code of the awesome_submodule.git repository to the path_to_awesome_submodule directory, and will add information to the main repository about this submodule, which contains the commit the submodule points to , which will be the current commit of the default branch (usually the master branch) at the time this command is executed. After this operation, if you do a git status you'll see two files in the Changes to be committed list: the .gitmodules file and the path to the submodule. When you commit and push these files you commit/push the submodule to the origin. Getting the submodule's code If a new submodule is created by one person, the other people in the team need to initiate this submodule. First you have to get the information about the submodule, this is retrieved by a normal git pull . If there are new submodules you'll see it in the output of git pull . Then you'll have to initiate them with: git submodule init This will pull all the code from the submodule and place it in the directory that it's configured to. If you've cloned a repository that makes use of submodules, you should also run this command to get the submodule's code. This is not automatically done by git clone . Pushing updates in the submodule The submodule is just a separate resository. If you want to make changes to it, you should make the changes in this repository and push them like in a regular Git repository (just execute the git commands in the submodule's directory). However, you should also let the main repository know that you've updated the submodule's repository, and make it use the latest commit of the repository of the submodule. Because if you make new commits inside a submodule, the main repository will still point to the old commit . So, if you want to have these changes in your main repository too, you should tell the main repository to use the latest commit of the submodule. Now how do you do this? So you've made changes in the submodule's repository and committed them in its repository. If you now do a git status in the main repository, you'll see that the submodule is in the list Changes not staged for commit and it has the text (modified content) behind it. This means that the code of the submodule is checked out on a different commit than the main repository is pointing to . To make the main repository point to this new commit, you just add this change with git add and then commit and push it. Keeping your submodules up-to-date If someone updated a submodule, the other team-members should update the code of their submodules. This is not automatically done by git pull , because with git pull it only retrieves the information that the submodule is pointing to another commit , but doesn't update the submodule's code . To update the code of your submodules, you should run: git submodule update What happens if you don't run this command? If you don't run this command, the code of your submodule is checked out to an old commit. When you do git status you will see the submodule in the Changes not staged for commit list with the text (modified content) behind it. This is not because you changed the submodule's code, but because its code is checked out to a different commit. So Git sees this as a change, but actually you just didn't update the submodule's code. So if you're working with submodules, don't forget to keep your submodules up-to-date. Making it easier for everyone It is sometimes annoying if you forget to initiate and update your submodules. Fortunately, there are some tricks to make it easier: git submodule update --init This will update the submodules, and if they're not initiated yet, will initiate them. You can also have submodules inside of submodules. In this case you'll want to update/initiate the submodules recursively: git submodule update --init --recursive This is a lot to type, so you can make an alias: git config --global alias.update '!git pull && git submodule update --init --recursive' Now whenever you execute git update , it will execute a git pull and a git submodule update --init --recursive , thus updating all the code in your project. Courtesy of github To remove a submodule you need to: Delete the relevant section from the .gitmodules file. Stage the .gitmodules changes git add .gitmodules Delete the relevant section from .git/config . Run git rm --cached path_to_submodule (no trailing slash). Run rm -rf .git/modules/path_to_submodule (no trailing slash). Commit git commit -m \"Removed submodule \" Delete the now untracked submodule files rm -rf path_to_submodule","title":"Submodules"},{"location":"notes/git/git_submodules/#submodules","text":"Courtesy of github Git Submodules basic explanation","title":"Submodules"},{"location":"notes/git/git_submodules/#why-submodules","text":"In Git you can add a submodule to a repository. This is basically a repository embedded in your main repository. This can be very useful. A couple of advantages of using submodules: You can separate the code into different repositories. Useful if you have a codebase with big components, you could make a component a submodule. This way you'll have a cleaner Git log (commits are specific to a certain component). You can add the submodule to multiple repositories. Useful if you have multiple repositories that share the same components. With this approach you can easily update those components in all the repositories that added them as a submodule. This is a lot more convienient than copy-pasting the code into the repositories.","title":"Why submodules?"},{"location":"notes/git/git_submodules/#basics","text":"When you add a submodule in Git, you don't add the code of the submodule to the main repository, you only add information about the submodule that is added to the main repository. This information describes which commit the submodule is pointing at. This way, the submodule's code won't automatically be updated if the submodule's repository is updated. This is good, because your code might not work with the latest commit of the submodule, it prevents unexpected behaviour.","title":"Basics"},{"location":"notes/git/git_submodules/#adding-a-submodule","text":"You can add a submodule to a repository like this: git submodule add git@github.com:url_to/awesome_submodule.git path_to_awesome_submodule With default configuration, this will check out the code of the awesome_submodule.git repository to the path_to_awesome_submodule directory, and will add information to the main repository about this submodule, which contains the commit the submodule points to , which will be the current commit of the default branch (usually the master branch) at the time this command is executed. After this operation, if you do a git status you'll see two files in the Changes to be committed list: the .gitmodules file and the path to the submodule. When you commit and push these files you commit/push the submodule to the origin.","title":"Adding a submodule"},{"location":"notes/git/git_submodules/#getting-the-submodules-code","text":"If a new submodule is created by one person, the other people in the team need to initiate this submodule. First you have to get the information about the submodule, this is retrieved by a normal git pull . If there are new submodules you'll see it in the output of git pull . Then you'll have to initiate them with: git submodule init This will pull all the code from the submodule and place it in the directory that it's configured to. If you've cloned a repository that makes use of submodules, you should also run this command to get the submodule's code. This is not automatically done by git clone .","title":"Getting the submodule's code"},{"location":"notes/git/git_submodules/#pushing-updates-in-the-submodule","text":"The submodule is just a separate resository. If you want to make changes to it, you should make the changes in this repository and push them like in a regular Git repository (just execute the git commands in the submodule's directory). However, you should also let the main repository know that you've updated the submodule's repository, and make it use the latest commit of the repository of the submodule. Because if you make new commits inside a submodule, the main repository will still point to the old commit . So, if you want to have these changes in your main repository too, you should tell the main repository to use the latest commit of the submodule. Now how do you do this? So you've made changes in the submodule's repository and committed them in its repository. If you now do a git status in the main repository, you'll see that the submodule is in the list Changes not staged for commit and it has the text (modified content) behind it. This means that the code of the submodule is checked out on a different commit than the main repository is pointing to . To make the main repository point to this new commit, you just add this change with git add and then commit and push it.","title":"Pushing updates in the submodule"},{"location":"notes/git/git_submodules/#keeping-your-submodules-up-to-date","text":"If someone updated a submodule, the other team-members should update the code of their submodules. This is not automatically done by git pull , because with git pull it only retrieves the information that the submodule is pointing to another commit , but doesn't update the submodule's code . To update the code of your submodules, you should run: git submodule update","title":"Keeping your submodules up-to-date"},{"location":"notes/git/git_submodules/#what-happens-if-you-dont-run-this-command","text":"If you don't run this command, the code of your submodule is checked out to an old commit. When you do git status you will see the submodule in the Changes not staged for commit list with the text (modified content) behind it. This is not because you changed the submodule's code, but because its code is checked out to a different commit. So Git sees this as a change, but actually you just didn't update the submodule's code. So if you're working with submodules, don't forget to keep your submodules up-to-date.","title":"What happens if you don't run this command?"},{"location":"notes/git/git_submodules/#making-it-easier-for-everyone","text":"It is sometimes annoying if you forget to initiate and update your submodules. Fortunately, there are some tricks to make it easier: git submodule update --init This will update the submodules, and if they're not initiated yet, will initiate them. You can also have submodules inside of submodules. In this case you'll want to update/initiate the submodules recursively: git submodule update --init --recursive This is a lot to type, so you can make an alias: git config --global alias.update '!git pull && git submodule update --init --recursive' Now whenever you execute git update , it will execute a git pull and a git submodule update --init --recursive , thus updating all the code in your project. Courtesy of github To remove a submodule you need to: Delete the relevant section from the .gitmodules file. Stage the .gitmodules changes git add .gitmodules Delete the relevant section from .git/config . Run git rm --cached path_to_submodule (no trailing slash). Run rm -rf .git/modules/path_to_submodule (no trailing slash). Commit git commit -m \"Removed submodule \" Delete the now untracked submodule files rm -rf path_to_submodule","title":"Making it easier for everyone"},{"location":"notes/internet_of_things/General Notes/","text":"Notes About the Internet IP Address Types IPv4 IPv4 (Internet Protocol Version 4) is the fourth revision of the Internet Protocol (IP) used to to identify devices on a network through an addressing system. The Internet Protocol is designed for use in interconnected systems of packet-switched computer communication networks IPv4 uses a 32-bit address scheme allowing for a total of 2^32 addresses (just over 4 billion addresses). IPv6 A new Internet addressing system Internet Protocol version 6 (IPv6) is being deployed to fulfill the need for more Internet addresses. IPv6 (Internet Protocol Version 6) is also called IPng (Internet Protocol next generation) and it is the newest version of the Internet Protocol (IP) reviewed in the IETF standards committees to replace the current version of IPv4 (Internet Protocol Version 4). IPv6 addresses are 128-bit IP address written in hexadecimal and separated by colons. An example IPv6 address could be written like this: 3ffe:1900:4545:3:200:f8ff:fe21:67cf.","title":"General Notes"},{"location":"notes/internet_of_things/General Notes/#notes-about-the-internet","text":"","title":"Notes About the Internet"},{"location":"notes/internet_of_things/General Notes/#ip-address-types","text":"","title":"IP Address Types"},{"location":"notes/internet_of_things/General Notes/#ipv4","text":"IPv4 (Internet Protocol Version 4) is the fourth revision of the Internet Protocol (IP) used to to identify devices on a network through an addressing system. The Internet Protocol is designed for use in interconnected systems of packet-switched computer communication networks IPv4 uses a 32-bit address scheme allowing for a total of 2^32 addresses (just over 4 billion addresses).","title":"IPv4"},{"location":"notes/internet_of_things/General Notes/#ipv6","text":"A new Internet addressing system Internet Protocol version 6 (IPv6) is being deployed to fulfill the need for more Internet addresses. IPv6 (Internet Protocol Version 6) is also called IPng (Internet Protocol next generation) and it is the newest version of the Internet Protocol (IP) reviewed in the IETF standards committees to replace the current version of IPv4 (Internet Protocol Version 4). IPv6 addresses are 128-bit IP address written in hexadecimal and separated by colons. An example IPv6 address could be written like this: 3ffe:1900:4545:3:200:f8ff:fe21:67cf.","title":"IPv6"},{"location":"notes/internet_of_things/SimpleHTTPServer/","text":"SimpleHTTPServer Courtesy of 2ality SimpleHTTPServer: a quick way to serve a directory Using SimpleHTTPServer SimpleHTTPServer is invoked like this (the parameter is optional): python -m SimpleHTTPServer <port> (On OS X, Python is pre-installed and this command works out of the box.) Let\u2019s look at an example of using SimpleHTTPServer: During the following Unix shell interaction, I first list the files in the current directory and then start SimpleHTTPServer to serve it. $ ls . foo.html $ python -m SimpleHTTPServer Serving HTTP on 0.0.0.0 port 8000 ... Afterwards, I can access the following URLs: http://localhost:8000/ lists the files in the current directory (namely, just foo.html). If there were a file index.html, it would be displayed, instead. http://localhost:8000/foo.html displays the file foo.html in the current directory. Customizing SimpleHTTPServer The following Unix shell script demonstrates how to customize SimpleHTTPServer so that it serves files that have a given file name extension with a given media type. One case where that matters is Firefox being picky about the media type of the webapp.manifest. #!/usr/bin/python import SimpleHTTPServer import SocketServer PORT = 8000 Handler = SimpleHTTPServer.SimpleHTTPRequestHandler Handler.extensions_map.update({ '.webapp': 'application/x-web-app-manifest+json', }); httpd = SocketServer.TCPServer((\"\", PORT), Handler) print \"Serving at port\", PORT httpd.serve_forever()","title":"SimpleHTTPServer"},{"location":"notes/internet_of_things/SimpleHTTPServer/#simplehttpserver","text":"Courtesy of 2ality SimpleHTTPServer: a quick way to serve a directory","title":"SimpleHTTPServer"},{"location":"notes/internet_of_things/SimpleHTTPServer/#using-simplehttpserver","text":"SimpleHTTPServer is invoked like this (the parameter is optional): python -m SimpleHTTPServer <port> (On OS X, Python is pre-installed and this command works out of the box.) Let\u2019s look at an example of using SimpleHTTPServer: During the following Unix shell interaction, I first list the files in the current directory and then start SimpleHTTPServer to serve it. $ ls . foo.html $ python -m SimpleHTTPServer Serving HTTP on 0.0.0.0 port 8000 ... Afterwards, I can access the following URLs: http://localhost:8000/ lists the files in the current directory (namely, just foo.html). If there were a file index.html, it would be displayed, instead. http://localhost:8000/foo.html displays the file foo.html in the current directory.","title":"Using SimpleHTTPServer"},{"location":"notes/internet_of_things/SimpleHTTPServer/#customizing-simplehttpserver","text":"The following Unix shell script demonstrates how to customize SimpleHTTPServer so that it serves files that have a given file name extension with a given media type. One case where that matters is Firefox being picky about the media type of the webapp.manifest. #!/usr/bin/python import SimpleHTTPServer import SocketServer PORT = 8000 Handler = SimpleHTTPServer.SimpleHTTPRequestHandler Handler.extensions_map.update({ '.webapp': 'application/x-web-app-manifest+json', }); httpd = SocketServer.TCPServer((\"\", PORT), Handler) print \"Serving at port\", PORT httpd.serve_forever()","title":"Customizing SimpleHTTPServer"},{"location":"notes/internet_of_things/nginx/","text":"Nginx","title":"Nginx"},{"location":"notes/internet_of_things/nginx/#nginx","text":"","title":"Nginx"},{"location":"notes/internet_of_things/AWS/storage/","text":"Storage In my quest to get started with AWS, I noticed lots of different storage types. I'll make some quick notes about them here. EC2 \u2013 Elastic Compute Cloud \u2013 The VMs While not storage, EC2 instances are the basis for anything in AWS EBS \u2013 Elastic Block Storage - $$ - Can be scaled but upgrading costs money S3 \u2013 Simple Storage Service \u2013 files and objects - $$ EFS \u2013 Elastic File System - - $$$ Glacier \u2013 Low cost option for long term storage - $ AWS Snowball - Snowball is designed to make such transfers easy without incurring astronomical network usage fees. FSx for Lustre - High performance computing for fast processing of workloads. Integrates with S3 and you pay as you go. AWS Storage Gateway - Seamlessly links your on-premises environment to Amazon cloud storage Cloud Data Migration Services - A portfolio of services to help simplify and accelerate moving data of all types and sizes into and out of the AWS cloud AWS Backup - Backups","title":"AWS"},{"location":"notes/internet_of_things/AWS/storage/#storage","text":"In my quest to get started with AWS, I noticed lots of different storage types. I'll make some quick notes about them here. EC2 \u2013 Elastic Compute Cloud \u2013 The VMs While not storage, EC2 instances are the basis for anything in AWS EBS \u2013 Elastic Block Storage - $$ - Can be scaled but upgrading costs money S3 \u2013 Simple Storage Service \u2013 files and objects - $$ EFS \u2013 Elastic File System - - $$$ Glacier \u2013 Low cost option for long term storage - $ AWS Snowball - Snowball is designed to make such transfers easy without incurring astronomical network usage fees. FSx for Lustre - High performance computing for fast processing of workloads. Integrates with S3 and you pay as you go. AWS Storage Gateway - Seamlessly links your on-premises environment to Amazon cloud storage Cloud Data Migration Services - A portfolio of services to help simplify and accelerate moving data of all types and sizes into and out of the AWS cloud AWS Backup - Backups","title":"Storage"},{"location":"notes/internet_of_things/Azure/placeholder/","text":"Placeholder This will be filled in eventually: $ echo awesome stuff coming","title":"Azure"},{"location":"notes/internet_of_things/Azure/placeholder/#placeholder","text":"This will be filled in eventually: $ echo awesome stuff coming","title":"Placeholder"},{"location":"notes/internet_of_things/TLS Security/TLS Security/","text":"TLS Security Courtesy of cloudfare Summary What is Transport Layer Security (TLS)? Transport Layer Security, or TLS, is a widely adopted security protocol designed to facilitate privacy and data security for communications over the Internet. A primary use case of TLS is encrypting the communication between web applications and servers, such as web browsers loading a website. TLS can also be used to encrypt other communications such as email, messaging, and voice over IP (VOIP). In this article we will focus on the role of TLS in web application security. TLS was proposed by the Internet Engineering Task Force (IETF), an international standards organization, and the first version of the protocol was published in 1999. The most recent version is TLS 1.3, which was published in 2018. What\u2019s the difference between TLS and SSL? TLS evolved from a previous encryption protocol called Secure Socket Layer (SSL), which was developed by Netscape. TLS version 1.0 actually began development as SSL version 3.1, but the name of the protocol was changed before publication in order to indicate that it was no longer associated with Netscape. Because of this history, the terms TLS and SSL are sometimes used interchangeably. What\u2019s the difference between TLS and HTTPS? HTTPS is an implementation of TLS encryption on top of the HTTP protocol, which is used by all websites as well as some other web services. Any website that uses HTTPS is therefore employing TLS encryption. Why should you use TLS? TLS encryption can help protect web applications from attacks such as data breaches, and DDoS attacks. Additionally, TLS-protected HTTPS is quickly becoming a standard practice for websites. For example, the Google Chrome browser is cracking down on non-HTTPS sites, and everyday Internet users are starting to become more wary of websites that don\u2019t feature the HTTPS padlock icon. How does TLS work? TLS can be used on top of a transport-layer security protocol like TCP. There are three main components to TLS: Encryption, Authentication, and Integrity. Encryption: hides the data being transferred from third parties. Authentication: ensures that the parties exchanging information are who they claim to be. Integrity: verifies that the data has not been forged or tampered with. A TLS connection is initiated using a sequence known as the TLS handshake. The TLS handshake establishes a cypher suite for each communication session. The cypher suite is a set of algorithms that specifies details such as which shared encryption keys, or session keys, will be used for that particular session. TLS is able to set the matching session keys over an unencrypted channel thanks to a technology known as public key cryptography. The handshake also handles authentication, which usually consists of the server proving its identity to the client. This is done using public keys. Public keys are encryption keys that use one-way encryption, meaning that anyone can unscramble data encrypted with the private key to ensure its authenticity, but only the original sender can encrypt data with the private key. Once data is encrypted and authenticated, it is then signed with a message authentication code (MAC). The recipient can then verify the MAC to ensure the integrity of the data. This is kind of like the tamper-proof foil found on a bottle of aspirin; the consumer knows no one has tampered with their medicine because the foil is intact when they purchase it. How does TLS affect web application performance? Because of the complex process involved in setting up a TLS connection, some load time and computational power must be expended. The client and server must communicate back and forth several times before any data is transmitted, and that eats up precious milliseconds of load times for web applications, as well as some memory for both the client and the server. Thankfully there are technologies in place that help to mitigate the lag created by the TLS handshake. One is TLS False Start, which lets the server and client start transmitting data before the TLS handshake is complete. Another technology to speed up TLS is TLS Session Resumption, which allows clients and servers that have previously communicated to use an abbreviated handshake. These improvements have helped to make TLS a very fast protocol that shouldn\u2019t noticeably affect load times. As for the computational costs associated with TLS, they are mostly negligible by today\u2019s standards. For example, when Google moved their entire Gmail platform to HTTPS in 2010, there was no need for them to enable any additional hardware. The extra load on their servers as a result of TLS encryption was less than 1%. How to start implementing TLS on a website All Cloudflare users automatically have HTTPS protection from Cloudflare. Via Universal SSL, Cloudflare offers free TLS/SSL certificates to all users. Anyone who doesn't use Cloudflare will have to acquire an SSL certificate from a certificate authority, often for a fee, and install the certificate on their origin servers. For more on how TLS/SSL certificates work, see What is an SSL certificate? Get a CA Certificate","title":"TLS Security"},{"location":"notes/internet_of_things/TLS Security/TLS Security/#tls-security","text":"Courtesy of cloudfare","title":"TLS Security"},{"location":"notes/internet_of_things/TLS Security/TLS Security/#summary","text":"","title":"Summary"},{"location":"notes/internet_of_things/TLS Security/TLS Security/#what-is-transport-layer-security-tls","text":"Transport Layer Security, or TLS, is a widely adopted security protocol designed to facilitate privacy and data security for communications over the Internet. A primary use case of TLS is encrypting the communication between web applications and servers, such as web browsers loading a website. TLS can also be used to encrypt other communications such as email, messaging, and voice over IP (VOIP). In this article we will focus on the role of TLS in web application security. TLS was proposed by the Internet Engineering Task Force (IETF), an international standards organization, and the first version of the protocol was published in 1999. The most recent version is TLS 1.3, which was published in 2018.","title":"What is Transport Layer Security (TLS)?"},{"location":"notes/internet_of_things/TLS Security/TLS Security/#whats-the-difference-between-tls-and-ssl","text":"TLS evolved from a previous encryption protocol called Secure Socket Layer (SSL), which was developed by Netscape. TLS version 1.0 actually began development as SSL version 3.1, but the name of the protocol was changed before publication in order to indicate that it was no longer associated with Netscape. Because of this history, the terms TLS and SSL are sometimes used interchangeably.","title":"What\u2019s the difference between TLS and SSL?"},{"location":"notes/internet_of_things/TLS Security/TLS Security/#whats-the-difference-between-tls-and-https","text":"HTTPS is an implementation of TLS encryption on top of the HTTP protocol, which is used by all websites as well as some other web services. Any website that uses HTTPS is therefore employing TLS encryption.","title":"What\u2019s the difference between TLS and HTTPS?"},{"location":"notes/internet_of_things/TLS Security/TLS Security/#why-should-you-use-tls","text":"TLS encryption can help protect web applications from attacks such as data breaches, and DDoS attacks. Additionally, TLS-protected HTTPS is quickly becoming a standard practice for websites. For example, the Google Chrome browser is cracking down on non-HTTPS sites, and everyday Internet users are starting to become more wary of websites that don\u2019t feature the HTTPS padlock icon.","title":"Why should you use TLS?"},{"location":"notes/internet_of_things/TLS Security/TLS Security/#how-does-tls-work","text":"TLS can be used on top of a transport-layer security protocol like TCP. There are three main components to TLS: Encryption, Authentication, and Integrity. Encryption: hides the data being transferred from third parties. Authentication: ensures that the parties exchanging information are who they claim to be. Integrity: verifies that the data has not been forged or tampered with. A TLS connection is initiated using a sequence known as the TLS handshake. The TLS handshake establishes a cypher suite for each communication session. The cypher suite is a set of algorithms that specifies details such as which shared encryption keys, or session keys, will be used for that particular session. TLS is able to set the matching session keys over an unencrypted channel thanks to a technology known as public key cryptography. The handshake also handles authentication, which usually consists of the server proving its identity to the client. This is done using public keys. Public keys are encryption keys that use one-way encryption, meaning that anyone can unscramble data encrypted with the private key to ensure its authenticity, but only the original sender can encrypt data with the private key. Once data is encrypted and authenticated, it is then signed with a message authentication code (MAC). The recipient can then verify the MAC to ensure the integrity of the data. This is kind of like the tamper-proof foil found on a bottle of aspirin; the consumer knows no one has tampered with their medicine because the foil is intact when they purchase it.","title":"How does TLS work?"},{"location":"notes/internet_of_things/TLS Security/TLS Security/#how-does-tls-affect-web-application-performance","text":"Because of the complex process involved in setting up a TLS connection, some load time and computational power must be expended. The client and server must communicate back and forth several times before any data is transmitted, and that eats up precious milliseconds of load times for web applications, as well as some memory for both the client and the server. Thankfully there are technologies in place that help to mitigate the lag created by the TLS handshake. One is TLS False Start, which lets the server and client start transmitting data before the TLS handshake is complete. Another technology to speed up TLS is TLS Session Resumption, which allows clients and servers that have previously communicated to use an abbreviated handshake. These improvements have helped to make TLS a very fast protocol that shouldn\u2019t noticeably affect load times. As for the computational costs associated with TLS, they are mostly negligible by today\u2019s standards. For example, when Google moved their entire Gmail platform to HTTPS in 2010, there was no need for them to enable any additional hardware. The extra load on their servers as a result of TLS encryption was less than 1%.","title":"How does TLS affect web application performance?"},{"location":"notes/internet_of_things/TLS Security/TLS Security/#how-to-start-implementing-tls-on-a-website","text":"All Cloudflare users automatically have HTTPS protection from Cloudflare. Via Universal SSL, Cloudflare offers free TLS/SSL certificates to all users. Anyone who doesn't use Cloudflare will have to acquire an SSL certificate from a certificate authority, often for a fee, and install the certificate on their origin servers. For more on how TLS/SSL certificates work, see What is an SSL certificate?","title":"How to start implementing TLS on a website"},{"location":"notes/internet_of_things/TLS Security/TLS Security/#get-a-ca-certificate","text":"","title":"Get a CA Certificate"},{"location":"notes/python/Installs/","text":"Installs Installing You an use wget to grab the latest like so: cd /usr/src sudo wget https://www.python.org/ftp/python/3.7.4/Python-3.7.4.tgz You can also go to https://www.python.org/ and download it. This gave me a Python-3.7.4.tar.xz file. To unzip it use: $ tar -xf Python-3.7.4.tar.xz $ ls -la drwxr-xr-x 18 bbearce bbearce 4096 Jul 8 14:31 Python-3.7.4 -rw-rw-r-- 1 bbearce bbearce 17131432 Sep 4 11:09 Python-3.7.4.tar.xz To see other unzipping techniques for different file types try here Change into that new directory and use make to install Python: $ cd Python-3.7.4 Note: Notice the README.rst $ vi README.rst ... Build Instructions On Unix, Linux, BSD, macOS, and Cygwin:: ./configure make make test sudo make install This will install Python as python3 . ... Installing multiple versions On Unix and Mac systems if you intend to install multiple versions of Python using the same installation prefix ( --prefix argument to the configure script) you must take care that your primary python executable is not overwritten by the installation of a different version. All files and directories installed using make altinstall contain the major and minor version and can thus live side-by-side. make install also creates ${prefix}/bin/python3 which refers to ${prefix}/bin/pythonX.Y . If you intend to install multiple versions using the same prefix you must decide which version (if any) is your \"primary\" version. Install that version using make install . Install all other versions using make altinstall . To continue run make : $ ./configure $ make $ make test $ sudo make altinstall","title":"Installs"},{"location":"notes/python/Installs/#installs","text":"","title":"Installs"},{"location":"notes/python/Installs/#installing","text":"You an use wget to grab the latest like so: cd /usr/src sudo wget https://www.python.org/ftp/python/3.7.4/Python-3.7.4.tgz You can also go to https://www.python.org/ and download it. This gave me a Python-3.7.4.tar.xz file. To unzip it use: $ tar -xf Python-3.7.4.tar.xz $ ls -la drwxr-xr-x 18 bbearce bbearce 4096 Jul 8 14:31 Python-3.7.4 -rw-rw-r-- 1 bbearce bbearce 17131432 Sep 4 11:09 Python-3.7.4.tar.xz To see other unzipping techniques for different file types try here Change into that new directory and use make to install Python: $ cd Python-3.7.4 Note: Notice the README.rst $ vi README.rst ...","title":"Installing"},{"location":"notes/python/Installs/#build-instructions","text":"On Unix, Linux, BSD, macOS, and Cygwin:: ./configure make make test sudo make install This will install Python as python3 . ...","title":"Build Instructions"},{"location":"notes/python/Installs/#installing-multiple-versions","text":"On Unix and Mac systems if you intend to install multiple versions of Python using the same installation prefix ( --prefix argument to the configure script) you must take care that your primary python executable is not overwritten by the installation of a different version. All files and directories installed using make altinstall contain the major and minor version and can thus live side-by-side. make install also creates ${prefix}/bin/python3 which refers to ${prefix}/bin/pythonX.Y . If you intend to install multiple versions using the same prefix you must decide which version (if any) is your \"primary\" version. Install that version using make install . Install all other versions using make altinstall . To continue run make : $ ./configure $ make $ make test $ sudo make altinstall","title":"Installing multiple versions"},{"location":"notes/python/s3/","text":"Working with s3 Courtesy of these resources: https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-configure.html https://aws.amazon.com/cli/ https://boto3.amazonaws.com/v1/documentation/api/latest/guide/quickstart.html https://devcenter.heroku.com/articles/s3-upload-python import boto3 # Let's use Amazon S3 s3 = boto3.resource('s3') for bucket in s3.buckets.all(): print(bucket.name) # Upload a new file data = open('favicon-32x32.png', 'rb') s3.Bucket('thegratefulbrauer/recipe_description_images').put_object(Key='favicon-32x32.png', Body=data)","title":"S3"},{"location":"notes/python/s3/#working-with-s3","text":"Courtesy of these resources: https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-configure.html https://aws.amazon.com/cli/ https://boto3.amazonaws.com/v1/documentation/api/latest/guide/quickstart.html https://devcenter.heroku.com/articles/s3-upload-python import boto3 # Let's use Amazon S3 s3 = boto3.resource('s3') for bucket in s3.buckets.all(): print(bucket.name) # Upload a new file data = open('favicon-32x32.png', 'rb') s3.Bucket('thegratefulbrauer/recipe_description_images').put_object(Key='favicon-32x32.png', Body=data)","title":"Working with s3"},{"location":"notes/python/advanced/Classes/","text":"Classes Basic Class Definition Intro: - Class: Blueprint - Object - Instance class Shark: # Basic Method definition def swim(self): print(\"The shark is swimming.\") def be_awesome(self): print(\"The shark is being awesome.\") Notice the use of self to reference an instance specifically...the one calling the method. Implementing sammy = Shark() sammy.swim() # >>> The shark is swimming. sammy.be_awesome() # >>> The shark is being awesome. Now let's dicuss init . class Shark: def __init__(self): print(\"This is the constructor method.\") >>> Shark() This is the constructor method. <__main__.Shark object at 0x10348d470> Finally, we can set the name of the Shark object sammy as equal to \"Sammy\" by passing it as a parameter of the Shark class: class Shark: def __init__(self, name): self.name = name def swim(self): print(self.name + \" is swimming.\") def be_awesome(self): print(self.name + \" is being awesome.\") def main(): # Set name of Shark object sammy = Shark(\"Sammy\") sammy.swim() sammy.be_awesome() if __name__ == \"__main__\": main() run... $ python shark.py Sammy is swimming. Sammy is being awesome. Inheritance super() and inheritance. In this tutorial, you\u2019ll learn about the following: The concept of inheritance in Python Multiple inheritance in Python How the super() function works How the super() function in single inheritance works How the super() function in multiple inheritance works Let's start with a simple example: class Rectangle: def __init__(self, length, width): self.length = length self.width = width def area(self): return self.length * self.width def perimeter(self): return 2 * self.length + 2 * self.width class Square: def __init__(self, length): self.length = length def area(self): return self.length * self.length def perimeter(self): return 4 * self.length >>> square = Square(4) >>> square.area() 16 >>> rectangle = Rectangle(2,4) >>> rectangle.area() 8 Here no references to inheritance are being made. super() in Single Inheritance super() gives you access to methods in a superclass from the subclass that inherits from it. super() alone returns a temporary object of the superclass that then allows you to call that superclass\u2019s methods. By using inheritance, you can reduce the amount of code you write while simultaneously reflecting the real-world relationship between rectangles and squares: class Rectangle: def __init__(self, length, width): self.length = length self.width = width def area(self): return self.length * self.width def perimeter(self): return 2 * self.length + 2 * self.width # Here we declare that the Square class inherits from the Rectangle class class Square(Rectangle): def __init__(self, length): super().__init__(length, length) >>> square = Square(4) >>> square.area() 16 What Can super() Do for You? Like in other object-oriented languages, it allows you to call methods of the superclass in your subclass. The primary use case of this is to extend the functionality of the inherited method. In the example below, you will create a class Cube that inherits from Square and extends the functionality of .area() (inherited from the Rectangle class through Square) to calculate the surface area and volume of a Cube instance: class Square(Rectangle): def __init__(self, length): super().__init__(length, length) class Cube(Square): def surface_area(self): face_area = super().area() return face_area * 6 def volume(self): face_area = super().area() return face_area * self.length >>> cube = Cube(3) >>> cube.surface_area() 54 >>> cube.volume() 27 Here you have implemented two methods for the Cube class: .surface_area() and .volume(). Both of these calculations rely on calculating the area of a single face, so rather than reimplementing the area calculation, you use super() to extend the area calculation. Also notice that the Cube class definition does not have an . init (). Because Cube inherits from Square and . init () doesn\u2019t really do anything differently for Cube than it already does for Square, you can skip defining it, and the . init () of the superclass (Square) will be called automatically. A super() Deep Dive While the examples above (and below) call super() without any parameters, super() can also take two parameters: the first is the subclass, and the second parameter is an object that is an instance of that subclass. First, let\u2019s see two examples showing what manipulating the first variable can do, using the classes already shown: class Rectangle: def __init__(self, length, width): self.length = length self.width = width def area(self): return self.length * self.width def perimeter(self): return 2 * self.length + 2 * self.width class Square(Rectangle): def __init__(self, length): super(Square, self).__init__(length, length) In Python 3, the super(Square, self) call is equivalent to the parameterless super() call. The first parameter refers to the subclass Square, while the second parameter refers to a Square object which, in this case, is self. You can call super() with other classes as well: class Cube(Square): def surface_area(self): face_area = super(Square, self).area() return face_area * 6 def volume(self): face_area = super(Square, self).area() return face_area * self.length In this example, you are setting Square as the subclass argument to super(), instead of Cube. This causes super() to start searching for a matching method (in this case, .area()) at one level above Square in the instance hierarchy, in this case Rectangle. In this specific example, the behavior doesn\u2019t change. But imagine that Square also implemented an .area() function that you wanted to make sure Cube did not use. Calling super() in this way allows you to do that. What about the second parameter? Remember, this is an object that is an instance of the class used as the first parameter. For an example, isinstance(Cube, Square) must return True. By including an instantiated object, super() returns a bound method: a method that is bound to the object, which gives the method the object\u2019s context such as any instance attributes. If this parameter is not included, the method returned is just a function, unassociated with an object\u2019s context. For more information about bound methods, unbound methods, and functions, read the Python documentation on its descriptor system . Multiple Inheritance and Composition super() in Multiple Inheritance Now that you\u2019ve worked through an overview and some examples of super() and single inheritance, you will be introduced to an overview and some examples that will demonstrate how multiple inheritance works and how super() enables that functionality. Multiple Inheritance Overview There is another use case in which super() really shines, and this one isn\u2019t as common as the single inheritance scenario. In addition to single inheritance, Python supports multiple inheritance, in which a subclass can inherit from multiple superclasses that don\u2019t necessarily inherit from each other (also known as sibling classes). Superclass 1 Superclass 2 | | | | | | | | | | ------> Subclass <------- Let's get reacquainted with our base code: class Rectangle: def __init__(self, length, width): self.length = length self.width = width def area(self): return self.length * self.width def perimeter(self): return 2 * self.length + 2 * self.width class Square(Rectangle): def __init__(self, length): super(Square, self).__init__(length, length) Now let's proceed... To better illustrate multiple inheritance in action, here is some code for you to try out, showing how you can build a right pyramid (a pyramid with a square base) out of a Triangle and a Square: class Triangle: def __init__(self, base, height): self.base = base self.height = height def area(self): return 0.5 * self.base * self.height class RightPyramid(Triangle, Square): def __init__(self, base, slant_height): self.base = base self.slant_height = slant_height def area(self): base_area = super().area() perimeter = super().perimeter() return 0.5 * perimeter * self.slant_height + base_area This example declares a Triangle class and a RightPyramid class that inherits from both Square and Triangle. You\u2019ll see another .area() method that uses super() just like in single inheritance, with the aim of it reaching the .perimeter() and .area() methods defined all the way up in the Rectangle class. The problem, though, is that both superclasses (Triangle and Square) define a .area(). Take a second and think about what might happen when you call .area() on RightPyramid, and then try calling it like below: >> pyramid = RightPyramid(2, 4) >> pyramid.area() Traceback (most recent call last): File \"shapes.py\", line 63, in print(pyramid.area()) File \"shapes.py\", line 47, in area base_area = super().area() File \"shapes.py\", line 38, in area return 0.5 * self.base * self.height AttributeError: 'RightPyramid' object has no attribute 'height' Did you guess that Python will try to call Triangle.area()? This is because of something called the method resolution order. Method Resolution Order The method resolution order (or MRO) tells Python how to search for inherited methods. This comes in handy when you\u2019re using super() because the MRO tells you exactly where Python will look for a method you\u2019re calling with super() and in what order. Every class has an . mro attribute that allows us to inspect the order, so let\u2019s do that: >>> RightPyramid.__mro__ (<class '__main__.RightPyramid'>, <class '__main__.Triangle'>, <class '__main__.Square'>, <class '__main__.Rectangle'>, <class 'object'>) This tells us that methods will be searched first in Rightpyramid, then in Triangle, then in Square, then Rectangle, and then, if nothing is found, in object, from which all classes originate. The problem here is that the interpreter is searching for .area() in Triangle before Square and Rectangle, and upon finding .area() in Triangle, Python calls it instead of the one you want. Because Triangle.area() expects there to be a .height and a .base attribute, Python throws an AttributeError. The problem here is that the interpreter is searching for .area() in Triangle before Square and Rectangle, and upon finding .area() in Triangle, Python calls it instead of the one you want. Because Triangle.area() expects there to be a .height and a .base attribute, Python throws an AttributeError. Luckily, you have some control over how the MRO is constructed. Just by changing the signature of the RightPyramid class, you can search in the order you want, and the methods will resolve correctly: class RightPyramid(Square, Triangle): def __init__(self, base, slant_height): self.base = base self.slant_height = slant_height super().__init__(self.base) def area(self): base_area = super().area() perimeter = super().perimeter() return 0.5 * perimeter * self.slant_height + base_area Notice that RightPyramid initializes partially with the . init () from the Square class. This allows .area() to use the .length on the object, as is designed. Now, you can build a pyramid, inspect the MRO, and calculate the surface area: >>> pyramid = RightPyramid(2, 4) >>> RightPyramid.__mro__ (<class '__main__.RightPyramid'>, <class '__main__.Square'>, <class '__main__.Rectangle'>, <class '__main__.Triangle'>, <class 'object'>) >>> pyramid.area() 20.0 You see that the MRO is now what you\u2019d expect, and you can inspect the area of the pyramid as well, thanks to .area() and .perimeter(). There\u2019s still a problem here, though. For the sake of simplicity, I did a few things wrong in this example: the first, and arguably most importantly, was that I had two separate classes with the same method name and signature. This causes issues with method resolution, because the first instance of .area() that is encountered in the MRO list will be called. When you\u2019re using super() with multiple inheritance, it\u2019s imperative to design your classes to cooperate. Part of this is ensuring that your methods are unique so that they get resolved in the MRO, by making sure method signatures are unique\u2014whether by using method names or method parameters. In this case, to avoid a complete overhaul of your code, you can rename the Triangle class\u2019s .area() method to .tri_area(). This way, the area methods can continue using class properties rather than taking external parameters: class Triangle: def __init__(self, base, height): self.base = base self.height = height super().__init__() def tri_area(self): return 0.5 * self.base * self.height Let\u2019s also go ahead and use this in the RightPyramid class: class RightPyramid(Square, Triangle): def __init__(self, base, slant_height): self.base = base self.slant_height = slant_height super().__init__(self.base) def area(self): base_area = super().area() perimeter = super().perimeter() return 0.5 * perimeter * self.slant_height + base_area def area_2(self): base_area = super().area() triangle_area = super().tri_area() return triangle_area * 4 + base_area The next issue here is that the code doesn\u2019t have a delegated Triangle object like it does for a Square object, so calling .area_2() will give us an AttributeError since .base and .height don\u2019t have any values. You need to do two things to fix this: All methods that are called with super() need to have a call to their superclass\u2019s version of that method. This means that you will need to add super(). init () to the . init () methods of Triangle and Rectangle. Redesign all the . init () calls to take a keyword dictionary. See the complete code below. class Rectangle: def __init__(self, length, width, **kwargs): self.length = length self.width = width super().__init__(**kwargs) def area(self): return self.length * self.width def perimeter(self): return 2 * self.length + 2 * self.width # Here we declare that the Square class inherits from # the Rectangle class class Square(Rectangle): def __init__(self, length, **kwargs): super().__init__(length=length, width=length, **kwargs) class Cube(Square): def surface_area(self): face_area = super().area() return face_area * 6 def volume(self): face_area = super().area() return face_area * self.length class Triangle: def __init__(self, base, height, **kwargs): self.base = base self.height = height super().__init__(**kwargs) def tri_area(self): return 0.5 * self.base * self.height class RightPyramid(Square, Triangle): def __init__(self, base, slant_height, **kwargs): self.base = base self.slant_height = slant_height kwargs[\"height\"] = slant_height kwargs[\"length\"] = base super().__init__(base=base, **kwargs) def area(self): base_area = super().area() perimeter = super().perimeter() return 0.5 * perimeter * self.slant_height + base_area def area_2(self): base_area = super().area() triangle_area = super().tri_area() return triangle_area * 4 + base_area There are a number of important differences in this code: kwargs is modified in some places (such as RightPyramid. init ()): This will allow users of these objects to instantiate them only with the arguments that make sense for that particular object. Setting up named arguments before kwargs: You can see this in RightPyramid. init (). This has the neat effect of popping that key right out of the kwargs dictionary, so that by the time that it ends up at the end of the MRO in the object class, **kwargs is empty. Now, when you use these updated classes, you have this: >>> pyramid = RightPyramid(base=2, slant_height=4) >>> pyramid.area() 20.0 >>> pyramid.area_2() 20.0 It works! You\u2019ve used super() to successfully navigate a complicated class hierarchy while using both inheritance and composition to create new classes with minimal reimplementation. Quiz!!! When Rectangle calls super() what are the values of kwargs and what class gets it's init method called Answer: kwargs is still containing {'base': 2, 'height': 4} values as they haven't been removed from kwargs super().__init__(**kwargs) calls Triangle's init , but Rectangle doesn't inherit from Triangle so why? Remember the MRO? Let's look at RightPyramid's MRO >>> RightPyramid.__mro__ (<class '__main__.RightPyramid'>, <class '__main__.Square'>, <class '__main__.Rectangle'>, <class '__main__.Triangle'>, <class 'object'>) Even though Rectangle doesn't inherit from Triangle, Triangle is next in the list of classes to search for an init method. You'll notice object is at the end of the list. super().__init__(**kwargs) Multiple Inheritance Alternatives As you can see, multiple inheritance can be useful but also lead to very complicated situations and code that is hard to read. It\u2019s also rare to have objects that neatly inherit everything from more than multiple other objects. If you see yourself beginning to use multiple inheritance and a complicated class hierarchy, it\u2019s worth asking yourself if you can achieve code that is cleaner and easier to understand by using composition instead of inheritance. With composition, you can add very specific functionality to your classes from a specialized, simple class called a mixin. Since this article is focused on inheritance, I won\u2019t go into too much detail on composition and how to wield it in Python, but here\u2019s a short example using VolumeMixin to give specific functionality to our 3D objects\u2014in this case, a volume calculation: class Rectangle: def __init__(self, length, width): self.length = length self.width = width def area(self): return self.length * self.width class Square(Rectangle): def __init__(self, length): super().__init__(length, length) class VolumeMixin: def volume(self): return self.area() * self.height class Cube(VolumeMixin, Square): def __init__(self, length): super().__init__(length) self.height = length def face_area(self): return super().area() def surface_area(self): return super().area() * 6 In this example, the code was reworked to include a mixin called VolumeMixin. The mixin is then used by Cube and gives Cube the ability to calculate its volume, which is shown below: >>> cube = Cube(2) >>> cube.surface_area() 24 >>> cube.volume() 8 A super() Recap In this tutorial, you learned how to supercharge your classes with super(). Your journey started with a review of single inheritance and then showed how to call superclass methods easily with super(). You then learned how multiple inheritance works in Python, and techniques to combine super() with multiple inheritance. You also learned about how Python resolves method calls using the method resolution order (MRO), as well as how to inspect and modify the MRO to ensure appropriate methods are called at appropriate times. For more information about object-oriented programming in Python and using super(), check out these resources: Official super() documentation Python\u2019s super() Considered Super by Raymond Hettinger Object-Oriented Programming in Python 3","title":"Classes"},{"location":"notes/python/advanced/Classes/#classes","text":"","title":"Classes"},{"location":"notes/python/advanced/Classes/#basic-class-definition","text":"Intro: - Class: Blueprint - Object - Instance class Shark: # Basic Method definition def swim(self): print(\"The shark is swimming.\") def be_awesome(self): print(\"The shark is being awesome.\") Notice the use of self to reference an instance specifically...the one calling the method. Implementing sammy = Shark() sammy.swim() # >>> The shark is swimming. sammy.be_awesome() # >>> The shark is being awesome. Now let's dicuss init . class Shark: def __init__(self): print(\"This is the constructor method.\") >>> Shark() This is the constructor method. <__main__.Shark object at 0x10348d470> Finally, we can set the name of the Shark object sammy as equal to \"Sammy\" by passing it as a parameter of the Shark class: class Shark: def __init__(self, name): self.name = name def swim(self): print(self.name + \" is swimming.\") def be_awesome(self): print(self.name + \" is being awesome.\") def main(): # Set name of Shark object sammy = Shark(\"Sammy\") sammy.swim() sammy.be_awesome() if __name__ == \"__main__\": main() run... $ python shark.py Sammy is swimming. Sammy is being awesome.","title":"Basic Class Definition"},{"location":"notes/python/advanced/Classes/#inheritance","text":"super() and inheritance. In this tutorial, you\u2019ll learn about the following: The concept of inheritance in Python Multiple inheritance in Python How the super() function works How the super() function in single inheritance works How the super() function in multiple inheritance works Let's start with a simple example: class Rectangle: def __init__(self, length, width): self.length = length self.width = width def area(self): return self.length * self.width def perimeter(self): return 2 * self.length + 2 * self.width class Square: def __init__(self, length): self.length = length def area(self): return self.length * self.length def perimeter(self): return 4 * self.length >>> square = Square(4) >>> square.area() 16 >>> rectangle = Rectangle(2,4) >>> rectangle.area() 8 Here no references to inheritance are being made. super() in Single Inheritance super() gives you access to methods in a superclass from the subclass that inherits from it. super() alone returns a temporary object of the superclass that then allows you to call that superclass\u2019s methods. By using inheritance, you can reduce the amount of code you write while simultaneously reflecting the real-world relationship between rectangles and squares: class Rectangle: def __init__(self, length, width): self.length = length self.width = width def area(self): return self.length * self.width def perimeter(self): return 2 * self.length + 2 * self.width # Here we declare that the Square class inherits from the Rectangle class class Square(Rectangle): def __init__(self, length): super().__init__(length, length) >>> square = Square(4) >>> square.area() 16 What Can super() Do for You? Like in other object-oriented languages, it allows you to call methods of the superclass in your subclass. The primary use case of this is to extend the functionality of the inherited method. In the example below, you will create a class Cube that inherits from Square and extends the functionality of .area() (inherited from the Rectangle class through Square) to calculate the surface area and volume of a Cube instance: class Square(Rectangle): def __init__(self, length): super().__init__(length, length) class Cube(Square): def surface_area(self): face_area = super().area() return face_area * 6 def volume(self): face_area = super().area() return face_area * self.length >>> cube = Cube(3) >>> cube.surface_area() 54 >>> cube.volume() 27 Here you have implemented two methods for the Cube class: .surface_area() and .volume(). Both of these calculations rely on calculating the area of a single face, so rather than reimplementing the area calculation, you use super() to extend the area calculation. Also notice that the Cube class definition does not have an . init (). Because Cube inherits from Square and . init () doesn\u2019t really do anything differently for Cube than it already does for Square, you can skip defining it, and the . init () of the superclass (Square) will be called automatically. A super() Deep Dive While the examples above (and below) call super() without any parameters, super() can also take two parameters: the first is the subclass, and the second parameter is an object that is an instance of that subclass. First, let\u2019s see two examples showing what manipulating the first variable can do, using the classes already shown: class Rectangle: def __init__(self, length, width): self.length = length self.width = width def area(self): return self.length * self.width def perimeter(self): return 2 * self.length + 2 * self.width class Square(Rectangle): def __init__(self, length): super(Square, self).__init__(length, length) In Python 3, the super(Square, self) call is equivalent to the parameterless super() call. The first parameter refers to the subclass Square, while the second parameter refers to a Square object which, in this case, is self. You can call super() with other classes as well: class Cube(Square): def surface_area(self): face_area = super(Square, self).area() return face_area * 6 def volume(self): face_area = super(Square, self).area() return face_area * self.length In this example, you are setting Square as the subclass argument to super(), instead of Cube. This causes super() to start searching for a matching method (in this case, .area()) at one level above Square in the instance hierarchy, in this case Rectangle. In this specific example, the behavior doesn\u2019t change. But imagine that Square also implemented an .area() function that you wanted to make sure Cube did not use. Calling super() in this way allows you to do that. What about the second parameter? Remember, this is an object that is an instance of the class used as the first parameter. For an example, isinstance(Cube, Square) must return True. By including an instantiated object, super() returns a bound method: a method that is bound to the object, which gives the method the object\u2019s context such as any instance attributes. If this parameter is not included, the method returned is just a function, unassociated with an object\u2019s context. For more information about bound methods, unbound methods, and functions, read the Python documentation on its descriptor system .","title":"Inheritance"},{"location":"notes/python/advanced/Classes/#multiple-inheritance-and-composition","text":"super() in Multiple Inheritance Now that you\u2019ve worked through an overview and some examples of super() and single inheritance, you will be introduced to an overview and some examples that will demonstrate how multiple inheritance works and how super() enables that functionality. Multiple Inheritance Overview There is another use case in which super() really shines, and this one isn\u2019t as common as the single inheritance scenario. In addition to single inheritance, Python supports multiple inheritance, in which a subclass can inherit from multiple superclasses that don\u2019t necessarily inherit from each other (also known as sibling classes). Superclass 1 Superclass 2 | | | | | | | | | | ------> Subclass <------- Let's get reacquainted with our base code: class Rectangle: def __init__(self, length, width): self.length = length self.width = width def area(self): return self.length * self.width def perimeter(self): return 2 * self.length + 2 * self.width class Square(Rectangle): def __init__(self, length): super(Square, self).__init__(length, length) Now let's proceed... To better illustrate multiple inheritance in action, here is some code for you to try out, showing how you can build a right pyramid (a pyramid with a square base) out of a Triangle and a Square: class Triangle: def __init__(self, base, height): self.base = base self.height = height def area(self): return 0.5 * self.base * self.height class RightPyramid(Triangle, Square): def __init__(self, base, slant_height): self.base = base self.slant_height = slant_height def area(self): base_area = super().area() perimeter = super().perimeter() return 0.5 * perimeter * self.slant_height + base_area This example declares a Triangle class and a RightPyramid class that inherits from both Square and Triangle. You\u2019ll see another .area() method that uses super() just like in single inheritance, with the aim of it reaching the .perimeter() and .area() methods defined all the way up in the Rectangle class. The problem, though, is that both superclasses (Triangle and Square) define a .area(). Take a second and think about what might happen when you call .area() on RightPyramid, and then try calling it like below: >> pyramid = RightPyramid(2, 4) >> pyramid.area() Traceback (most recent call last): File \"shapes.py\", line 63, in print(pyramid.area()) File \"shapes.py\", line 47, in area base_area = super().area() File \"shapes.py\", line 38, in area return 0.5 * self.base * self.height AttributeError: 'RightPyramid' object has no attribute 'height' Did you guess that Python will try to call Triangle.area()? This is because of something called the method resolution order. Method Resolution Order The method resolution order (or MRO) tells Python how to search for inherited methods. This comes in handy when you\u2019re using super() because the MRO tells you exactly where Python will look for a method you\u2019re calling with super() and in what order. Every class has an . mro attribute that allows us to inspect the order, so let\u2019s do that: >>> RightPyramid.__mro__ (<class '__main__.RightPyramid'>, <class '__main__.Triangle'>, <class '__main__.Square'>, <class '__main__.Rectangle'>, <class 'object'>) This tells us that methods will be searched first in Rightpyramid, then in Triangle, then in Square, then Rectangle, and then, if nothing is found, in object, from which all classes originate. The problem here is that the interpreter is searching for .area() in Triangle before Square and Rectangle, and upon finding .area() in Triangle, Python calls it instead of the one you want. Because Triangle.area() expects there to be a .height and a .base attribute, Python throws an AttributeError. The problem here is that the interpreter is searching for .area() in Triangle before Square and Rectangle, and upon finding .area() in Triangle, Python calls it instead of the one you want. Because Triangle.area() expects there to be a .height and a .base attribute, Python throws an AttributeError. Luckily, you have some control over how the MRO is constructed. Just by changing the signature of the RightPyramid class, you can search in the order you want, and the methods will resolve correctly: class RightPyramid(Square, Triangle): def __init__(self, base, slant_height): self.base = base self.slant_height = slant_height super().__init__(self.base) def area(self): base_area = super().area() perimeter = super().perimeter() return 0.5 * perimeter * self.slant_height + base_area Notice that RightPyramid initializes partially with the . init () from the Square class. This allows .area() to use the .length on the object, as is designed. Now, you can build a pyramid, inspect the MRO, and calculate the surface area: >>> pyramid = RightPyramid(2, 4) >>> RightPyramid.__mro__ (<class '__main__.RightPyramid'>, <class '__main__.Square'>, <class '__main__.Rectangle'>, <class '__main__.Triangle'>, <class 'object'>) >>> pyramid.area() 20.0 You see that the MRO is now what you\u2019d expect, and you can inspect the area of the pyramid as well, thanks to .area() and .perimeter(). There\u2019s still a problem here, though. For the sake of simplicity, I did a few things wrong in this example: the first, and arguably most importantly, was that I had two separate classes with the same method name and signature. This causes issues with method resolution, because the first instance of .area() that is encountered in the MRO list will be called. When you\u2019re using super() with multiple inheritance, it\u2019s imperative to design your classes to cooperate. Part of this is ensuring that your methods are unique so that they get resolved in the MRO, by making sure method signatures are unique\u2014whether by using method names or method parameters. In this case, to avoid a complete overhaul of your code, you can rename the Triangle class\u2019s .area() method to .tri_area(). This way, the area methods can continue using class properties rather than taking external parameters: class Triangle: def __init__(self, base, height): self.base = base self.height = height super().__init__() def tri_area(self): return 0.5 * self.base * self.height Let\u2019s also go ahead and use this in the RightPyramid class: class RightPyramid(Square, Triangle): def __init__(self, base, slant_height): self.base = base self.slant_height = slant_height super().__init__(self.base) def area(self): base_area = super().area() perimeter = super().perimeter() return 0.5 * perimeter * self.slant_height + base_area def area_2(self): base_area = super().area() triangle_area = super().tri_area() return triangle_area * 4 + base_area The next issue here is that the code doesn\u2019t have a delegated Triangle object like it does for a Square object, so calling .area_2() will give us an AttributeError since .base and .height don\u2019t have any values. You need to do two things to fix this: All methods that are called with super() need to have a call to their superclass\u2019s version of that method. This means that you will need to add super(). init () to the . init () methods of Triangle and Rectangle. Redesign all the . init () calls to take a keyword dictionary. See the complete code below. class Rectangle: def __init__(self, length, width, **kwargs): self.length = length self.width = width super().__init__(**kwargs) def area(self): return self.length * self.width def perimeter(self): return 2 * self.length + 2 * self.width # Here we declare that the Square class inherits from # the Rectangle class class Square(Rectangle): def __init__(self, length, **kwargs): super().__init__(length=length, width=length, **kwargs) class Cube(Square): def surface_area(self): face_area = super().area() return face_area * 6 def volume(self): face_area = super().area() return face_area * self.length class Triangle: def __init__(self, base, height, **kwargs): self.base = base self.height = height super().__init__(**kwargs) def tri_area(self): return 0.5 * self.base * self.height class RightPyramid(Square, Triangle): def __init__(self, base, slant_height, **kwargs): self.base = base self.slant_height = slant_height kwargs[\"height\"] = slant_height kwargs[\"length\"] = base super().__init__(base=base, **kwargs) def area(self): base_area = super().area() perimeter = super().perimeter() return 0.5 * perimeter * self.slant_height + base_area def area_2(self): base_area = super().area() triangle_area = super().tri_area() return triangle_area * 4 + base_area There are a number of important differences in this code: kwargs is modified in some places (such as RightPyramid. init ()): This will allow users of these objects to instantiate them only with the arguments that make sense for that particular object. Setting up named arguments before kwargs: You can see this in RightPyramid. init (). This has the neat effect of popping that key right out of the kwargs dictionary, so that by the time that it ends up at the end of the MRO in the object class, **kwargs is empty. Now, when you use these updated classes, you have this: >>> pyramid = RightPyramid(base=2, slant_height=4) >>> pyramid.area() 20.0 >>> pyramid.area_2() 20.0 It works! You\u2019ve used super() to successfully navigate a complicated class hierarchy while using both inheritance and composition to create new classes with minimal reimplementation. Quiz!!! When Rectangle calls super() what are the values of kwargs and what class gets it's init method called Answer: kwargs is still containing {'base': 2, 'height': 4} values as they haven't been removed from kwargs super().__init__(**kwargs) calls Triangle's init , but Rectangle doesn't inherit from Triangle so why? Remember the MRO? Let's look at RightPyramid's MRO >>> RightPyramid.__mro__ (<class '__main__.RightPyramid'>, <class '__main__.Square'>, <class '__main__.Rectangle'>, <class '__main__.Triangle'>, <class 'object'>) Even though Rectangle doesn't inherit from Triangle, Triangle is next in the list of classes to search for an init method. You'll notice object is at the end of the list. super().__init__(**kwargs) Multiple Inheritance Alternatives As you can see, multiple inheritance can be useful but also lead to very complicated situations and code that is hard to read. It\u2019s also rare to have objects that neatly inherit everything from more than multiple other objects. If you see yourself beginning to use multiple inheritance and a complicated class hierarchy, it\u2019s worth asking yourself if you can achieve code that is cleaner and easier to understand by using composition instead of inheritance. With composition, you can add very specific functionality to your classes from a specialized, simple class called a mixin. Since this article is focused on inheritance, I won\u2019t go into too much detail on composition and how to wield it in Python, but here\u2019s a short example using VolumeMixin to give specific functionality to our 3D objects\u2014in this case, a volume calculation: class Rectangle: def __init__(self, length, width): self.length = length self.width = width def area(self): return self.length * self.width class Square(Rectangle): def __init__(self, length): super().__init__(length, length) class VolumeMixin: def volume(self): return self.area() * self.height class Cube(VolumeMixin, Square): def __init__(self, length): super().__init__(length) self.height = length def face_area(self): return super().area() def surface_area(self): return super().area() * 6 In this example, the code was reworked to include a mixin called VolumeMixin. The mixin is then used by Cube and gives Cube the ability to calculate its volume, which is shown below: >>> cube = Cube(2) >>> cube.surface_area() 24 >>> cube.volume() 8 A super() Recap In this tutorial, you learned how to supercharge your classes with super(). Your journey started with a review of single inheritance and then showed how to call superclass methods easily with super(). You then learned how multiple inheritance works in Python, and techniques to combine super() with multiple inheritance. You also learned about how Python resolves method calls using the method resolution order (MRO), as well as how to inspect and modify the MRO to ensure appropriate methods are called at appropriate times. For more information about object-oriented programming in Python and using super(), check out these resources: Official super() documentation Python\u2019s super() Considered Super by Raymond Hettinger Object-Oriented Programming in Python 3","title":"Multiple Inheritance and Composition"},{"location":"notes/python/advanced/Decorators/","text":"Decorators @Add_This_Functionality_To_Any_Function! Simple Example: def my_decorator(original_function): def new_function(*args,**kwargs): print(\"you did it!\") of = original_function(*args,**kwargs) return of return new_function @my_decorator def my_func1(stuff): print(\"do things\") @my_decorator def my_func2(stuff): print(\"do things\") @my_decorator def my_func3(stuff): print(\"do things\") my_func1(1);my_func2(1);my_func3(1); Tutorial: We need to discuss global variables and function closure [1] functions: def foo(): return 1; [2] scope a_string = 'this is a string' def foo(): print(locals()) foo() # {} print(globals()) # {..., 'a_string': 'this is a string'} [3] varible resolution rules Local variables with the same name as global ones don't modify the global one. [4] variable lifetime def foo(): x = 1; foo() # NameError: name 'x' is not defined [5] function arguments and parameters def foo(x): print(locals()) foo(1) # {'x': 1} def foo(x, y=0): # remember if no default it's mandatory return x - y foo() # Traceback (most recent call last): # File \"\", line 1, in # TypeError: foo() missing 1 required positional argument: 'x' [6] Nested Functions def outer(): x = 1 def inner(): print(x) inner() outer() # 1 [7] Functions are first class objectsin python # all objects in Python inherit from a common baseclass issubclass(int, object) # True def foo(): pass foo.__class__ # <type 'function'> issubclass(foo.__class__, object) # True #..so what? def add(x,y): return x + y def sub(x,y): return x - y def apply(func, x, y): return func(x, y) apply(add, 2, 1) # 3 apply(sub, 2, 1) # 1 #.. closure lead in def outer(): def inner(): print('this is inner') return inner # the function not what it returns foo = outer() foo # .inner at 0x10be011e0> foo() # 'this is inner' [8] Closures def outer(): x = 1 def inner(): print(x) return inner # the function not what it returns foo = outer() foo.__closure__ # (,) # aside: cell objects are used to store the free variables of a closure # without closures x would have not existed as after the call to outer x is gone based on variable life time. # inner functions defined in non-global scope remember what their enclosing namespaces looked like at definition time. foo() # 1 # let's tweak it def outer(x): def inner(): print(x) return inner print1 = outer(1) print2 = outer(2) print1() # 1 print2() # 2 [9] Decorators def outer(some_func): def inner(): print('before some_func') ret = some_func() # 1 return ret + 1 return inner def foo(): return 1 decorated = outer(foo) decorated() # we've added functionality to foo()! # what if we did this foo = outer(foo) foo() # before some_func # 2 # Let's write a more useful decorator class Coordinate(object): def __init__(self, x, y): self.x = x self.y = y def __repr__(self): return \"Coord: \" + str(self.__dict__) def add(a, b): return Coordinate(a.x + b.x, a.y + b.y) def sub(a, b): return Coordinate(a.x - b.x, a.y - b.y) one = Coordinate(100, 200) two = Coordinate(300, 200) add(one, two) # Coord: {'y': 400, 'x': 400} # add this instance three = Coordinate(-100, -100) def wrapper(func): def checker(a, b): # 1 if a.x < 0 or a.y < 0: a = Coordinate(a.x if a.x > 0 else 0, a.y if a.y > 0 else 0) if b.x < 0 or b.y < 0: b = Coordinate(b.x if b.x > 0 else 0, b.y if b.y > 0 else 0) ret = func(a, b) if ret.x < 0 or ret.y < 0: ret = Coordinate(ret.x if ret.x > 0 else 0, ret.y if ret.y > 0 else 0) return ret return checker add = wrapper(add) sub = wrapper(sub) sub(one, two) add(one, three) [10] the @ symbol # so instead of wrapper(add)\\wrapper(sub), use @wrapper @wrapper def add(a, b): return Coordinate(a.x + b.x, a.y + b.y) @wrapper def sub(a, b): return Coordinate(a.x - b.x, a.y - b.y) [11] *args and **kwargs def one(*args): print(args) one() # () one(1,2,3) # (1, 2, 3) def two(x, y, *args): print(x, y, args) two('a','b','c') # Reminder # l = (1,2,3) # one(l[0], l[1], l[2]) # (1, 2, 3) # one(*l) # (1, 2, 3) def foo(**kwargs): print(kwargs) foo() foo(x=1, y=2) [12] More generic decorators def logger(func): def inner(*args, **kwargs): print('Arguments were: {}, {}'.format(args,kwargs)) return func(*args, **kwargs) return inner @logger def foo1(x,y=1): return x * y @logger def foo2(): return 2 foo1(5,4) # Arguments were: (5, 4), {} # 20 foo2() # Arguments were: (), {} # 2","title":"Decorators"},{"location":"notes/python/advanced/Decorators/#decorators","text":"@Add_This_Functionality_To_Any_Function!","title":"Decorators"},{"location":"notes/python/advanced/Decorators/#simple-example","text":"def my_decorator(original_function): def new_function(*args,**kwargs): print(\"you did it!\") of = original_function(*args,**kwargs) return of return new_function @my_decorator def my_func1(stuff): print(\"do things\") @my_decorator def my_func2(stuff): print(\"do things\") @my_decorator def my_func3(stuff): print(\"do things\") my_func1(1);my_func2(1);my_func3(1);","title":"Simple Example:"},{"location":"notes/python/advanced/Decorators/#tutorial","text":"We need to discuss global variables and function closure","title":"Tutorial:"},{"location":"notes/python/advanced/Decorators/#1-functions","text":"def foo(): return 1;","title":"[1] functions:"},{"location":"notes/python/advanced/Decorators/#2-scope","text":"a_string = 'this is a string' def foo(): print(locals()) foo() # {} print(globals()) # {..., 'a_string': 'this is a string'}","title":"[2] scope"},{"location":"notes/python/advanced/Decorators/#3-varible-resolution-rules","text":"Local variables with the same name as global ones don't modify the global one.","title":"[3] varible resolution rules"},{"location":"notes/python/advanced/Decorators/#4-variable-lifetime","text":"def foo(): x = 1; foo() # NameError: name 'x' is not defined","title":"[4] variable lifetime"},{"location":"notes/python/advanced/Decorators/#5-function-arguments-and-parameters","text":"def foo(x): print(locals()) foo(1) # {'x': 1} def foo(x, y=0): # remember if no default it's mandatory return x - y foo() # Traceback (most recent call last): # File \"\", line 1, in # TypeError: foo() missing 1 required positional argument: 'x'","title":"[5] function arguments and parameters"},{"location":"notes/python/advanced/Decorators/#6-nested-functions","text":"def outer(): x = 1 def inner(): print(x) inner() outer() # 1","title":"[6] Nested Functions"},{"location":"notes/python/advanced/Decorators/#7-functions-are-first-class-objectsin-python","text":"# all objects in Python inherit from a common baseclass issubclass(int, object) # True def foo(): pass foo.__class__ # <type 'function'> issubclass(foo.__class__, object) # True #..so what? def add(x,y): return x + y def sub(x,y): return x - y def apply(func, x, y): return func(x, y) apply(add, 2, 1) # 3 apply(sub, 2, 1) # 1 #.. closure lead in def outer(): def inner(): print('this is inner') return inner # the function not what it returns foo = outer() foo # .inner at 0x10be011e0> foo() # 'this is inner'","title":"[7] Functions are first class objectsin python"},{"location":"notes/python/advanced/Decorators/#8-closures","text":"def outer(): x = 1 def inner(): print(x) return inner # the function not what it returns foo = outer() foo.__closure__ # (,) # aside: cell objects are used to store the free variables of a closure # without closures x would have not existed as after the call to outer x is gone based on variable life time. # inner functions defined in non-global scope remember what their enclosing namespaces looked like at definition time. foo() # 1 # let's tweak it def outer(x): def inner(): print(x) return inner print1 = outer(1) print2 = outer(2) print1() # 1 print2() # 2","title":"[8] Closures"},{"location":"notes/python/advanced/Decorators/#9-decorators","text":"def outer(some_func): def inner(): print('before some_func') ret = some_func() # 1 return ret + 1 return inner def foo(): return 1 decorated = outer(foo) decorated() # we've added functionality to foo()! # what if we did this foo = outer(foo) foo() # before some_func # 2 # Let's write a more useful decorator class Coordinate(object): def __init__(self, x, y): self.x = x self.y = y def __repr__(self): return \"Coord: \" + str(self.__dict__) def add(a, b): return Coordinate(a.x + b.x, a.y + b.y) def sub(a, b): return Coordinate(a.x - b.x, a.y - b.y) one = Coordinate(100, 200) two = Coordinate(300, 200) add(one, two) # Coord: {'y': 400, 'x': 400} # add this instance three = Coordinate(-100, -100) def wrapper(func): def checker(a, b): # 1 if a.x < 0 or a.y < 0: a = Coordinate(a.x if a.x > 0 else 0, a.y if a.y > 0 else 0) if b.x < 0 or b.y < 0: b = Coordinate(b.x if b.x > 0 else 0, b.y if b.y > 0 else 0) ret = func(a, b) if ret.x < 0 or ret.y < 0: ret = Coordinate(ret.x if ret.x > 0 else 0, ret.y if ret.y > 0 else 0) return ret return checker add = wrapper(add) sub = wrapper(sub) sub(one, two) add(one, three)","title":"[9] Decorators"},{"location":"notes/python/advanced/Decorators/#10-the-symbol","text":"# so instead of wrapper(add)\\wrapper(sub), use @wrapper @wrapper def add(a, b): return Coordinate(a.x + b.x, a.y + b.y) @wrapper def sub(a, b): return Coordinate(a.x - b.x, a.y - b.y)","title":"[10] the @ symbol"},{"location":"notes/python/advanced/Decorators/#11-42args-and-4242kwargs","text":"def one(*args): print(args) one() # () one(1,2,3) # (1, 2, 3) def two(x, y, *args): print(x, y, args) two('a','b','c') # Reminder # l = (1,2,3) # one(l[0], l[1], l[2]) # (1, 2, 3) # one(*l) # (1, 2, 3) def foo(**kwargs): print(kwargs) foo() foo(x=1, y=2)","title":"[11] *args and **kwargs"},{"location":"notes/python/advanced/Decorators/#12-more-generic-decorators","text":"def logger(func): def inner(*args, **kwargs): print('Arguments were: {}, {}'.format(args,kwargs)) return func(*args, **kwargs) return inner @logger def foo1(x,y=1): return x * y @logger def foo2(): return 2 foo1(5,4) # Arguments were: (5, 4), {} # 20 foo2() # Arguments were: (), {} # 2","title":"[12] More generic decorators"},{"location":"notes/python/advanced/Generators/","text":"Generators A simplified Iterator Quick Example: def all_even(): n = 0 while True: yield n n += 2 x = all_even() print(next(x)) # 0 print(next(x)) # 2 print(next(x)) # 4 #.... forever What are generators in Python? There is a lot of overhead in building an iterator in Python; we have to implement a class with iter () and next () method, keep track of internal states, raise StopIteration when there was no values to be returned etc. This is both lengthy and counter intuitive. Generator comes into rescue in such situations. Python generators are a simple way of creating iterators. All the overhead we mentioned above are automatically handled by generators in Python. Simply speaking, a generator is a function that returns an object (iterator) which we can iterate over (one value at a time). How to create a generator in Python? It is fairly simple to create a generator in Python. It is as easy as defining a normal function with yield statement instead of a return statement. If a function contains at least one yield statement (it may contain other yield or return statements), it becomes a generator function. Both yield and return will return some value from a function. The difference is that, while a return statement terminates a function entirely, yield statement pauses the function saving all its states and later continues from there on successive calls. Differences between Generator function and a Normal function Generator function contains one or more yield statement. When called, it returns an object (iterator) but does not start execution immediately. Methods like iter () and next () are implemented automatically. So we can iterate through the items using next(). Once the function yields, the function is paused and the control is transferred to the caller. Local variables and their states are remembered between successive calls. Finally, when the function terminates, StopIteration is raised automatically on further calls. Simple Example: # A simple generator function def my_gen(): n = 1 print('This is printed first') # Generator function contains yield statements yield n n += 1 print('This is printed second') yield n n += 1 print('This is printed at last') yield n mg = my_gen() next(mg) # This is printed first next(mg) # This is printed second next(mg) # This is printed third next(mg) # Raises error... One interesting thing to note in the above example is that, the value of variable n is remembered between each call. Unlike normal functions, the local variables are not destroyed when the function yields. Furthermore, the generator object can be iterated only once. To restart the process we need to create another generator object using something like a = my_gen(). Note: One final thing to note is that we can use generators with for loops directly. This is because, a for loop takes an iterator and iterates over it using next() function. It automatically ends when StopIteration is raised. Check here to know how a for loop is actually implemented in Python . Python Generators with a Loop The above example is of less use and we studied it just to get an idea of what was happening in the background. Normally, generator functions are implemented with a loop having a suitable terminating condition. Let's take an example of a generator that reverses a string. def rev_str(my_str): length = len(my_str) for i in range(length - 1,-1,-1): yield my_str[i] # For loop to reverse the string # Output: # o # l # l # e # h for char in rev_str(\"hello\"): print(char) In this example, we use range() function to get the index in reverse order using the for loop. It turns out that this generator function not only works with string, but also with other kind of iterables like list, tuple etc. Python Generator Expression Simple generators can be easily created on the fly using generator expressions. It makes building generators easy. Same as lambda function creates an anonymous function, generator expression creates an anonymous generator function. The syntax for generator expression is similar to that of a list comprehension in Python. But the square brackets are replaced with round parentheses. The major difference between a list comprehension and a generator expression is that while list comprehension produces the entire list, generator expression produces one item at a time. They are kind of lazy, producing items only when asked for. For this reason, a generator expression is much more memory efficient than an equivalent list comprehension. # Initialize the list my_list = [1, 3, 6, 10] # square each term using list comprehension # Output: [1, 9, 36, 100] [x**2 for x in my_list] # same thing can be done using generator expression # Output: at 0x0000000002EBDAF8> y = (x**2 for x in my_list) print(next(y)) # 1 print(next(y)) # 9 print(next(y)) # 36 print(next(y)) # 100 print(next(y)) # error Generator expression can be used inside functions. When used in such a way, the round parentheses can be dropped. >>> sum(x**2 for x in my_list) 146 >>> max(x**2 for x in my_list) 100 Why generators are used in Python? Easy to Implement: Generators can be implemented in a clear and concise way as compared to their iterator class counterpart. Following is an example to implement a sequence of power of 2's using iterator class. class PowTwo: def __init__(self, max = 0): self.max = max def __iter__(self): self.n = 0 return self def __next__(self): if self.n > self.max: raise StopIteration result = 2 ** self.n self.n += 1 return result This was lengthy. Now lets do the same using a generator function. def PowTwoGen(max = 0): n = 0 while n < max: yield 2 ** n n += 1 Memory Efficient: A normal function to return a sequence will create the entire sequence in memory before returning the result. This is an overkill if the number of items in the sequence is very large. Generator implementation of such sequence is memory friendly and is preferred since it only produces one item at a time. Represent Infinite Stream: Generators are excellent medium to represent an infinite stream of data. Infinite streams cannot be stored in memory and since generators produce only one item at a time, it can represent infinite stream of data. The following example can generate all the even numbers (at least in theory). def all_even(): n = 0 while True: yield n n += 2 Pipelining Generators: Generators can be used to pipeline a series of operations. This is best illustrated using an example. Suppose we have a log file from a famous fast food chain. The log file has a column (4th column) that keeps track of the number of pizza sold every hour and we want to sum it to find the total pizzas sold in 5 years. Assume everything is in string and numbers that are not available are marked as 'N/A'. A generator implementation of this could be as follows. # - sells.log - # # 1 2 3 1 # 1 2 3 2 # 1 2 3 3 # 1 2 3 4 # 1 2 3 5 # 1 2 3 6 # 1 2 3 7 # 1 2 3 8 # 1 2 3 9 # 1 2 3 10 # - - # with open('sells.log') as file: pizza_col = (line.split()[3] for line in file) per_hour = (int(x) for x in pizza_col if x != 'N/A') print(\"Total pizzas sold = \",sum(per_hour)) This pipelining is efficient and easy to read (and yes, a lot cooler!).","title":"Generators"},{"location":"notes/python/advanced/Generators/#generators","text":"A simplified Iterator","title":"Generators"},{"location":"notes/python/advanced/Generators/#quick-example","text":"def all_even(): n = 0 while True: yield n n += 2 x = all_even() print(next(x)) # 0 print(next(x)) # 2 print(next(x)) # 4 #.... forever","title":"Quick Example:"},{"location":"notes/python/advanced/Generators/#what-are-generators-in-python","text":"There is a lot of overhead in building an iterator in Python; we have to implement a class with iter () and next () method, keep track of internal states, raise StopIteration when there was no values to be returned etc. This is both lengthy and counter intuitive. Generator comes into rescue in such situations. Python generators are a simple way of creating iterators. All the overhead we mentioned above are automatically handled by generators in Python. Simply speaking, a generator is a function that returns an object (iterator) which we can iterate over (one value at a time).","title":"What are generators in Python?"},{"location":"notes/python/advanced/Generators/#how-to-create-a-generator-in-python","text":"It is fairly simple to create a generator in Python. It is as easy as defining a normal function with yield statement instead of a return statement. If a function contains at least one yield statement (it may contain other yield or return statements), it becomes a generator function. Both yield and return will return some value from a function. The difference is that, while a return statement terminates a function entirely, yield statement pauses the function saving all its states and later continues from there on successive calls.","title":"How to create a generator in Python?"},{"location":"notes/python/advanced/Generators/#differences-between-generator-function-and-a-normal-function","text":"Generator function contains one or more yield statement. When called, it returns an object (iterator) but does not start execution immediately. Methods like iter () and next () are implemented automatically. So we can iterate through the items using next(). Once the function yields, the function is paused and the control is transferred to the caller. Local variables and their states are remembered between successive calls. Finally, when the function terminates, StopIteration is raised automatically on further calls. Simple Example: # A simple generator function def my_gen(): n = 1 print('This is printed first') # Generator function contains yield statements yield n n += 1 print('This is printed second') yield n n += 1 print('This is printed at last') yield n mg = my_gen() next(mg) # This is printed first next(mg) # This is printed second next(mg) # This is printed third next(mg) # Raises error... One interesting thing to note in the above example is that, the value of variable n is remembered between each call. Unlike normal functions, the local variables are not destroyed when the function yields. Furthermore, the generator object can be iterated only once. To restart the process we need to create another generator object using something like a = my_gen(). Note: One final thing to note is that we can use generators with for loops directly. This is because, a for loop takes an iterator and iterates over it using next() function. It automatically ends when StopIteration is raised. Check here to know how a for loop is actually implemented in Python .","title":"Differences between Generator function and a Normal function"},{"location":"notes/python/advanced/Generators/#python-generators-with-a-loop","text":"The above example is of less use and we studied it just to get an idea of what was happening in the background. Normally, generator functions are implemented with a loop having a suitable terminating condition. Let's take an example of a generator that reverses a string. def rev_str(my_str): length = len(my_str) for i in range(length - 1,-1,-1): yield my_str[i] # For loop to reverse the string # Output: # o # l # l # e # h for char in rev_str(\"hello\"): print(char) In this example, we use range() function to get the index in reverse order using the for loop. It turns out that this generator function not only works with string, but also with other kind of iterables like list, tuple etc.","title":"Python Generators with a Loop"},{"location":"notes/python/advanced/Generators/#python-generator-expression","text":"Simple generators can be easily created on the fly using generator expressions. It makes building generators easy. Same as lambda function creates an anonymous function, generator expression creates an anonymous generator function. The syntax for generator expression is similar to that of a list comprehension in Python. But the square brackets are replaced with round parentheses. The major difference between a list comprehension and a generator expression is that while list comprehension produces the entire list, generator expression produces one item at a time. They are kind of lazy, producing items only when asked for. For this reason, a generator expression is much more memory efficient than an equivalent list comprehension. # Initialize the list my_list = [1, 3, 6, 10] # square each term using list comprehension # Output: [1, 9, 36, 100] [x**2 for x in my_list] # same thing can be done using generator expression # Output: at 0x0000000002EBDAF8> y = (x**2 for x in my_list) print(next(y)) # 1 print(next(y)) # 9 print(next(y)) # 36 print(next(y)) # 100 print(next(y)) # error Generator expression can be used inside functions. When used in such a way, the round parentheses can be dropped. >>> sum(x**2 for x in my_list) 146 >>> max(x**2 for x in my_list) 100","title":"Python Generator Expression"},{"location":"notes/python/advanced/Generators/#why-generators-are-used-in-python","text":"Easy to Implement: Generators can be implemented in a clear and concise way as compared to their iterator class counterpart. Following is an example to implement a sequence of power of 2's using iterator class. class PowTwo: def __init__(self, max = 0): self.max = max def __iter__(self): self.n = 0 return self def __next__(self): if self.n > self.max: raise StopIteration result = 2 ** self.n self.n += 1 return result This was lengthy. Now lets do the same using a generator function. def PowTwoGen(max = 0): n = 0 while n < max: yield 2 ** n n += 1 Memory Efficient: A normal function to return a sequence will create the entire sequence in memory before returning the result. This is an overkill if the number of items in the sequence is very large. Generator implementation of such sequence is memory friendly and is preferred since it only produces one item at a time. Represent Infinite Stream: Generators are excellent medium to represent an infinite stream of data. Infinite streams cannot be stored in memory and since generators produce only one item at a time, it can represent infinite stream of data. The following example can generate all the even numbers (at least in theory). def all_even(): n = 0 while True: yield n n += 2 Pipelining Generators: Generators can be used to pipeline a series of operations. This is best illustrated using an example. Suppose we have a log file from a famous fast food chain. The log file has a column (4th column) that keeps track of the number of pizza sold every hour and we want to sum it to find the total pizzas sold in 5 years. Assume everything is in string and numbers that are not available are marked as 'N/A'. A generator implementation of this could be as follows. # - sells.log - # # 1 2 3 1 # 1 2 3 2 # 1 2 3 3 # 1 2 3 4 # 1 2 3 5 # 1 2 3 6 # 1 2 3 7 # 1 2 3 8 # 1 2 3 9 # 1 2 3 10 # - - # with open('sells.log') as file: pizza_col = (line.split()[3] for line in file) per_hour = (int(x) for x in pizza_col if x != 'N/A') print(\"Total pizzas sold = \",sum(per_hour)) This pipelining is efficient and easy to read (and yes, a lot cooler!).","title":"Why generators are used in Python?"},{"location":"notes/python/base_modules/Pdb/","text":"Pdb Useage - Docs You can use import pdb pdb.set_trace() or New: as of 3.7 breakpoint() breakpoint() to enter debug mode. Hidden gems Use ! to escape default pdb commands like n(ext), c(ont(inue)) and h(elp) >>> c = 1 >>> breakpoint() --Return-- > <stdin>(1)<module>()->None (Pdb) !c 1 (Pdb)","title":"Pdb"},{"location":"notes/python/base_modules/Pdb/#pdb","text":"","title":"Pdb"},{"location":"notes/python/base_modules/Pdb/#useage-docs","text":"You can use import pdb pdb.set_trace() or New: as of 3.7 breakpoint() breakpoint() to enter debug mode.","title":"Useage - Docs"},{"location":"notes/python/base_modules/Pdb/#hidden-gems","text":"Use ! to escape default pdb commands like n(ext), c(ont(inue)) and h(elp) >>> c = 1 >>> breakpoint() --Return-- > <stdin>(1)<module>()->None (Pdb) !c 1 (Pdb)","title":"Hidden gems"},{"location":"notes/python/base_modules/collections/Counter/","text":"Counter Counter is a dict subclass for counting hashable objects: >>> c = Counter() # a new, empty counter >>> c Counter() >>> c = Counter('gallahad') # a new counter from an iterable >>> c Counter({'a': 3, 'l': 2, 'g': 1, 'h': 1, 'd': 1}) # a new counter from a mapping >>> c = Counter({'red': 4, 'blue': 2}) # a new counter from a mapping >>> c Counter({'red': 4, 'blue': 2}) >>> c = Counter(cats=4, dogs=8) # a new counter from keyword args >>> c Counter({'dogs': 8, 'cats': 4}) >>> Counter([1,2,2,3,3,3,4,4,4,4]) Counter({4: 4, 3: 3, 2: 2, 1: 1}) Delete objects as shown below: # Delete records as shown below: >>> c = Counter(['eggs', 'ham']) >>> c Counter({'eggs': 1, 'ham': 1}) >>> del c['ham'] >>> c Counter({'eggs': 1}) Counter objects support three methods beyond those available for all dictionaries: elements() Return an iterator over elements repeating each as many times as its count. Elements are returned in arbitrary order. If an element\u2019s count is less than one, elements() will ignore it. >>> c = Counter(a=4, b=2, c=0, d=-2) >>> list(c.elements()) ['a', 'a', 'a', 'a', 'b', 'b'] most_common([n]) Return a list of the n most common elements and their counts from the most common to the least. If n is omitted or None, most_common() returns all elements in the counter. Elements with equal counts are ordered arbitrarily: >>> Counter('abracadabra').most_common(3) [('a', 5), ('r', 2), ('b', 2)] subtract([iterable-or-mapping]) Elements are subtracted from an iterable or from another mapping (or counter). Like dict.update() but subtracts counts instead of replacing them. Both inputs and outputs may be zero or negative. >>> c = Counter(a=4, b=2, c=0, d=-2) >>> d = Counter(a=1, b=2, c=3, d=4) >>> c.subtract(d) >>> c Counter({'a': 3, 'b': 0, 'c': -3, 'd': -6})","title":"Counter"},{"location":"notes/python/base_modules/collections/Counter/#counter","text":"Counter is a dict subclass for counting hashable objects: >>> c = Counter() # a new, empty counter >>> c Counter() >>> c = Counter('gallahad') # a new counter from an iterable >>> c Counter({'a': 3, 'l': 2, 'g': 1, 'h': 1, 'd': 1}) # a new counter from a mapping >>> c = Counter({'red': 4, 'blue': 2}) # a new counter from a mapping >>> c Counter({'red': 4, 'blue': 2}) >>> c = Counter(cats=4, dogs=8) # a new counter from keyword args >>> c Counter({'dogs': 8, 'cats': 4}) >>> Counter([1,2,2,3,3,3,4,4,4,4]) Counter({4: 4, 3: 3, 2: 2, 1: 1})","title":"Counter"},{"location":"notes/python/base_modules/collections/Counter/#delete-objects-as-shown-below","text":"# Delete records as shown below: >>> c = Counter(['eggs', 'ham']) >>> c Counter({'eggs': 1, 'ham': 1}) >>> del c['ham'] >>> c Counter({'eggs': 1}) Counter objects support three methods beyond those available for all dictionaries:","title":"Delete objects as shown below:"},{"location":"notes/python/base_modules/collections/Counter/#elements","text":"Return an iterator over elements repeating each as many times as its count. Elements are returned in arbitrary order. If an element\u2019s count is less than one, elements() will ignore it. >>> c = Counter(a=4, b=2, c=0, d=-2) >>> list(c.elements()) ['a', 'a', 'a', 'a', 'b', 'b']","title":"elements()"},{"location":"notes/python/base_modules/collections/Counter/#most_commonn","text":"Return a list of the n most common elements and their counts from the most common to the least. If n is omitted or None, most_common() returns all elements in the counter. Elements with equal counts are ordered arbitrarily: >>> Counter('abracadabra').most_common(3) [('a', 5), ('r', 2), ('b', 2)]","title":"most_common([n])"},{"location":"notes/python/base_modules/collections/Counter/#subtractiterable-or-mapping","text":"Elements are subtracted from an iterable or from another mapping (or counter). Like dict.update() but subtracts counts instead of replacing them. Both inputs and outputs may be zero or negative. >>> c = Counter(a=4, b=2, c=0, d=-2) >>> d = Counter(a=1, b=2, c=3, d=4) >>> c.subtract(d) >>> c Counter({'a': 3, 'b': 0, 'c': -3, 'd': -6})","title":"subtract([iterable-or-mapping])"},{"location":"notes/python/base_modules/collections/Default Dict/","text":"Default Dict Initialize dictionary values with a data type. Returns a new dictionary-like object. defaultdict is a subclass of the built-in dict class. The first argument provides the initial value for the default_factory attribute; it defaults to None . All remaining arguments are treated the same as if they were passed to the dict constructor, including keyword arguments. from collections import defaultdict # Try to append all numbers in a list to their descriptions s = [('yellow', 1), ('blue', 2), ('yellow', 3), ('blue', 4), ('red', 1)] d = {} for k, v in s: d[k].append(v) # You can't because there is no default data type for the values of the keys being created. >>> Traceback (most recent call last): File \"\", line 1, in File \"\", line 6, in KeyError: 'yellow' # Use a default dict to accomplish this: s = [('yellow', 1), ('blue', 2), ('yellow', 3), ('blue', 4), ('red', 1)] d = defaultdict(list) for k, v in s: d[k].append(v) >>> d defaultdict(, {'yellow': [1, 3], 'blue': [2, 4], 'red': [1]}) # You can accomplish this with the base dictionary like this: >>> d = {} >>> d.setdefault('yellow', []) [] >>> d {'yellow': []} or >>> d = {} >>> d.setdefault('yellow', list) >>> d {'yellow': } # ...and our previous example: s = [('yellow', 1), ('blue', 2), ('yellow', 3), ('blue', 4), ('red', 1)] d = {} for k, v in s: d.setdefault(k, []).append(v) >>> d {'yellow': [1, 3], 'blue': [2, 4], 'red': [1]}","title":"default_dict()"},{"location":"notes/python/base_modules/collections/Default Dict/#default-dict","text":"Initialize dictionary values with a data type. Returns a new dictionary-like object. defaultdict is a subclass of the built-in dict class. The first argument provides the initial value for the default_factory attribute; it defaults to None . All remaining arguments are treated the same as if they were passed to the dict constructor, including keyword arguments. from collections import defaultdict # Try to append all numbers in a list to their descriptions s = [('yellow', 1), ('blue', 2), ('yellow', 3), ('blue', 4), ('red', 1)] d = {} for k, v in s: d[k].append(v) # You can't because there is no default data type for the values of the keys being created. >>> Traceback (most recent call last): File \"\", line 1, in File \"\", line 6, in KeyError: 'yellow' # Use a default dict to accomplish this: s = [('yellow', 1), ('blue', 2), ('yellow', 3), ('blue', 4), ('red', 1)] d = defaultdict(list) for k, v in s: d[k].append(v) >>> d defaultdict(, {'yellow': [1, 3], 'blue': [2, 4], 'red': [1]}) # You can accomplish this with the base dictionary like this: >>> d = {} >>> d.setdefault('yellow', []) [] >>> d {'yellow': []} or >>> d = {} >>> d.setdefault('yellow', list) >>> d {'yellow': } # ...and our previous example: s = [('yellow', 1), ('blue', 2), ('yellow', 3), ('blue', 4), ('red', 1)] d = {} for k, v in s: d.setdefault(k, []).append(v) >>> d {'yellow': [1, 3], 'blue': [2, 4], 'red': [1]}","title":"Default Dict"},{"location":"notes/python/strings/Strings/","text":"Strings Padding: center(), rjust(), ljust() The center() method returns a string which is padded with the specified character. The rjust()\\ljust() methods return a string which is padded on either side. >>> 'A'.center(1, '*') 'A' >>> 'A'.center(2, '*') 'A*' >>> 'A'.center(3, '*') '*A*' >>> 'A'.rjust(1, '*') 'A' >>> 'A'.rjust(2, '*') '*A' >>> 'A'.rjust(3, '*') '**A' >>> 'A'.ljust(1, '*') 'A' >>> 'A'.ljust(2, '*') 'A*' >>> 'A'.ljust(3, '*') 'A**' str.format() Different common uses of the str.format() function format(value[, format_spec]) First example: >>> \"{}\".format('value') 'value' Multiple values: >>> \"{} {}\".format('value1','value2') 'value1 value2' Reverse order: >>> \"{1} {0}\".format('value1','value2') 'value2 value1' Key Word Arguments >>> print(\"{kwarg} is {0} used for {1}\" .format(\"being\", \"string formatting\", kwarg =\"Some Key Word Argument\")) ... Some Key Word Argument is being used for string formatting We can also use types to further format values: Syntax: {field_name:conversion}.format(value) Note: field_name can be the index (0) or name of key word argument conversion values: s \u2013 strings d \u2013 decimal integers (base-10) f \u2013 floating point display c \u2013 character b \u2013 binary o \u2013 octal x \u2013 hexadecimal with lowercase letters after 9 X \u2013 hexadecimal with uppercase letters after 9 e \u2013 exponent notation Use like this: s - string >>> '{kwarg:s}'.format(kwarg='5') '5' >>> '{kwarg:s}'.format(kwarg=5) Traceback (most recent call last): File \"\", line 1, in ValueError: Unknown format code 's' for object of type 'int' Notice how we got an error for trying to convert an int to a string d - decimal integers >>> # This works print(\"Convert {0} to decimal integer: {0:d}.\".format(100)) # Notice the Error print(\"Convert {0} to decimal integer: {0:d}.\".format(100.0)) ... Convert 100 to decimal integer: 100. >>> ... Traceback (most recent call last): File \"\", line 2, in ValueError: Unknown format code 'd' for object of type 'float' f - floats >>> # Default decimal precision to 0.000001 print(\"Convert {0} to float: {0:f}.\".format(100.123456789)) ... Convert 100.123456789 to float: 100.123457. >>> # Change decimal precision to 0.01 print(\"Convert {0} to float: {0:.2f}.\".format(100.123456789)) ... Convert 100.123456789 to float: 100.12. >>> # Change decimal precision to 0.1 print(\"Convert {0} to float: {0:.1f}.\".format(100.123456789)) ... Convert 100.123456789 to float: 100.1. >>> # Change decimal precision to 0.000000001 print(\"Convert {0} to float: {0:.9f}.\".format(100.123456789)) ... Convert 100.123456789 to float: 100.123456789. c - single character (accepts integer or single character string). Use this link for a unicode character lookup table Brief sample... NUL SOH STX ETX EOT ENQ ACK BEL BS HT LF VT FF CR SO SI DLE DC1 DC2 DC3 DC4 NAK SYN ETB CAN EM SUB ESC FS GS RS US ! \" # $ % & ' ( ) * + , - . / 0 1 2 3 4 5 6 7 8 9 : ; < = > ? @ A B C D E F G H I J K L M N O P Q R S T U V W X Y Z [ \\ ] ^ _ ... #000 >>> ' '.join(['{0:c}'.format(_) for _ in range(16)]) '\\x00 \\x01 \\x02 \\x03 \\x04 \\x05 \\x06 \\x07 \\x08 \\t \\n \\x0b \\x0c \\r \\x0e \\x0f' #001 >>> ' '.join(['{0:c}'.format(_) for _ in range(16,32)]) '\\x10 \\x11 \\x12 \\x13 \\x14 \\x15 \\x16 \\x17 \\x18 \\x19 \\x1a \\x1b \\x1c \\x1d \\x1e \\x1f' #002 >>> ' '.join(['{0:c}'.format(_) for _ in range(32,48)]) ' ! \" # $ % & \\' ( ) * + , - . /' #003 >>> ' '.join(['{0:c}'.format(_) for _ in range(48,64)]) '0 1 2 3 4 5 6 7 8 9 : ; < = > ?' #004 >>> ' '.join(['{0:c}'.format(_) for _ in range(64,80)]) '@ A B C D E F G H I J K L M N O' #005 >>> ' '.join(['{0:c}'.format(_) for _ in range(80,96)]) 'P Q R S T U V W X Y Z [ \\\\ ] ^ _' b - binary >>> print(\"{0:b}\".format(0)) 0 >>> print(\"{0:b}\".format(1)) 1 >>> print(\"{0:b}\".format(2)) 10 >>> print(\"{0:b}\".format(3)) 11 >>> print(\"{0:b}\".format(100)) 1100100 o - octal >>> print(\"{0:o}\".format(0)) 0 >>> print(\"{0:o}\".format(8)) 10 >>> print(\"{0:o}\".format(8*2)) 20 >>> print(\"{0:o}\".format(8*3)) 30 >>> print(\"{0:o}\".format(8*4)) 40 >>> print(\"{0:o}\".format(8 ** 1)) 10 >>> print(\"{0:o}\".format(8 ** 2)) 100 >>> print(\"{0:o}\".format(8 ** 3)) 1000 x\\H - hex\\HEX print(\"{0:x}\".format(0*16)) # 0 print(\"{0:x}\".format(1*16)) # 10 print(\"{0:x}\".format(2*16)) # 20 print(\"{0:x}\".format(16 ** 1)) # 10 print(\"{0:x}\".format(16 ** 2)) # 100 print(\"{0:x}\".format(16 ** 3)) # 1000 print(\"{0:x}\".format(10)) # a print(\"{0:X}\".format(10)) # A print(\"{0:x}\".format(15)) # f print(\"{0:X}\".format(15)) # F e - exponent print(\"{0:e}\".format(10)) # 1.000000e+01 print(\"{0:e}\".format(100)) # 1.000000e+02 print(\"{0:e}\".format(1000)) # 1.000000e+03 str.find() Use a substring and start-end range to identify where a substring resides in a larger string str.find(sub[, start[, end]]) s = 'ABCBCBCBCBC' # str.find() will return the index found or -1. # with only a start value the rest of the string is searched print(s.find('BC', 0)) # >>> 1 print(s.find('BC', 1)) # >>> 1 print(s.find('BC', 2)) # >>> 3 print(s.find('BC', 3)) # >>> 3 print(s.find('BC', 4)) # >>> 5 print(s.find('BC', 5)) # >>> 5 print(s.find('BC', 6)) # >>> 7 print(s.find('BC', 7)) # >>> 7 print(s.find('BC', 8)) # >>> 9 print(s.find('BC', 9)) # >>> 9 print(s.find('BC', 10)) # >>> -1 # with start and end, the substring must be within the range print(s.find('BC', 0,1)) # >>> -1 print(s.find('BC', 0,2)) # >>> -1 print(s.find('BC', 0,3)) # >>> 1","title":"Strings"},{"location":"notes/python/strings/Strings/#strings","text":"","title":"Strings"},{"location":"notes/python/strings/Strings/#padding-center-rjust-ljust","text":"The center() method returns a string which is padded with the specified character. The rjust()\\ljust() methods return a string which is padded on either side. >>> 'A'.center(1, '*') 'A' >>> 'A'.center(2, '*') 'A*' >>> 'A'.center(3, '*') '*A*' >>> 'A'.rjust(1, '*') 'A' >>> 'A'.rjust(2, '*') '*A' >>> 'A'.rjust(3, '*') '**A' >>> 'A'.ljust(1, '*') 'A' >>> 'A'.ljust(2, '*') 'A*' >>> 'A'.ljust(3, '*') 'A**'","title":"Padding: center(), rjust(), ljust()"},{"location":"notes/python/strings/Strings/#strformat","text":"Different common uses of the str.format() function format(value[, format_spec]) First example: >>> \"{}\".format('value') 'value' Multiple values: >>> \"{} {}\".format('value1','value2') 'value1 value2' Reverse order: >>> \"{1} {0}\".format('value1','value2') 'value2 value1' Key Word Arguments >>> print(\"{kwarg} is {0} used for {1}\" .format(\"being\", \"string formatting\", kwarg =\"Some Key Word Argument\")) ... Some Key Word Argument is being used for string formatting We can also use types to further format values: Syntax: {field_name:conversion}.format(value) Note: field_name can be the index (0) or name of key word argument conversion values: s \u2013 strings d \u2013 decimal integers (base-10) f \u2013 floating point display c \u2013 character b \u2013 binary o \u2013 octal x \u2013 hexadecimal with lowercase letters after 9 X \u2013 hexadecimal with uppercase letters after 9 e \u2013 exponent notation Use like this: s - string >>> '{kwarg:s}'.format(kwarg='5') '5' >>> '{kwarg:s}'.format(kwarg=5) Traceback (most recent call last): File \"\", line 1, in ValueError: Unknown format code 's' for object of type 'int' Notice how we got an error for trying to convert an int to a string d - decimal integers >>> # This works print(\"Convert {0} to decimal integer: {0:d}.\".format(100)) # Notice the Error print(\"Convert {0} to decimal integer: {0:d}.\".format(100.0)) ... Convert 100 to decimal integer: 100. >>> ... Traceback (most recent call last): File \"\", line 2, in ValueError: Unknown format code 'd' for object of type 'float' f - floats >>> # Default decimal precision to 0.000001 print(\"Convert {0} to float: {0:f}.\".format(100.123456789)) ... Convert 100.123456789 to float: 100.123457. >>> # Change decimal precision to 0.01 print(\"Convert {0} to float: {0:.2f}.\".format(100.123456789)) ... Convert 100.123456789 to float: 100.12. >>> # Change decimal precision to 0.1 print(\"Convert {0} to float: {0:.1f}.\".format(100.123456789)) ... Convert 100.123456789 to float: 100.1. >>> # Change decimal precision to 0.000000001 print(\"Convert {0} to float: {0:.9f}.\".format(100.123456789)) ... Convert 100.123456789 to float: 100.123456789. c - single character (accepts integer or single character string). Use this link for a unicode character lookup table Brief sample... NUL SOH STX ETX EOT ENQ ACK BEL BS HT LF VT FF CR SO SI DLE DC1 DC2 DC3 DC4 NAK SYN ETB CAN EM SUB ESC FS GS RS US ! \" # $ % & ' ( ) * + , - . / 0 1 2 3 4 5 6 7 8 9 : ; < = > ? @ A B C D E F G H I J K L M N O P Q R S T U V W X Y Z [ \\ ] ^ _ ... #000 >>> ' '.join(['{0:c}'.format(_) for _ in range(16)]) '\\x00 \\x01 \\x02 \\x03 \\x04 \\x05 \\x06 \\x07 \\x08 \\t \\n \\x0b \\x0c \\r \\x0e \\x0f' #001 >>> ' '.join(['{0:c}'.format(_) for _ in range(16,32)]) '\\x10 \\x11 \\x12 \\x13 \\x14 \\x15 \\x16 \\x17 \\x18 \\x19 \\x1a \\x1b \\x1c \\x1d \\x1e \\x1f' #002 >>> ' '.join(['{0:c}'.format(_) for _ in range(32,48)]) ' ! \" # $ % & \\' ( ) * + , - . /' #003 >>> ' '.join(['{0:c}'.format(_) for _ in range(48,64)]) '0 1 2 3 4 5 6 7 8 9 : ; < = > ?' #004 >>> ' '.join(['{0:c}'.format(_) for _ in range(64,80)]) '@ A B C D E F G H I J K L M N O' #005 >>> ' '.join(['{0:c}'.format(_) for _ in range(80,96)]) 'P Q R S T U V W X Y Z [ \\\\ ] ^ _' b - binary >>> print(\"{0:b}\".format(0)) 0 >>> print(\"{0:b}\".format(1)) 1 >>> print(\"{0:b}\".format(2)) 10 >>> print(\"{0:b}\".format(3)) 11 >>> print(\"{0:b}\".format(100)) 1100100 o - octal >>> print(\"{0:o}\".format(0)) 0 >>> print(\"{0:o}\".format(8)) 10 >>> print(\"{0:o}\".format(8*2)) 20 >>> print(\"{0:o}\".format(8*3)) 30 >>> print(\"{0:o}\".format(8*4)) 40 >>> print(\"{0:o}\".format(8 ** 1)) 10 >>> print(\"{0:o}\".format(8 ** 2)) 100 >>> print(\"{0:o}\".format(8 ** 3)) 1000 x\\H - hex\\HEX print(\"{0:x}\".format(0*16)) # 0 print(\"{0:x}\".format(1*16)) # 10 print(\"{0:x}\".format(2*16)) # 20 print(\"{0:x}\".format(16 ** 1)) # 10 print(\"{0:x}\".format(16 ** 2)) # 100 print(\"{0:x}\".format(16 ** 3)) # 1000 print(\"{0:x}\".format(10)) # a print(\"{0:X}\".format(10)) # A print(\"{0:x}\".format(15)) # f print(\"{0:X}\".format(15)) # F e - exponent print(\"{0:e}\".format(10)) # 1.000000e+01 print(\"{0:e}\".format(100)) # 1.000000e+02 print(\"{0:e}\".format(1000)) # 1.000000e+03","title":"str.format()"},{"location":"notes/python/strings/Strings/#strfind","text":"Use a substring and start-end range to identify where a substring resides in a larger string str.find(sub[, start[, end]]) s = 'ABCBCBCBCBC' # str.find() will return the index found or -1. # with only a start value the rest of the string is searched print(s.find('BC', 0)) # >>> 1 print(s.find('BC', 1)) # >>> 1 print(s.find('BC', 2)) # >>> 3 print(s.find('BC', 3)) # >>> 3 print(s.find('BC', 4)) # >>> 5 print(s.find('BC', 5)) # >>> 5 print(s.find('BC', 6)) # >>> 7 print(s.find('BC', 7)) # >>> 7 print(s.find('BC', 8)) # >>> 9 print(s.find('BC', 9)) # >>> 9 print(s.find('BC', 10)) # >>> -1 # with start and end, the substring must be within the range print(s.find('BC', 0,1)) # >>> -1 print(s.find('BC', 0,2)) # >>> -1 print(s.find('BC', 0,3)) # >>> 1","title":"str.find()"},{"location":"notes/python/useful/Args and Kwargs/","text":"Args and Kwargs Passing unknown amounts of inputs to a function *args - any number of inputs of any data type. They will be referenced in order with indicies being of the form args[0]...etc. **kwargs - The same as above but with key work arguments, so you would be able to access elements by key name. kwargs The * is important as it signifies if args or kwargs are being used. Otherwise this happens: >>> def prac(*args): ... for i in args: ... print(\"This arg is :{}\".format(i)) ... >>> prac([1,2,3,4,5]) This arg is :[1, 2, 3, 4, 5] # ooooops! >>> prac(*[1,2,3,4,5]) This arg is :1 This arg is :2 This arg is :3 This arg is :4 This arg is :5 >>> def prac(**kwargs): ... for k in kwargs.keys(): ... print(kwargs[k]) ... >>> prac(**{'A':1,'B':2}) 1 2 Also note iterables are acceptible inputs: >>> prac(*[1,2,3,4,5]) This arg is :1 This arg is :2 This arg is :3 This arg is :4 This arg is :5 >>> prac(*(1,2,3,4,5)) This arg is :1 This arg is :2 This arg is :3 This arg is :4 This arg is :5 >>> prac(*{1,2,3,4,5}) This arg is :1 This arg is :2 This arg is :3 This arg is :4 This arg is :5 >>> prac(*range(1,6)) This arg is :1 This arg is :2 This arg is :3 This arg is :4 This arg is :5 Below are additional examples def f(*args,**kwargs): print(args, kwargs) l = [1,2,3] t = (4,5,6) d = {'a':7,'b':8,'c':9} f() # () {} f(1,2,3) # (1, 2, 3) {} f(1,2,3,\"groovy\") # (1, 2, 3, 'groovy') {} f(a=1,b=2,c=3) # () {'a': 1, 'c': 3, 'b': 2} f(a=1,b=2,c=3,zzz=\"hi\") # () {'a': 1, 'c': 3, 'b': 2, 'zzz': 'hi'} f(1,2,3,a=1,b=2,c=3) # (1, 2, 3) {'a': 1, 'c': 3, 'b': 2} f(*l,**d) # (1, 2, 3) {'a': 7, 'c': 9, 'b': 8} f(*t,**d) # (4, 5, 6) {'a': 7, 'c': 9, 'b': 8} f(1,2,*t) # (1, 2, 4, 5, 6) {} f(q=\"winning\",**d) # () {'a': 7, 'q': 'winning', 'c': 9, 'b': 8} f(1,2,*t,q=\"winning\",**d) # (1, 2, 4, 5, 6) {'a': 7, 'q': 'winning', 'c': 9, 'b': 8} def f2(arg1,arg2,*args,**kwargs): print(arg1,arg2, args, kwargs) f2(1,2,3) # 1 2 (3,) {} f2(1,2,3,\"groovy\") # 1 2 (3, 'groovy') {} f2(arg1=1,arg2=2,c=3) # 1 2 () {'c': 3} f2(arg1=1,arg2=2,c=3,zzz=\"hi\") # 1 2 () {'c': 3, 'zzz': 'hi'} f2(1,2,3,a=1,b=2,c=3) # 1 2 (3,) {'a': 1, 'c': 3, 'b': 2} f2(*l,**d) # 1 2 (3,) {'a': 7, 'c': 9, 'b': 8} f2(*t,**d) # 4 5 (6,) {'a': 7, 'c': 9, 'b': 8} f2(1,2,*t) # 1 2 (4, 5, 6) {} f2(1,1,q=\"winning\",**d) # 1 1 () {'a': 7, 'q': 'winning', 'c': 9, 'b': 8} f2(1,2,*t,q=\"winning\",**d) # 1 2 (4, 5, 6) {'a': 7, 'q': 'winning', 'c': 9, 'b': 8}","title":"args, kwargs"},{"location":"notes/python/useful/Args and Kwargs/#args-and-kwargs","text":"Passing unknown amounts of inputs to a function *args - any number of inputs of any data type. They will be referenced in order with indicies being of the form args[0]...etc. **kwargs - The same as above but with key work arguments, so you would be able to access elements by key name. kwargs The * is important as it signifies if args or kwargs are being used. Otherwise this happens: >>> def prac(*args): ... for i in args: ... print(\"This arg is :{}\".format(i)) ... >>> prac([1,2,3,4,5]) This arg is :[1, 2, 3, 4, 5] # ooooops! >>> prac(*[1,2,3,4,5]) This arg is :1 This arg is :2 This arg is :3 This arg is :4 This arg is :5 >>> def prac(**kwargs): ... for k in kwargs.keys(): ... print(kwargs[k]) ... >>> prac(**{'A':1,'B':2}) 1 2 Also note iterables are acceptible inputs: >>> prac(*[1,2,3,4,5]) This arg is :1 This arg is :2 This arg is :3 This arg is :4 This arg is :5 >>> prac(*(1,2,3,4,5)) This arg is :1 This arg is :2 This arg is :3 This arg is :4 This arg is :5 >>> prac(*{1,2,3,4,5}) This arg is :1 This arg is :2 This arg is :3 This arg is :4 This arg is :5 >>> prac(*range(1,6)) This arg is :1 This arg is :2 This arg is :3 This arg is :4 This arg is :5 Below are additional examples def f(*args,**kwargs): print(args, kwargs) l = [1,2,3] t = (4,5,6) d = {'a':7,'b':8,'c':9} f() # () {} f(1,2,3) # (1, 2, 3) {} f(1,2,3,\"groovy\") # (1, 2, 3, 'groovy') {} f(a=1,b=2,c=3) # () {'a': 1, 'c': 3, 'b': 2} f(a=1,b=2,c=3,zzz=\"hi\") # () {'a': 1, 'c': 3, 'b': 2, 'zzz': 'hi'} f(1,2,3,a=1,b=2,c=3) # (1, 2, 3) {'a': 1, 'c': 3, 'b': 2} f(*l,**d) # (1, 2, 3) {'a': 7, 'c': 9, 'b': 8} f(*t,**d) # (4, 5, 6) {'a': 7, 'c': 9, 'b': 8} f(1,2,*t) # (1, 2, 4, 5, 6) {} f(q=\"winning\",**d) # () {'a': 7, 'q': 'winning', 'c': 9, 'b': 8} f(1,2,*t,q=\"winning\",**d) # (1, 2, 4, 5, 6) {'a': 7, 'q': 'winning', 'c': 9, 'b': 8} def f2(arg1,arg2,*args,**kwargs): print(arg1,arg2, args, kwargs) f2(1,2,3) # 1 2 (3,) {} f2(1,2,3,\"groovy\") # 1 2 (3, 'groovy') {} f2(arg1=1,arg2=2,c=3) # 1 2 () {'c': 3} f2(arg1=1,arg2=2,c=3,zzz=\"hi\") # 1 2 () {'c': 3, 'zzz': 'hi'} f2(1,2,3,a=1,b=2,c=3) # 1 2 (3,) {'a': 1, 'c': 3, 'b': 2} f2(*l,**d) # 1 2 (3,) {'a': 7, 'c': 9, 'b': 8} f2(*t,**d) # 4 5 (6,) {'a': 7, 'c': 9, 'b': 8} f2(1,2,*t) # 1 2 (4, 5, 6) {} f2(1,1,q=\"winning\",**d) # 1 1 () {'a': 7, 'q': 'winning', 'c': 9, 'b': 8} f2(1,2,*t,q=\"winning\",**d) # 1 2 (4, 5, 6) {'a': 7, 'q': 'winning', 'c': 9, 'b': 8}","title":"Args and Kwargs"},{"location":"notes/python/useful/Input/","text":"Input Here we show how to accept user input print('Enter your name:') x = input() print('Hello, ' + x) >>> Enter your name: Ben Hello, Ben","title":"input()"},{"location":"notes/python/useful/Input/#input","text":"Here we show how to accept user input print('Enter your name:') x = input() print('Hello, ' + x) >>> Enter your name: Ben Hello, Ben","title":"Input"},{"location":"notes/python/useful/Map/","text":"Map map() allows us to apply a function to a list of items # Simple Example >>> list(map(float, ['1.0', '2.0'])) [1.0, 2.0] # Turn this: items = [1, 2, 3, 4, 5] squared = [] for i in items: squared.append(i**2) # Into this with a lambda function: items = [1, 2, 3, 4, 5] squared = list(map(lambda x: x**2, items))","title":"map()"},{"location":"notes/python/useful/Map/#map","text":"map() allows us to apply a function to a list of items # Simple Example >>> list(map(float, ['1.0', '2.0'])) [1.0, 2.0] # Turn this: items = [1, 2, 3, 4, 5] squared = [] for i in items: squared.append(i**2) # Into this with a lambda function: items = [1, 2, 3, 4, 5] squared = list(map(lambda x: x**2, items))","title":"Map"},{"location":"notes/python/useful/Pass By Reference/","text":"Pass By Reference Python will pass values between objects as references to their memory position. Addresses not values are passed...except for primitives.. An example: def f(x,l=[]): for i in range(x): l.append(i*i) print(l) f(2) # [0, 1] f(3,[3,2,1]) # [3, 2, 1, 0, 1, 4] Here python treats the variable l as a fresh list because a fresh list or more accurately, it's location in memory was passed. See python created [3, 2, 1] separately and passed it's location to the function. Watch what happends when we call the function again with no list. f(3) # [0, 1, 0, 1, 4] why not [0,1,4]?. When the function was first called we created the default list \"l=[]\", and according to the function's directions, by default this function refers to that list's memory position. Check out the following examples of pythons memory usage for this example: l_mem = [] l = l_mem # the first call for i in range(2): l.append(i*i) print(l) # [0, 1] l = [3,2,1] # the second call for i in range(3): l.append(i*i) print(l) # [3, 2, 1, 0, 1, 4] l = l_mem # the third call for i in range(3): l.append(i*i) print(l) # [0, 1, 0, 1, 4]","title":"P.B. Reference"},{"location":"notes/python/useful/Pass By Reference/#pass-by-reference","text":"Python will pass values between objects as references to their memory position. Addresses not values are passed...except for primitives.. An example: def f(x,l=[]): for i in range(x): l.append(i*i) print(l) f(2) # [0, 1] f(3,[3,2,1]) # [3, 2, 1, 0, 1, 4] Here python treats the variable l as a fresh list because a fresh list or more accurately, it's location in memory was passed. See python created [3, 2, 1] separately and passed it's location to the function. Watch what happends when we call the function again with no list. f(3) # [0, 1, 0, 1, 4] why not [0,1,4]?. When the function was first called we created the default list \"l=[]\", and according to the function's directions, by default this function refers to that list's memory position. Check out the following examples of pythons memory usage for this example: l_mem = [] l = l_mem # the first call for i in range(2): l.append(i*i) print(l) # [0, 1] l = [3,2,1] # the second call for i in range(3): l.append(i*i) print(l) # [3, 2, 1, 0, 1, 4] l = l_mem # the third call for i in range(3): l.append(i*i) print(l) # [0, 1, 0, 1, 4]","title":"Pass By Reference"},{"location":"notes/python/useful/Sets/","text":"Sets Sets In Python A Set is an unordered collection data type that is iterable, mutable, and has no duplicate elements. Python\u2019s set class represents the mathematical notion of a set. The major advantage of using a set, as opposed to a list, is that it has a highly optimized method for checking whether a specific element is contained in the set. This is based on a data structure known as a hash table. Methods: add() add(x) Method: Adds the item x to set if it is not already present in the set. >>> s3.add(9) >>> s3 {9, 3} 2. union(s) Method: Returns a union of two set.Using the \u2018|\u2019 operator between 2 sets is the same as writing set1.union(set2) union() >>> s1.union(s2) {1, 2, 3, 4, 5} >>> s1 | s2 {1, 2, 3, 4, 5} 3. intersect(s) Method: Returns an intersection of two sets.The \u2018&\u2019 operator comes can also be used in this case. intersection() >>> s1.intersection(s2) {3} >>> s1 & s2 {3} difference difference(s) Method: Returns a set containing all the elements of invoking set but not of the second set. We can use \u2018-\u2018 operator here. >>> s1.difference(s2) {1, 2} >>> s1 - s2 {1, 2} 5. clear() Method: Empties the whole set. >>> s1.clear() >>> s2.clear() >>> s1 set() >>> s2 set() discard() discard() Method: The discard() method takes a single element x and removes it from the set (if present). >>> s1 {1, 2, 3} >>> s1.discard(1) >>> s1 {2, 3} issubset() issubset() Method: The issubset() method returns True if all elements of a set are present in another set (passed as an argument). If not, it returns False. >>> s1 {1, 2, 3} >>> s1.issubset({1,2,3,4}) True Operators for Sets Sets and frozen sets support the following operators: >>> k = 1 >>> key in s1 # containment check True >>> key not in s1 # non-containment check False >>> s1 == s2 # s1 is equivalent to s2 False >>> s1 != s2 # s1 is not equivalent to s2 True >>> s1 <= s2 # s1 is subset of s2 False >>> s1 < s2 # s1 is proper subset of s2 False >>> s1 >= s2 # s1 is superset of s2 False >>> s1 > s2 # s1 is proper superset of s2 False >>> s1 | s2 # the union of s1 and s2 {1, 2, 3, 4, 5} >>> s1 & s2 # the intersection of s1 and s2 {3} >>> s1 - s2 # the set of elements in s1 but not s2 {1, 2} >>> s1 ^ s2 # the set of elements in precisely one of s1 or s2 {1, 2, 4, 5}","title":"Sets"},{"location":"notes/python/useful/Sets/#sets","text":"Sets In Python A Set is an unordered collection data type that is iterable, mutable, and has no duplicate elements. Python\u2019s set class represents the mathematical notion of a set. The major advantage of using a set, as opposed to a list, is that it has a highly optimized method for checking whether a specific element is contained in the set. This is based on a data structure known as a hash table. Methods:","title":"Sets"},{"location":"notes/python/useful/Sets/#add","text":"add(x) Method: Adds the item x to set if it is not already present in the set. >>> s3.add(9) >>> s3 {9, 3} 2. union(s) Method: Returns a union of two set.Using the \u2018|\u2019 operator between 2 sets is the same as writing set1.union(set2)","title":"add()"},{"location":"notes/python/useful/Sets/#union","text":">>> s1.union(s2) {1, 2, 3, 4, 5} >>> s1 | s2 {1, 2, 3, 4, 5} 3. intersect(s) Method: Returns an intersection of two sets.The \u2018&\u2019 operator comes can also be used in this case.","title":"union()"},{"location":"notes/python/useful/Sets/#intersection","text":">>> s1.intersection(s2) {3} >>> s1 & s2 {3}","title":"intersection()"},{"location":"notes/python/useful/Sets/#difference","text":"difference(s) Method: Returns a set containing all the elements of invoking set but not of the second set. We can use \u2018-\u2018 operator here. >>> s1.difference(s2) {1, 2} >>> s1 - s2 {1, 2} 5. clear() Method: Empties the whole set. >>> s1.clear() >>> s2.clear() >>> s1 set() >>> s2 set()","title":"difference"},{"location":"notes/python/useful/Sets/#discard","text":"discard() Method: The discard() method takes a single element x and removes it from the set (if present). >>> s1 {1, 2, 3} >>> s1.discard(1) >>> s1 {2, 3}","title":"discard()"},{"location":"notes/python/useful/Sets/#issubset","text":"issubset() Method: The issubset() method returns True if all elements of a set are present in another set (passed as an argument). If not, it returns False. >>> s1 {1, 2, 3} >>> s1.issubset({1,2,3,4}) True Operators for Sets Sets and frozen sets support the following operators: >>> k = 1 >>> key in s1 # containment check True >>> key not in s1 # non-containment check False >>> s1 == s2 # s1 is equivalent to s2 False >>> s1 != s2 # s1 is not equivalent to s2 True >>> s1 <= s2 # s1 is subset of s2 False >>> s1 < s2 # s1 is proper subset of s2 False >>> s1 >= s2 # s1 is superset of s2 False >>> s1 > s2 # s1 is proper superset of s2 False >>> s1 | s2 # the union of s1 and s2 {1, 2, 3, 4, 5} >>> s1 & s2 # the intersection of s1 and s2 {3} >>> s1 - s2 # the set of elements in s1 but not s2 {1, 2} >>> s1 ^ s2 # the set of elements in precisely one of s1 or s2 {1, 2, 4, 5}","title":"issubset()"},{"location":"notes/python/useful/Sorted/","text":"Sorted Sort Arrays Want to sort something, sorted() is a great start. Syntax: sorted(iterable, key, reverse) Parameters: sorted takes three parameters from which two are optional. Iterable: sequence (list, tuple, string) or collection (dictionary, set, frozenset) or any other iterator that needs to be sorted Key(optional) : A function that would server as a key or a basis of sort comparison Reverse(optional) : If set true, then the iterable would be sorted in reverse (descending) order, by default it is set as false Note: A list also has sort() method which performs the same way as sorted(). Only difference being, sort() method doesn't return any value and changes the original list itself. x = [2,44,3,87,5] print(x) # [2, 44, 3, 87, 5] print(sorted(x)) #[2, 3, 5, 44, 87] print(sorted(x, reverse=True)) # [87, 44, 5, 3, 2] Custom Sorting using the key parameter: sorted() function has an optional parameter called \u2018key\u2019 which takes a function as its value. This key function transforms each element before sorting, it takes the value and returns 1 value which is then used within sort instead of the original value. For example, if we pass a list of strings in sorted(), it gets sorted alphabetically . But if we specify key = len, i.e. give len function as key, then the strings would be passed to len, and the value it returns, i.e. the length of strings will be sorted. Which means that the strings would be sorted based on their lengths instead # sort by your own criteria L = [\"cccc\", \"b\", \"dd\", \"aaa\"] print(\"Normal sort :\", sorted(L)) print(\"Sort with len :\", sorted(L, key = len))","title":"sorted()"},{"location":"notes/python/useful/Sorted/#sorted","text":"Sort Arrays Want to sort something, sorted() is a great start. Syntax: sorted(iterable, key, reverse) Parameters: sorted takes three parameters from which two are optional. Iterable: sequence (list, tuple, string) or collection (dictionary, set, frozenset) or any other iterator that needs to be sorted Key(optional) : A function that would server as a key or a basis of sort comparison Reverse(optional) : If set true, then the iterable would be sorted in reverse (descending) order, by default it is set as false Note: A list also has sort() method which performs the same way as sorted(). Only difference being, sort() method doesn't return any value and changes the original list itself. x = [2,44,3,87,5] print(x) # [2, 44, 3, 87, 5] print(sorted(x)) #[2, 3, 5, 44, 87] print(sorted(x, reverse=True)) # [87, 44, 5, 3, 2] Custom Sorting using the key parameter: sorted() function has an optional parameter called \u2018key\u2019 which takes a function as its value. This key function transforms each element before sorting, it takes the value and returns 1 value which is then used within sort instead of the original value. For example, if we pass a list of strings in sorted(), it gets sorted alphabetically . But if we specify key = len, i.e. give len function as key, then the strings would be passed to len, and the value it returns, i.e. the length of strings will be sorted. Which means that the strings would be sorted based on their lengths instead # sort by your own criteria L = [\"cccc\", \"b\", \"dd\", \"aaa\"] print(\"Normal sort :\", sorted(L)) print(\"Sort with len :\", sorted(L, key = len))","title":"Sorted"},{"location":"notes/python/useful/Zip/","text":"Zip Combine iterables and return them as tuple sets. The zip() function returns an iterator of tuples based on the iterable object. If no parameters are passed, zip() returns an empty iterator If a single iterable is passed, zip() returns an iterator of 1-tuples. Meaning, the number of elements in each tuple is 1 If multiple iterables are passed, ith tuple contains ith iterable values from all iterables. Suppose, two iterables are passed; one iterable containing 3 and other containing 5 elements, then the returned iterator will have 3 tuples >>> zip() <zip object at 0x102c9be48> # length 0 >>> list(zip()) [] # length 1 >>> list(zip([1,2,3])) [(1,), (2,), (3,)] # same length iterables >>> x, y = [1,2,3], [4,5,6] >>> list(zip(x,y)) [(1, 4), (2, 5), (3, 6)] # different length iterables >>> x, y = [1,2,3], [4,5,6,7] >>> list(zip(x,y)) [(1, 4), (2, 5), (3, 6)] iterables - can be built-in iterables (like: list, set, tuple, string, dict...), or user-defined iterables (object that has iter method). x, y, z = [1,2,3], [4,5,6], {'a':4,'b':5,'c':6} # dictionaries use keys by default results_default = set(zip(x,y,z)) results_2 = set(zip(x,y,z.keys())) results_3 = set(zip(x,y,z.values())) print(results_default) # {(3, 6, 'c'), (1, 4, 'a'), (2, 5, 'b')} print(results_2) # {(3, 6, 'c'), (1, 4, 'a'), (2, 5, 'b')} print(results_3) # {(1, 4, 4), (3, 6, 6), (2, 5, 5)} View the zip contents with a list or set or tuple data type: >>> list(zip(x,y)) [(1, 4), (2, 5), (3, 6)] >>> set(zip(x,y)) {(2, 5), (3, 6), (1, 4)} >>> tuple(zip(x,y)) ((1, 4), (2, 5), (3, 6)) Unzipping is possible too: > x [1, 2, 3] >>> y [4, 5, 6, 7] >>> list(zip(x,y)) [(1, 4), (2, 5), (3, 6)] # Use * to unzip a zip object. You have to call zip() as a wrapper for *zip(). >>> list(zip(*zip(x,y))) [(1, 2, 3), (4, 5, 6)] >>> zip(*zip(x,y)) <zip object at 0x102ccb888> # The zip object is automatically unpacked into a nd b. >>> a,b = zip(*zip(x,y)) >>> a (1, 2, 3) >>> b (4, 5, 6) >>> Watch what happens when you try to view a zip object with a dictionary: >>> dict(zip([1,2],['a','b'])) {1: 'a', 2: 'b'} We can create dictionaries from individual unassociated key, values lists!","title":"zip()"},{"location":"notes/python/useful/Zip/#zip","text":"Combine iterables and return them as tuple sets. The zip() function returns an iterator of tuples based on the iterable object. If no parameters are passed, zip() returns an empty iterator If a single iterable is passed, zip() returns an iterator of 1-tuples. Meaning, the number of elements in each tuple is 1 If multiple iterables are passed, ith tuple contains ith iterable values from all iterables. Suppose, two iterables are passed; one iterable containing 3 and other containing 5 elements, then the returned iterator will have 3 tuples >>> zip() <zip object at 0x102c9be48> # length 0 >>> list(zip()) [] # length 1 >>> list(zip([1,2,3])) [(1,), (2,), (3,)] # same length iterables >>> x, y = [1,2,3], [4,5,6] >>> list(zip(x,y)) [(1, 4), (2, 5), (3, 6)] # different length iterables >>> x, y = [1,2,3], [4,5,6,7] >>> list(zip(x,y)) [(1, 4), (2, 5), (3, 6)] iterables - can be built-in iterables (like: list, set, tuple, string, dict...), or user-defined iterables (object that has iter method). x, y, z = [1,2,3], [4,5,6], {'a':4,'b':5,'c':6} # dictionaries use keys by default results_default = set(zip(x,y,z)) results_2 = set(zip(x,y,z.keys())) results_3 = set(zip(x,y,z.values())) print(results_default) # {(3, 6, 'c'), (1, 4, 'a'), (2, 5, 'b')} print(results_2) # {(3, 6, 'c'), (1, 4, 'a'), (2, 5, 'b')} print(results_3) # {(1, 4, 4), (3, 6, 6), (2, 5, 5)} View the zip contents with a list or set or tuple data type: >>> list(zip(x,y)) [(1, 4), (2, 5), (3, 6)] >>> set(zip(x,y)) {(2, 5), (3, 6), (1, 4)} >>> tuple(zip(x,y)) ((1, 4), (2, 5), (3, 6)) Unzipping is possible too: > x [1, 2, 3] >>> y [4, 5, 6, 7] >>> list(zip(x,y)) [(1, 4), (2, 5), (3, 6)] # Use * to unzip a zip object. You have to call zip() as a wrapper for *zip(). >>> list(zip(*zip(x,y))) [(1, 2, 3), (4, 5, 6)] >>> zip(*zip(x,y)) <zip object at 0x102ccb888> # The zip object is automatically unpacked into a nd b. >>> a,b = zip(*zip(x,y)) >>> a (1, 2, 3) >>> b (4, 5, 6) >>> Watch what happens when you try to view a zip object with a dictionary: >>> dict(zip([1,2],['a','b'])) {1: 'a', 2: 'b'} We can create dictionaries from individual unassociated key, values lists!","title":"Zip"},{"location":"notes/sql/mysql/mySQL/","text":"mySQL Basics First, connect to your MySQL database using your MySQL client from your operating system command line: $ mysql -u root -p Next, after you're logged into your MySQL database, tell MySQL which database you want to use: mysql> show databases; +--------------------+ | Database | +--------------------+ | information_schema | | MySQL_DevDB | | mysql | | performance_schema | +--------------------+ 4 rows in set (0.01 sec) mysql> use mysql; Reading table information for completion of table and column names You can turn off this feature to get a quicker startup with -A Database changed mysql> show tables; +---------------------------+ | Tables_in_mysql | +---------------------------+ | columns_priv | | db | | event | | func | | general_log | | help_category | | help_keyword | | help_relation | | help_topic | | innodb_index_stats | | innodb_table_stats | | ndb_binlog_index | | plugin | | proc | | procs_priv | | proxies_priv | | servers | | slave_master_info | | slave_relay_log_info | | slave_worker_info | | slow_log | | tables_priv | | time_zone | | time_zone_leap_second | | time_zone_name | | time_zone_transition | | time_zone_transition_type | | user | +---------------------------+ 28 rows in set (0.00 sec) Create Database You can now work with the database. For example, the following commands demonstrate how to create a basic table named example , and how to insert some data into it: CREATE TABLE example ( id smallint unsigned not null auto_increment, name varchar(20) not null, constraint pk_example primary key (id) ); INSERT INTO example ( id, name ) VALUES ( null, 'Sample data' ); Drop Database\\Table DROP DATABASE dbname; DROP TABLE tablename; Type \\q to exit the mysql program. New User Courtesty of a2hosting.com To create a database user, type the following command. Replace username with the user you want to create, and replace password with the user's password: GRANT ALL PRIVILEGES ON *.* TO 'username'@'localhost' IDENTIFIED BY 'password'; This command grants the user all permissions. However, you can grant specific permissions to maintain precise control over database access. For example, to explicitly grant the SELECT permission, you would use the following command: GRANT SELECT ON *.* TO 'username'@'localhost' To log in to MySQL as the user you just created, type the following command. Replace username with the name of the user you created in step 3: mysql -u username -p Delete User To view a list of all users, type the following command from the mysql> prompt: SELECT user FROM mysql.user GROUP BY user; To delete a specific user, type the following command from the mysql> prompt. Replace username with the name of the user that you want to delete: DELETE FROM mysql.user WHERE user = 'username'; Using SQL script files Create a file named example.sql and open it in your preferred text edtior. Copy and paste the following text into the file: CREATE DATABASE dbname; USE dbname; CREATE TABLE tablename ( id smallint unsigned not null auto_increment, name varchar(20) not null, constraint pk_example primary key (id) ); INSERT INTO tablename ( id, name ) VALUES ( null, 'Sample data' ); To process the SQL script, type the following command. Replace username with the name of the user you just created: mysql -u username -p < example.sql MySQL Root Password Guide Courtest of a2hosting To reset the root password for MySQL, follow these steps: Log in to your account using SSH. You must runUsing SQL script files the commands in the following steps as the root user. Therefore, you can either log in directly as the root user (which is not recommended for security reasons), or use the su or sudo commands to run the commands as the root user. Stop the MySQL server using the appropriate command for your Linux distribution: For Debian and Ubuntu, type: service mysql stop For CentOS and Fedora, type: service mysqld stop Restart the MySQL server with the \u2014skip-grant-tables option. To do this, type the following command: mysqld_safe --skip-grant-tables & Make sure you type the ampersand ( & ) at the end of the command. This runs the command in the background and allows you to type the commands in the following steps. Running MySQL with the \u2014skip-grant-tables option enabled is highly insecure, and should only be done for a brief period while you reset the password. The steps below show you how to stop the mysqld_safe server instance safely and start the MySQL server securely after you have reset the root password. Log into MySQL using the following command: mysql At the mysql> prompt, reset the password. To do this, type the following command, replacing NEW-PASSWORD with the new root password: UPDATE mysql.user SET Password=PASSWORD('NEW-PASSWORD') WHERE User='root'; At the mysql> prompt, type the following commands: FLUSH PRIVILEGES; exit; Stop the MySQL server using the following command. You will be prompted to enter the new MySQL root password before the MySQL server shuts down: mysqladmin -u root -p shutdown Start the MySQL server normally. To do this, type the appropriate command for your Linux distribution: For Debian and Ubuntu, type: service mysql start For CentOS and Fedora, type: service mysqld start","title":"mySQL"},{"location":"notes/sql/mysql/mySQL/#mysql","text":"","title":"mySQL"},{"location":"notes/sql/mysql/mySQL/#basics","text":"First, connect to your MySQL database using your MySQL client from your operating system command line: $ mysql -u root -p Next, after you're logged into your MySQL database, tell MySQL which database you want to use: mysql> show databases; +--------------------+ | Database | +--------------------+ | information_schema | | MySQL_DevDB | | mysql | | performance_schema | +--------------------+ 4 rows in set (0.01 sec) mysql> use mysql; Reading table information for completion of table and column names You can turn off this feature to get a quicker startup with -A Database changed mysql> show tables; +---------------------------+ | Tables_in_mysql | +---------------------------+ | columns_priv | | db | | event | | func | | general_log | | help_category | | help_keyword | | help_relation | | help_topic | | innodb_index_stats | | innodb_table_stats | | ndb_binlog_index | | plugin | | proc | | procs_priv | | proxies_priv | | servers | | slave_master_info | | slave_relay_log_info | | slave_worker_info | | slow_log | | tables_priv | | time_zone | | time_zone_leap_second | | time_zone_name | | time_zone_transition | | time_zone_transition_type | | user | +---------------------------+ 28 rows in set (0.00 sec)","title":"Basics"},{"location":"notes/sql/mysql/mySQL/#create-database","text":"You can now work with the database. For example, the following commands demonstrate how to create a basic table named example , and how to insert some data into it: CREATE TABLE example ( id smallint unsigned not null auto_increment, name varchar(20) not null, constraint pk_example primary key (id) ); INSERT INTO example ( id, name ) VALUES ( null, 'Sample data' );","title":"Create Database"},{"location":"notes/sql/mysql/mySQL/#drop-databasetable","text":"DROP DATABASE dbname; DROP TABLE tablename; Type \\q to exit the mysql program.","title":"Drop Database\\Table"},{"location":"notes/sql/mysql/mySQL/#new-user","text":"Courtesty of a2hosting.com To create a database user, type the following command. Replace username with the user you want to create, and replace password with the user's password: GRANT ALL PRIVILEGES ON *.* TO 'username'@'localhost' IDENTIFIED BY 'password'; This command grants the user all permissions. However, you can grant specific permissions to maintain precise control over database access. For example, to explicitly grant the SELECT permission, you would use the following command: GRANT SELECT ON *.* TO 'username'@'localhost' To log in to MySQL as the user you just created, type the following command. Replace username with the name of the user you created in step 3: mysql -u username -p","title":"New User"},{"location":"notes/sql/mysql/mySQL/#delete-user","text":"To view a list of all users, type the following command from the mysql> prompt: SELECT user FROM mysql.user GROUP BY user; To delete a specific user, type the following command from the mysql> prompt. Replace username with the name of the user that you want to delete: DELETE FROM mysql.user WHERE user = 'username';","title":"Delete User"},{"location":"notes/sql/mysql/mySQL/#using-sql-script-files","text":"Create a file named example.sql and open it in your preferred text edtior. Copy and paste the following text into the file: CREATE DATABASE dbname; USE dbname; CREATE TABLE tablename ( id smallint unsigned not null auto_increment, name varchar(20) not null, constraint pk_example primary key (id) ); INSERT INTO tablename ( id, name ) VALUES ( null, 'Sample data' ); To process the SQL script, type the following command. Replace username with the name of the user you just created: mysql -u username -p < example.sql","title":"Using SQL script files"},{"location":"notes/sql/mysql/mySQL/#mysql-root-password-guide","text":"Courtest of a2hosting To reset the root password for MySQL, follow these steps:","title":"MySQL Root Password Guide"},{"location":"notes/sql/mysql/mySQL/#log-in-to-your-account-using-ssh","text":"You must runUsing SQL script files the commands in the following steps as the root user. Therefore, you can either log in directly as the root user (which is not recommended for security reasons), or use the su or sudo commands to run the commands as the root user.","title":"Log in to your account using SSH."},{"location":"notes/sql/mysql/mySQL/#stop-the-mysql-server-using-the-appropriate-command-for-your-linux-distribution","text":"For Debian and Ubuntu, type: service mysql stop For CentOS and Fedora, type: service mysqld stop","title":"Stop the MySQL server using the appropriate command for your Linux distribution:"},{"location":"notes/sql/mysql/mySQL/#restart-the-mysql-server-with-the-skip-grant-tables-option-to-do-this-type-the-following-command","text":"mysqld_safe --skip-grant-tables & Make sure you type the ampersand ( & ) at the end of the command. This runs the command in the background and allows you to type the commands in the following steps. Running MySQL with the \u2014skip-grant-tables option enabled is highly insecure, and should only be done for a brief period while you reset the password. The steps below show you how to stop the mysqld_safe server instance safely and start the MySQL server securely after you have reset the root password.","title":"Restart the MySQL server with the \u2014skip-grant-tables option. To do this, type the following command:"},{"location":"notes/sql/mysql/mySQL/#log-into-mysql-using-the-following-command","text":"mysql At the mysql> prompt, reset the password. To do this, type the following command, replacing NEW-PASSWORD with the new root password: UPDATE mysql.user SET Password=PASSWORD('NEW-PASSWORD') WHERE User='root'; At the mysql> prompt, type the following commands: FLUSH PRIVILEGES; exit; Stop the MySQL server using the following command. You will be prompted to enter the new MySQL root password before the MySQL server shuts down: mysqladmin -u root -p shutdown Start the MySQL server normally. To do this, type the appropriate command for your Linux distribution: For Debian and Ubuntu, type: service mysql start For CentOS and Fedora, type: service mysqld start","title":"Log into MySQL using the following command:"},{"location":"notes/sql/postgres/Postgres/","text":"Postgres Courtesy of Stackoverflow Installation Whoops...I'm sure this is easy...I'll get to it eventually. First Time Use and Setup Here's what worked for postgresql-9.1 on Xubuntu 12.04.1 LTS. Connect to the default database with user postgres : sudo -u postgres psql template1 Set the password for user postgres , then exit psql (Ctrl-D) : postgres=# ALTER USER postgres with encrypted password 'xxxxxxx'; Edit the pg_hba.conf file: sudo vim /etc/postgresql/9.1/main/pg_hba.conf And change peer to md5 on the line concerning postgres : local all postgres peer md5 Note: you need sudo or the file will appear blank Restart the database: postgres=# sudo /etc/init.d/postgresql restart\\ (Here you can check it worked with psql -U postgres .) Create a user having the same name as you (to find it, you can type whoami ) : postgres=# createuser -U postgres -d -e -E -l -P -r -s <my_name> The options tell postgresql to create a user that can login, create databases, create new roles, is a superuser, and will have an encrypted password. The really important ones are -P -E , so that you're asked to type the password that will be encrypted, and -d so that you can do a createdb . Beware of passwords : it will first ask you twice the new password (for the new user), repeated, and then once the postgres password (the one specified on step 2). Again, edit the pg_hba.conf file (see step 3 above), and change peer to md5 on the line concerning \"all\" other users : local all all peer md5 Restart (like in step 4), and check that you can login without -U postgres : psql template1 Note that if you do a mere psql, it will fail since it will try to connect you to a default database having the same name as you (ie. whoami ). template1 is the admin database that is here from the start. Now createdb <dbname> should work. Display all DBs: Use \\list or \\l to display databases. postgres=# \\list List of databases Name | Owner | Encoding | Collate | Ctype | Access privileges -----------------+----------+----------+------------+------------+----------------------- codalab_website | postgres | UTF8 | en_US.utf8 | en_US.utf8 | postgres | postgres | UTF8 | en_US.utf8 | en_US.utf8 | template0 | postgres | UTF8 | en_US.utf8 | en_US.utf8 | =c/postgres + | | | | | postgres=CTc/postgres template1 | postgres | UTF8 | en_US.utf8 | en_US.utf8 | =c/postgres + | | | | | postgres=CTc/postgres (4 rows) Display Tables Use \\dt to list all public tables, and \\dt * for all tables in the current DB you are connected to. postgres=# \\dt List of relations Schema | Name | Type | Owner --------+-------------------------------------+-------+------- public | account_emailaddress | table | root public | account_emailconfirmation | table | root public | auth_group | table | root public | auth_group_permissions | table | root public | auth_permission | table | root public | authenz_cluser | table | root public | authenz_cluser_groups | table | root public | authenz_cluser_user_permissions | table | root public | captcha_captchastore | table | root public | coopetitions_dislike | table | root public | coopetitions_downloadrecord | table | root public | coopetitions_like | table | root public | customizer_configuration | table | root public | django_admin_log | table | root ... codalab_website=# \\dt * List of relations Schema | Name | Type | Owner ------------+-------------------------------------+-------+---------- pg_catalog | pg_aggregate | table | postgres pg_catalog | pg_am | table | postgres pg_catalog | pg_amop | table | postgres pg_catalog | pg_amproc | table | postgres pg_catalog | pg_attrdef | table | postgres pg_catalog | pg_attribute | table | postgres pg_catalog | pg_auth_members | table | postgres pg_catalog | pg_authid | table | postgres pg_catalog | pg_cast | table | postgres pg_catalog | pg_class | table | postgres ... Display Connection Information codalab_website-# \\conninfo You are connected to database \"codalab_website\" as user \"root\" via socket in \"/var/run/postgresql\" at port \"5432\". You will never see tables in other databases, these tables aren't visible. You have to connect to the correct database to see its tables (and other objects). Switch DBs: To switch databases: postgres=# \\connect database_name Selects all non-template DBs: postgres=# SELECT datname FROM pg_database WHERE datistemplate = false; Select all tables in current DB connection postgres=# SELECT table_schema,table_name FROM information_schema.tables ORDER BY table_schema,table_name; Delete Database: postgres=# DROP DATABASE [ IF EXISTS ] name Create Database: postgres=# CREATE DATABASE testdb; Create User: See all current users: postgres=# SELECT usename FROM pg_user; Create New User: Bash: $ createuser name or Postgres: postgres=# CREATE USER testuser; Drop User: Bash: $ dropuser name or Postgres: postgres=# DROP USER testuser;","title":"Postgres"},{"location":"notes/sql/postgres/Postgres/#postgres","text":"Courtesy of Stackoverflow","title":"Postgres"},{"location":"notes/sql/postgres/Postgres/#installation","text":"Whoops...I'm sure this is easy...I'll get to it eventually.","title":"Installation"},{"location":"notes/sql/postgres/Postgres/#first-time-use-and-setup","text":"Here's what worked for postgresql-9.1 on Xubuntu 12.04.1 LTS. Connect to the default database with user postgres : sudo -u postgres psql template1 Set the password for user postgres , then exit psql (Ctrl-D) : postgres=# ALTER USER postgres with encrypted password 'xxxxxxx'; Edit the pg_hba.conf file: sudo vim /etc/postgresql/9.1/main/pg_hba.conf And change peer to md5 on the line concerning postgres : local all postgres peer md5 Note: you need sudo or the file will appear blank Restart the database: postgres=# sudo /etc/init.d/postgresql restart\\ (Here you can check it worked with psql -U postgres .) Create a user having the same name as you (to find it, you can type whoami ) : postgres=# createuser -U postgres -d -e -E -l -P -r -s <my_name> The options tell postgresql to create a user that can login, create databases, create new roles, is a superuser, and will have an encrypted password. The really important ones are -P -E , so that you're asked to type the password that will be encrypted, and -d so that you can do a createdb . Beware of passwords : it will first ask you twice the new password (for the new user), repeated, and then once the postgres password (the one specified on step 2). Again, edit the pg_hba.conf file (see step 3 above), and change peer to md5 on the line concerning \"all\" other users : local all all peer md5 Restart (like in step 4), and check that you can login without -U postgres : psql template1 Note that if you do a mere psql, it will fail since it will try to connect you to a default database having the same name as you (ie. whoami ). template1 is the admin database that is here from the start. Now createdb <dbname> should work.","title":"First Time Use and Setup"},{"location":"notes/sql/postgres/Postgres/#display-all-dbs","text":"Use \\list or \\l to display databases. postgres=# \\list List of databases Name | Owner | Encoding | Collate | Ctype | Access privileges -----------------+----------+----------+------------+------------+----------------------- codalab_website | postgres | UTF8 | en_US.utf8 | en_US.utf8 | postgres | postgres | UTF8 | en_US.utf8 | en_US.utf8 | template0 | postgres | UTF8 | en_US.utf8 | en_US.utf8 | =c/postgres + | | | | | postgres=CTc/postgres template1 | postgres | UTF8 | en_US.utf8 | en_US.utf8 | =c/postgres + | | | | | postgres=CTc/postgres (4 rows)","title":"Display all DBs:"},{"location":"notes/sql/postgres/Postgres/#display-tables","text":"Use \\dt to list all public tables, and \\dt * for all tables in the current DB you are connected to. postgres=# \\dt List of relations Schema | Name | Type | Owner --------+-------------------------------------+-------+------- public | account_emailaddress | table | root public | account_emailconfirmation | table | root public | auth_group | table | root public | auth_group_permissions | table | root public | auth_permission | table | root public | authenz_cluser | table | root public | authenz_cluser_groups | table | root public | authenz_cluser_user_permissions | table | root public | captcha_captchastore | table | root public | coopetitions_dislike | table | root public | coopetitions_downloadrecord | table | root public | coopetitions_like | table | root public | customizer_configuration | table | root public | django_admin_log | table | root ... codalab_website=# \\dt * List of relations Schema | Name | Type | Owner ------------+-------------------------------------+-------+---------- pg_catalog | pg_aggregate | table | postgres pg_catalog | pg_am | table | postgres pg_catalog | pg_amop | table | postgres pg_catalog | pg_amproc | table | postgres pg_catalog | pg_attrdef | table | postgres pg_catalog | pg_attribute | table | postgres pg_catalog | pg_auth_members | table | postgres pg_catalog | pg_authid | table | postgres pg_catalog | pg_cast | table | postgres pg_catalog | pg_class | table | postgres ...","title":"Display Tables"},{"location":"notes/sql/postgres/Postgres/#display-connection-information","text":"codalab_website-# \\conninfo You are connected to database \"codalab_website\" as user \"root\" via socket in \"/var/run/postgresql\" at port \"5432\". You will never see tables in other databases, these tables aren't visible. You have to connect to the correct database to see its tables (and other objects).","title":"Display Connection Information"},{"location":"notes/sql/postgres/Postgres/#switch-dbs","text":"To switch databases: postgres=# \\connect database_name Selects all non-template DBs: postgres=# SELECT datname FROM pg_database WHERE datistemplate = false; Select all tables in current DB connection postgres=# SELECT table_schema,table_name FROM information_schema.tables ORDER BY table_schema,table_name;","title":"Switch DBs:"},{"location":"notes/sql/postgres/Postgres/#delete-database","text":"postgres=# DROP DATABASE [ IF EXISTS ] name","title":"Delete Database:"},{"location":"notes/sql/postgres/Postgres/#create-database","text":"postgres=# CREATE DATABASE testdb;","title":"Create Database:"},{"location":"notes/sql/postgres/Postgres/#create-user","text":"","title":"Create User:"},{"location":"notes/sql/postgres/Postgres/#see-all-current-users","text":"postgres=# SELECT usename FROM pg_user;","title":"See all current users:"},{"location":"notes/sql/postgres/Postgres/#create-new-user","text":"Bash: $ createuser name or Postgres: postgres=# CREATE USER testuser;","title":"Create New User:"},{"location":"notes/sql/postgres/Postgres/#drop-user","text":"Bash: $ dropuser name or Postgres: postgres=# DROP USER testuser;","title":"Drop User:"},{"location":"notes/sql/postgres/pgadmin/","text":"pgAdmin Running the program Navigate to: /home/bbearce/pgAdmin4/pgAdmin4 note: pgAdmin4/pgAdmin4 is a virtual environment(venv). Activate venv: $ . bin/activate Run pgAdmin: $ python lib/python2.7/site-packages/pgadmin4/pgAdmin4.py","title":"pgAdmin"},{"location":"notes/sql/postgres/pgadmin/#pgadmin","text":"","title":"pgAdmin"},{"location":"notes/sql/postgres/pgadmin/#running-the-program","text":"Navigate to: /home/bbearce/pgAdmin4/pgAdmin4 note: pgAdmin4/pgAdmin4 is a virtual environment(venv). Activate venv: $ . bin/activate Run pgAdmin: $ python lib/python2.7/site-packages/pgadmin4/pgAdmin4.py","title":"Running the program"},{"location":"notes/sql/sql_server/Sql Server/","text":"SQL Server Testing the addition of a new language SELECT TOP 10000 sum(colC) FROM DB_Server.dbo.DB_Table WHERE colA = 'some value' GROUP BY colB","title":"SQL server"},{"location":"notes/sql/sql_server/Sql Server/#sql-server","text":"Testing the addition of a new language SELECT TOP 10000 sum(colC) FROM DB_Server.dbo.DB_Table WHERE colA = 'some value' GROUP BY colB","title":"SQL Server"},{"location":"notes/sql/sqlite/Basics/","text":"Sqlite .tables The following notes are from sqlitetutorial.net List tables after connecting using .tables $ sqlite3 kaggle_rsna SQLite version 3.11.0 2016-02-15 17:29:24 Enter \".help\" for usage hints. sqlite> .tables all_images final_annotation_list all_images_corrected remove_exams annotations remove_series annotations_corrected study_and_instance_annotation_ids The .tables command also can be used to show temporary tables. See the following example: First, create a new temporary table named temp_table1: sqlite> CREATE TEMPORARY TABLE temp_table1( name TEXT ); Second, list all tables from the database: sqlite> .tables The following shows the output: albums employees invoices playlists artists genres media_types temp.temp_table1 customers invoice_items playlist_track tracks Because the schema of temporary tables is temp, the command showed the names of schema and table of the temporary table such as temp.temp_table1 . If you want to show tables with the specific name, you can add a matching pattern: .tables pattern The command works the same as LIKE operator. The pattern must be surrounded by single quotation marks ('). For example, to find tables whose names start with the letter \u2018a\u2019, you use the following command: sqlite> .table 'a%' Here is the output: albums artists To shows the tables whose name contains the string ck, you use the %ck% pattern as shown in the following command: sqlite> .tables '%ck%' The output is as follows: playlist_track tracks Showing tables using SQL statement: Another way to list all tables in a database is to query them from the sqlite_master table. SELECT name FROM sqlite_master WHERE type ='table' AND name NOT LIKE 'sqlite_%'; Here is the output: name albums customers employees genres invoices invoice_items media_types playlists playlist_track tracks .schema / create table View the schema of a particular table: sqlite> .schema table sqlite> .schema all_images CREATE TABLE all_images( \"InstanceID\" TEXT, \"SeriesID\" TEXT, \"StudyID\" TEXT ); bulk insert If the table doesn't exist, sqlite will try to create it and it's scheme assuming a header. sqlite> .mode csv all_images sqlite> .import <path_to_csv> all_images csv export An example export from the rad table. Any query can be used as the basis for the export, including multi-line complex ones. sqlite> .headers on sqlite> .mode csv sqlite> .output rad_data.csv sqlite> select * from rad; sqlite>","title":"Basics"},{"location":"notes/sql/sqlite/Basics/#sqlite","text":"","title":"Sqlite"},{"location":"notes/sql/sqlite/Basics/#tables","text":"The following notes are from sqlitetutorial.net List tables after connecting using .tables $ sqlite3 kaggle_rsna SQLite version 3.11.0 2016-02-15 17:29:24 Enter \".help\" for usage hints. sqlite> .tables all_images final_annotation_list all_images_corrected remove_exams annotations remove_series annotations_corrected study_and_instance_annotation_ids The .tables command also can be used to show temporary tables. See the following example: First, create a new temporary table named temp_table1: sqlite> CREATE TEMPORARY TABLE temp_table1( name TEXT ); Second, list all tables from the database: sqlite> .tables The following shows the output: albums employees invoices playlists artists genres media_types temp.temp_table1 customers invoice_items playlist_track tracks Because the schema of temporary tables is temp, the command showed the names of schema and table of the temporary table such as temp.temp_table1 . If you want to show tables with the specific name, you can add a matching pattern: .tables pattern The command works the same as LIKE operator. The pattern must be surrounded by single quotation marks ('). For example, to find tables whose names start with the letter \u2018a\u2019, you use the following command: sqlite> .table 'a%' Here is the output: albums artists To shows the tables whose name contains the string ck, you use the %ck% pattern as shown in the following command: sqlite> .tables '%ck%' The output is as follows: playlist_track tracks Showing tables using SQL statement: Another way to list all tables in a database is to query them from the sqlite_master table. SELECT name FROM sqlite_master WHERE type ='table' AND name NOT LIKE 'sqlite_%'; Here is the output: name albums customers employees genres invoices invoice_items media_types playlists playlist_track tracks","title":".tables"},{"location":"notes/sql/sqlite/Basics/#schema-create-table","text":"View the schema of a particular table: sqlite> .schema table sqlite> .schema all_images CREATE TABLE all_images( \"InstanceID\" TEXT, \"SeriesID\" TEXT, \"StudyID\" TEXT );","title":".schema / create table"},{"location":"notes/sql/sqlite/Basics/#bulk-insert","text":"If the table doesn't exist, sqlite will try to create it and it's scheme assuming a header. sqlite> .mode csv all_images sqlite> .import <path_to_csv> all_images","title":"bulk insert"},{"location":"notes/sql/sqlite/Basics/#csv-export","text":"An example export from the rad table. Any query can be used as the basis for the export, including multi-line complex ones. sqlite> .headers on sqlite> .mode csv sqlite> .output rad_data.csv sqlite> select * from rad; sqlite>","title":"csv export"},{"location":"notes/sql/sqlite/installing/","text":"Installing Courtest of linuxfromscratch Introduction to SQLite The SQLite package is a software library that implements a self-contained, serverless, zero-configuration, transactional SQL database engine. This package is known to build and work properly using an LFS-9.0 platform. Package Information Download (HTTP): https://sqlite.org/2019/sqlite-autoconf-3300100.tar.gz Download MD5 sum: 51252dc6bc9094ba11ab151ba650ff3c Download size: 2.7 MB Estimated disk space required: 73 MB Estimated build time: 0.4 SBU (Using parallelism=4) Additional Downloads Optional Documentation Download (HTTP): https://sqlite.org/2019/sqlite-doc-3300100.zip Download MD5 sum: 0a631f0f293167c82be0c10831642469 Download size: 9.1 MB Installation of SQLite If you downloaded the optional documentation, issue the following command to install the documentation into the source tree: unzip -q ../sqlite-doc-3300100.zip Install SQLite by running the following commands: before that unzip with tar zxvf sqlite-autoconf-3300100.tar.gz and cd sqlite-autoconf-3300100 ./configure --prefix=/usr \\ --disable-static \\ --enable-fts5 \\ CFLAGS=\"-g -O2 \\ -DSQLITE_ENABLE_FTS3=1 \\ -DSQLITE_ENABLE_FTS4=1 \\ -DSQLITE_ENABLE_COLUMN_METADATA=1 \\ -DSQLITE_ENABLE_UNLOCK_NOTIFY=1 \\ -DSQLITE_ENABLE_DBSTAT_VTAB=1 \\ -DSQLITE_SECURE_DELETE=1 \\ -DSQLITE_ENABLE_FTS3_TOKENIZER=1\" && make This package does not come with a test suite. Now, as the root user run sudo make install : bbearce@bbearce-XPS-15-9560:~/Downloads/sqlite-autoconf-3300100$ sudo make install make[1]: Entering directory '/home/bbearce/Downloads/sqlite-autoconf-3300100' /bin/mkdir -p '/usr/lib' /bin/bash ./libtool --mode=install /usr/bin/install -c libsqlite3.la '/usr/lib' libtool: install: /usr/bin/install -c .libs/libsqlite3.so.0.8.6 /usr/lib/libsqlite3.so.0.8.6 libtool: install: (cd /usr/lib && { ln -s -f libsqlite3.so.0.8.6 libsqlite3.so.0 || { rm -f libsqlite3.so.0 && ln -s libsqlite3.so.0.8.6 libsqlite3.so.0; }; }) libtool: install: (cd /usr/lib && { ln -s -f libsqlite3.so.0.8.6 libsqlite3.so || { rm -f libsqlite3.so && ln -s libsqlite3.so.0.8.6 libsqlite3.so; }; }) libtool: install: /usr/bin/install -c .libs/libsqlite3.lai /usr/lib/libsqlite3.la libtool: install: /usr/bin/install -c .libs/libsqlite3.a /usr/lib/libsqlite3.a libtool: install: chmod 644 /usr/lib/libsqlite3.a libtool: install: ranlib /usr/lib/libsqlite3.a libtool: warning: remember to run 'libtool --finish /usr/local/lib' /bin/mkdir -p '/usr/bin' /bin/bash ./libtool --mode=install /usr/bin/install -c sqlite3 '/usr/bin' libtool: install: /usr/bin/install -c sqlite3 /usr/bin/sqlite3 /bin/mkdir -p '/usr/include' /usr/bin/install -c -m 644 sqlite3.h sqlite3ext.h '/usr/include' /bin/mkdir -p '/usr/share/man/man1' /usr/bin/install -c -m 644 sqlite3.1 '/usr/share/man/man1' /bin/mkdir -p '/usr/lib/pkgconfig' /usr/bin/install -c -m 644 sqlite3.pc '/usr/lib/pkgconfig' make[1]: Leaving directory '/home/bbearce/Downloads/sqlite-autoconf-3300100' Not sure what warning: remember to run 'libtool --finish /usr/local/lib' is for but I ran it and it didn't break anything and output this message: bbearce@bbearce-XPS-15-9560:~/Downloads/sqlite-autoconf-3300100$ libtool --finish /usr/local/lib libtool: finish: PATH=\"/home/bbearce/gems/bin:/home/bbearce/bin:/home/bbearce/.local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/sbin\" ldconfig -n /usr/local/lib ---------------------------------------------------------------------- Libraries have been installed in: /usr/local/lib If you ever happen to want to link against installed libraries in a given directory, LIBDIR, you must either use libtool, and specify the full pathname of the library, or use the '-LLIBDIR' flag during linking and do at least one of the following: - add LIBDIR to the 'LD_LIBRARY_PATH' environment variable during execution - add LIBDIR to the 'LD_RUN_PATH' environment variable during linking - use the '-Wl,-rpath -Wl,LIBDIR' linker flag - have your system administrator add LIBDIR to '/etc/ld.so.conf' See any operating system documentation about shared libraries for more information, such as the ld(1) and ld.so(8) manual pages. ---------------------------------------------------------------------- ...a little background from gnu : GNU libtool is a generic library support script. Libtool hides the complexity of using shared libraries behind a consistent, portable interface. If you downloaded the optional documentation, issue the following commands as the root user to install it: install -v -m755 -d /usr/share/doc/sqlite-3.30.1 && cp -v -R sqlite-doc-3300100/* /usr/share/doc/sqlite-3.30.1","title":"Installing"},{"location":"notes/sql/sqlite/installing/#installing","text":"Courtest of linuxfromscratch","title":"Installing"},{"location":"notes/sql/sqlite/installing/#introduction-to-sqlite","text":"The SQLite package is a software library that implements a self-contained, serverless, zero-configuration, transactional SQL database engine. This package is known to build and work properly using an LFS-9.0 platform.","title":"Introduction to SQLite"},{"location":"notes/sql/sqlite/installing/#package-information","text":"Download (HTTP): https://sqlite.org/2019/sqlite-autoconf-3300100.tar.gz Download MD5 sum: 51252dc6bc9094ba11ab151ba650ff3c Download size: 2.7 MB Estimated disk space required: 73 MB Estimated build time: 0.4 SBU (Using parallelism=4)","title":"Package Information"},{"location":"notes/sql/sqlite/installing/#additional-downloads","text":"","title":"Additional Downloads"},{"location":"notes/sql/sqlite/installing/#optional-documentation","text":"Download (HTTP): https://sqlite.org/2019/sqlite-doc-3300100.zip Download MD5 sum: 0a631f0f293167c82be0c10831642469 Download size: 9.1 MB","title":"Optional Documentation"},{"location":"notes/sql/sqlite/installing/#installation-of-sqlite","text":"If you downloaded the optional documentation, issue the following command to install the documentation into the source tree: unzip -q ../sqlite-doc-3300100.zip Install SQLite by running the following commands: before that unzip with tar zxvf sqlite-autoconf-3300100.tar.gz and cd sqlite-autoconf-3300100 ./configure --prefix=/usr \\ --disable-static \\ --enable-fts5 \\ CFLAGS=\"-g -O2 \\ -DSQLITE_ENABLE_FTS3=1 \\ -DSQLITE_ENABLE_FTS4=1 \\ -DSQLITE_ENABLE_COLUMN_METADATA=1 \\ -DSQLITE_ENABLE_UNLOCK_NOTIFY=1 \\ -DSQLITE_ENABLE_DBSTAT_VTAB=1 \\ -DSQLITE_SECURE_DELETE=1 \\ -DSQLITE_ENABLE_FTS3_TOKENIZER=1\" && make This package does not come with a test suite. Now, as the root user run sudo make install : bbearce@bbearce-XPS-15-9560:~/Downloads/sqlite-autoconf-3300100$ sudo make install make[1]: Entering directory '/home/bbearce/Downloads/sqlite-autoconf-3300100' /bin/mkdir -p '/usr/lib' /bin/bash ./libtool --mode=install /usr/bin/install -c libsqlite3.la '/usr/lib' libtool: install: /usr/bin/install -c .libs/libsqlite3.so.0.8.6 /usr/lib/libsqlite3.so.0.8.6 libtool: install: (cd /usr/lib && { ln -s -f libsqlite3.so.0.8.6 libsqlite3.so.0 || { rm -f libsqlite3.so.0 && ln -s libsqlite3.so.0.8.6 libsqlite3.so.0; }; }) libtool: install: (cd /usr/lib && { ln -s -f libsqlite3.so.0.8.6 libsqlite3.so || { rm -f libsqlite3.so && ln -s libsqlite3.so.0.8.6 libsqlite3.so; }; }) libtool: install: /usr/bin/install -c .libs/libsqlite3.lai /usr/lib/libsqlite3.la libtool: install: /usr/bin/install -c .libs/libsqlite3.a /usr/lib/libsqlite3.a libtool: install: chmod 644 /usr/lib/libsqlite3.a libtool: install: ranlib /usr/lib/libsqlite3.a libtool: warning: remember to run 'libtool --finish /usr/local/lib' /bin/mkdir -p '/usr/bin' /bin/bash ./libtool --mode=install /usr/bin/install -c sqlite3 '/usr/bin' libtool: install: /usr/bin/install -c sqlite3 /usr/bin/sqlite3 /bin/mkdir -p '/usr/include' /usr/bin/install -c -m 644 sqlite3.h sqlite3ext.h '/usr/include' /bin/mkdir -p '/usr/share/man/man1' /usr/bin/install -c -m 644 sqlite3.1 '/usr/share/man/man1' /bin/mkdir -p '/usr/lib/pkgconfig' /usr/bin/install -c -m 644 sqlite3.pc '/usr/lib/pkgconfig' make[1]: Leaving directory '/home/bbearce/Downloads/sqlite-autoconf-3300100' Not sure what warning: remember to run 'libtool --finish /usr/local/lib' is for but I ran it and it didn't break anything and output this message: bbearce@bbearce-XPS-15-9560:~/Downloads/sqlite-autoconf-3300100$ libtool --finish /usr/local/lib libtool: finish: PATH=\"/home/bbearce/gems/bin:/home/bbearce/bin:/home/bbearce/.local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/sbin\" ldconfig -n /usr/local/lib ---------------------------------------------------------------------- Libraries have been installed in: /usr/local/lib If you ever happen to want to link against installed libraries in a given directory, LIBDIR, you must either use libtool, and specify the full pathname of the library, or use the '-LLIBDIR' flag during linking and do at least one of the following: - add LIBDIR to the 'LD_LIBRARY_PATH' environment variable during execution - add LIBDIR to the 'LD_RUN_PATH' environment variable during linking - use the '-Wl,-rpath -Wl,LIBDIR' linker flag - have your system administrator add LIBDIR to '/etc/ld.so.conf' See any operating system documentation about shared libraries for more information, such as the ld(1) and ld.so(8) manual pages. ---------------------------------------------------------------------- ...a little background from gnu : GNU libtool is a generic library support script. Libtool hides the complexity of using shared libraries behind a consistent, portable interface. If you downloaded the optional documentation, issue the following commands as the root user to install it: install -v -m755 -d /usr/share/doc/sqlite-3.30.1 && cp -v -R sqlite-doc-3300100/* /usr/share/doc/sqlite-3.30.1","title":"Installation of SQLite"},{"location":"notes/sql/sqlite/useful_everyday_useage/","text":"Useful Everyday Code Drop If Exists DROP TABLE [IF EXISTS] [schema_name.]table_name; Select Into source stackoverflow CREATE TABLE equipments_backup AS SELECT * FROM equipments Ranks / Row_Number Courtest of sqlitetutorial Window function support was first added to SQLite with release version 3.25.0 (2018-09-15). The SQLite developers used the PostgreSQL window function documentation as their primary reference for how window functions ought to behave. The RANK() function is a window function that assigns a rank to each row in a query\u2019s result set. The rank of a row is calculated by one plus the number of ranks that comes before it. The following shows the syntax of the RANK() function: RANK() OVER ( PARTITION BY <expression1>[{,<expression2>...}] ORDER BY <expression1> [ASC|DESC], [{,<expression1>...}] ) Courtesty of sqlite SQLite supports the following 11 built-in window functions: row_number() The number of the row within the current partition. Rows are numbered starting from 1 in the order defined by the ORDER BY clause in the window definition, or in arbitrary order otherwise. rank() The row_number() of the first peer in each group - the rank of the current row with gaps. If there is no ORDER BY clause, then all rows are considered peers and this function always returns 1. dense_rank() The number of the current row's peer group within its partition - the rank of the current row without gaps. Partitions are numbered starting from 1 in the order defined by the ORDER BY clause in the window definition. If there is no ORDER BY clause, then all rows are considered peers and this function always returns 1. percent_rank() Despite the name, this function always returns a value between 0.0 and 1.0 equal to (rank - 1)/(partition-rows - 1), where rank is the value returned by built-in window function rank() and partition-rows is the total number of rows in the partition. If the partition contains only one row, this function returns 0.0. cume_dist() The cumulative distribution. Calculated as row-number/partition-rows, where row-number is the value returned by row_number() for the last peer in the group and partition-rows the number of rows in the partition. ntile(N) Argument N is handled as an integer. This function divides the partition into N groups as evenly as possible and assigns an integer between 1 and N to each group, in the order defined by the ORDER BY clause, or in arbitrary order otherwise. If necessary, larger groups occur first. This function returns the integer value assigned to the group that the current row is a part of.","title":"Useful Code"},{"location":"notes/sql/sqlite/useful_everyday_useage/#useful-everyday-code","text":"","title":"Useful Everyday Code"},{"location":"notes/sql/sqlite/useful_everyday_useage/#drop-if-exists","text":"DROP TABLE [IF EXISTS] [schema_name.]table_name;","title":"Drop If Exists"},{"location":"notes/sql/sqlite/useful_everyday_useage/#select-into","text":"source stackoverflow CREATE TABLE equipments_backup AS SELECT * FROM equipments","title":"Select Into"},{"location":"notes/sql/sqlite/useful_everyday_useage/#ranks-row_number","text":"Courtest of sqlitetutorial Window function support was first added to SQLite with release version 3.25.0 (2018-09-15). The SQLite developers used the PostgreSQL window function documentation as their primary reference for how window functions ought to behave. The RANK() function is a window function that assigns a rank to each row in a query\u2019s result set. The rank of a row is calculated by one plus the number of ranks that comes before it. The following shows the syntax of the RANK() function: RANK() OVER ( PARTITION BY <expression1>[{,<expression2>...}] ORDER BY <expression1> [ASC|DESC], [{,<expression1>...}] ) Courtesty of sqlite SQLite supports the following 11 built-in window functions: row_number() The number of the row within the current partition. Rows are numbered starting from 1 in the order defined by the ORDER BY clause in the window definition, or in arbitrary order otherwise. rank() The row_number() of the first peer in each group - the rank of the current row with gaps. If there is no ORDER BY clause, then all rows are considered peers and this function always returns 1. dense_rank() The number of the current row's peer group within its partition - the rank of the current row without gaps. Partitions are numbered starting from 1 in the order defined by the ORDER BY clause in the window definition. If there is no ORDER BY clause, then all rows are considered peers and this function always returns 1. percent_rank() Despite the name, this function always returns a value between 0.0 and 1.0 equal to (rank - 1)/(partition-rows - 1), where rank is the value returned by built-in window function rank() and partition-rows is the total number of rows in the partition. If the partition contains only one row, this function returns 0.0. cume_dist() The cumulative distribution. Calculated as row-number/partition-rows, where row-number is the value returned by row_number() for the last peer in the group and partition-rows the number of rows in the partition. ntile(N) Argument N is handled as an integer. This function divides the partition into N groups as evenly as possible and assigns an integer between 1 and N to each group, in the order defined by the ORDER BY clause, or in arbitrary order otherwise. If necessary, larger groups occur first. This function returns the integer value assigned to the group that the current row is a part of.","title":"Ranks / Row_Number"}]}